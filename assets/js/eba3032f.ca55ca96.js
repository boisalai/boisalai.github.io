"use strict";(self.webpackChunkmy_doc=self.webpackChunkmy_doc||[]).push([[8067],{75632:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var t=s(85893),i=s(11151);const r={sidebar_label:"1 Expressions r\xe9guli\xe8res",sidebar_position:2},o="1 Expressions r\xe9guli\xe8res",a={id:"courses/university/ift-7022/week-01",title:"1 Expressions r\xe9guli\xe8res",description:"Cours du 5 septembre 2023 :",source:"@site/docs/courses/university/ift-7022/week-01.md",sourceDirName:"courses/university/ift-7022",slug:"/courses/university/ift-7022/week-01",permalink:"/docs/courses/university/ift-7022/week-01",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/courses/university/ift-7022/week-01.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_label:"1 Expressions r\xe9guli\xe8res",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"IFT-7022 Traitement automatique de la langue naturelle",permalink:"/docs/courses/university/ift-7022/"},next:{title:"2 Pr\xe9traitement de textes et distance minimale d'\xe9dition",permalink:"/docs/courses/university/ift-7022/week-02"}},l={},c=[];function d(e){const n={a:"a",code:"code",h1:"h1",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"1-expressions-r\xe9guli\xe8res",children:"1 Expressions r\xe9guli\xe8res"}),"\n",(0,t.jsx)(n.p,{children:"Cours du 5 septembre 2023 :"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcd5"," Jurafsky & Martin, 3e \xe9dition, ",(0,t.jsx)(n.a,{href:"https://web.stanford.edu/~jurafsky/slp3/2.pdf",children:"chapitre 2, section 2.1"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"s01",src:s(49333).Z+"",width:"2370",height:"1586"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Regular expression"})," (often shortened to ",(0,t.jsx)(n.strong,{children:"regex"}),"), can be used to specify strings we might want to extract from a document."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Text normalization"})," means converting it to a more convenient, standard form."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tokenization"})," is used in natural language processing (NLP) to split paragraphs and sentences into smaller units that can be more easily assigned meaning.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["En traitement automatique du langage naturel (TALN), la ",(0,t.jsx)(n.strong,{children:"tokenisation"})," permet de diviser des paragraphes et des phrases en unit\xe9s plus petites afin d'en faciliter l'attribution de sens."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["We need to tokenize ",(0,t.jsx)(n.strong,{children:"emoticons"})," like ",(0,t.jsx)(n.code,{children:":)"})," or ",(0,t.jsx)(n.strong,{children:"hashtags"})," like ",(0,t.jsx)(n.code,{children:"#nlproc"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Another part of text normalization is ",(0,t.jsx)(n.strong,{children:"lemmatization"}),", the task of determining that two words have the same root, despite their surface differences."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Stemming"})," refers to a simpler version of lemmatization in which we mainly just strip suffixes from the end of the word."]}),"\n",(0,t.jsxs)(n.li,{children:["Text normalization also includes ",(0,t.jsx)(n.strong,{children:"sentence segmentation"}),": breaking up a text into individual sentences, using cues like sentence segmentation periods or exclamation points."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Edit distance"})," is a metric that measures how similar two strings are based on the number of edits (insertions, deletions, substitutions) it takes to change one string into the other."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Before almost any natural language processing of a text, the text has to be normalized. At least three tasks are commonly applied as part of any normalization process:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Tokenizing (segmenting) words"}),"\n",(0,t.jsx)(n.li,{children:"Normalizing word formats"}),"\n",(0,t.jsx)(n.li,{children:"Segmenting sentences"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Most tokenization schemes have two parts: a ",(0,t.jsx)(n.strong,{children:"token learner"}),", and a ",(0,t.jsx)(n.strong,{children:"token segmenter"}),".\nThe token learner takes a raw training corpus (sometimes roughly preseparated into words, for example by whitespace) and induces a vocabulary, a set\nof tokens. The token segmenter takes a raw test sentence and segments it into the\ntokens in the vocabulary."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Case folding"})," is another kind of normalization, mapping everything to lower case."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Lemmatization"})," is the task of determining that two words have the same root, despite their surface differences."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Stemming"})," refers to the process of reducing a word to its word stem that affixes to suffixes and prefixes or the roots."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sentence segmentation"}),". The most useful cues for segmenting a text into sentences are punctuation, like periods, question marks, and exclamation points."]}),"\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.strong,{children:"minimum edit distance"})," between two strings is defined minimum edit distance\nas the minimum number of editing operations (operations like insertion, deletion,\nsubstitution) needed to transform one string into another."]}),"\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.strong,{children:"Levenshtein distance"})," between two sequences is the simplest weighting factor in\nwhich each of the three operations has a cost of 1."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Exemples \xe0 faire avec ",(0,t.jsx)(n.a,{href:"https://regexr.com/",children:"https://regexr.com/"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-txt",children:"# Trouver les la, le, les, l', etc.\n/le|la|l'|les/g\n/les|le|l'|le/g\n/\\b(les|le|l'|le)/g  # D\xe9but des mots.\n/\\b(les|le|l'|le)\\b/g  # Fin des mots.\n/\\b[Ll](e|a|'|es|es|e|'|e)\\b/g  # Isoler les Ll.\n/\\b[Ll](e|a|'|es)\\b/g  # Enlever les doublons.\n/\\b[Ll][ea']s?\\b/g  # Rendre le s optionel.\n\n# Trouver les courriels.\n/[a-z]+/g\n/[a-z]+.[a-z]+.[0-9]+/g\n/[a-z]+.[a-z]+.[0-9]@[a-z]+.[a-z]+.[a-z]+/g\n/[\\w]+.[\\w]+.[\\d]@[\\w]+.[\\w]+.[\\w]+/g  # Simplifier.\n/[\\w]+\\.[\\w]+\\.[\\d]@[\\w]+\\.[\\w]+\\.[\\w]+/g  # Forcer le point.\n/([\\w]+)\\.([\\w]+)\\.[\\d]@([\\w]+\\.[\\w]+\\.[\\w]+)/g  # Cr\xe9er des groupes.\n/([\\w]+)\\.([\\w]+)\\.[\\d]{1,3}@([\\w]+\\.[\\w]+\\.[\\w]+)/g  # Nombre de r\xe9p\xe9titions.\n\n# Exemples du prof le 12 septembre 2023\n[^\\n]([A-Z\xc0-\xdc][-A-z\xc0-\xfc]+)/g\n/(Canada|Qu\xe9bec)/g\n/(\\d[\\d\\s,]*(millions)?)\\s(d'h|h)/g  # pour obtenir les populations.\n"})}),"\n",(0,t.jsx)(n.p,{children:"Regex en Python."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Module ",(0,t.jsx)(n.code,{children:"re"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"compile"})," fonction qui g\xe9n\xe8re une version compil\xe9e d'une regex."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"match"})," ou ",(0,t.jsx)(n.code,{children:"search"})," fait le matching entre une regex et une cha\xeene."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"sub"})," remplace la premi\xe8re occurrence d'un patron par une cha\xeene."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import re\n\nexample_string = "this is a test"\np = re.compile(r"\\w+")\n\nm = p.search(example_string) print("Start index:", m.start())  # Start index: 0\nprint(" End index:", m.end())  # End index: 4\nprint(m.group())  # this\nprint(p.findall(example_string))  # [\u2018this\', \'is\', \'a\', \'test\']\n\np = re.compile("is")\nprint(p.match(example_string))  # None\nprint(re.sub(r"(this) (is) (.+)", "\\\\2 \\\\1 \\\\3", example_string))  # \'is this a test\'\n'})}),"\n",(0,t.jsx)(n.p,{children:"See also:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.a,{href:"https://docs.python.org/3/library/re.html",children:[(0,t.jsx)(n.code,{children:"re"})," - Regular expression operations"]}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://regex101.com/",children:"Online regular expression tester"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://regexr.com/",children:"RegExr"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"http://www.regextester.com/",children:"Regex Tester"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://alf.nu/RegexGolf?world=regex&level=r00",children:"Regex Golf"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://cheatography.com/davechild/cheat-sheets/regular-expressions/",children:"Regular Expressions cheat sheet"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://docs.python.org/3/howto/regex.html",children:"Regular Expression HOWTO"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://developers.google.com/edu/python/regular-expressions",children:"Python Regular Expressions"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://missing.csail.mit.edu/2020/data-wrangling/",children:"Data Wrangling"})," from CSAIL MIT."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},49333:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/s01-999a3ce9e11f795a4e464b67b29be0ff.png"},11151:(e,n,s)=>{s.d(n,{Z:()=>a,a:()=>o});var t=s(67294);const i={},r=t.createContext(i);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);
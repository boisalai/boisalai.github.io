"use strict";(self.webpackChunkmy_doc=self.webpackChunkmy_doc||[]).push([[9596],{91514:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>c,frontMatter:()=>t,metadata:()=>l,toc:()=>d});var i=s(85893),r=s(11151);const t={sidebar_label:"Quiz 4 du 15 novembre 2023",sidebar_position:34,sidebar_class_name:"hidden"},o="Quiz 4 du 15 novembre 2023",l={id:"courses/gif-7005/quiz-4",title:"Quiz 4 du 15 novembre 2023",description:"Question 1",source:"@site/docs/courses/gif-7005/quiz-4.md",sourceDirName:"courses/gif-7005",slug:"/courses/gif-7005/quiz-4",permalink:"/docs/courses/gif-7005/quiz-4",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/courses/gif-7005/quiz-4.md",tags:[],version:"current",sidebarPosition:34,frontMatter:{sidebar_label:"Quiz 4 du 15 novembre 2023",sidebar_position:34,sidebar_class_name:"hidden"},sidebar:"tutorialSidebar",previous:{title:"Quiz 3 du 25 octobre 2023",permalink:"/docs/courses/gif-7005/quiz-3"},next:{title:"Examen",permalink:"/docs/courses/gif-7005/examen"}},a={},d=[{value:"Question 1",id:"question-1",level:2},{value:"Question 2",id:"question-2",level:2},{value:"Question 3",id:"question-3",level:2},{value:"Question 4",id:"question-4",level:2}];function u(e){const n={h1:"h1",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"quiz-4-du-15-novembre-2023",children:"Quiz 4 du 15 novembre 2023"}),"\n",(0,i.jsx)(n.h2,{id:"question-1",children:"Question 1"}),"\n",(0,i.jsx)(n.p,{children:"Pour chacune des propositions suivantes, s\xe9lectionnez le terme correspondant. Les choix de r\xe9ponse sont :"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"1."})," Technique qui ajuste le processus d'apprentissage du r\xe9seau en normalisant les entr\xe9es des couches afin de maintenir l'activation moyenne proche de z\xe9ro et l'\xe9cart type proche de un.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Batch normalisation"})," - Cette technique ajuste le processus d'apprentissage du r\xe9seau en normalisant les entr\xe9es des couches."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"2."})," Couches denses au sein d'un r\xe9seau neuronal o\xf9 la sortie de chaque neurone de la couche pr\xe9c\xe9dente est connect\xe9e \xe0 chaque neurone d'entr\xe9e, g\xe9n\xe9ralement utilis\xe9es pour l'int\xe9gration de mod\xe8les et la prise de d\xe9cision.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Couches pleinement connect\xe9es"})," - Il s'agit de couches denses au sein d'un r\xe9seau neuronal o\xf9 chaque neurone est connect\xe9 \xe0 tous les neurones de la couche pr\xe9c\xe9dente."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"3."})," Composants des r\xe9seaux neuronaux qui permettent \xe0 la sortie d'une couche de contourner une ou plusieurs couches suivantes en l'ajoutant \xe0 la sortie de ces couches, ce qui facilite l'apprentissage de r\xe9seaux plus profonds.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Liens r\xe9siduels"})," - Ces composants permettent \xe0 la sortie d'une couche de contourner une ou plusieurs couches suivantes."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"4."})," La pratique consistant \xe0 convertir les mots en vecteurs denses de nombres r\xe9els o\xf9 l'espace vectoriel repr\xe9sente les similarit\xe9s linguistiques bas\xe9es sur les patrons d'utilisation des mots.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Plongement lexical"})," - Cela fait r\xe9f\xe9rence \xe0 la pratique de convertir les mots en vecteurs denses repr\xe9sentant les similarit\xe9s linguistiques."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"5."})," Un paradigme d'apprentissage dans lequel une repr\xe9sentation partag\xe9e est utilis\xe9e pour apprendre simultan\xe9ment plusieurs t\xe2ches diff\xe9rentes, mais li\xe9es, afin d'am\xe9liorer les performances pour chacune d'entre elles.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Apprentissage multit\xe2che"})," - Ce paradigme utilise une repr\xe9sentation partag\xe9e pour apprendre plusieurs t\xe2ches simultan\xe9ment."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"6."})," Architectures neuronales entra\xeen\xe9es \xe0 compresser l'entr\xe9e en un code condens\xe9, puis \xe0 la reconstruire sous sa forme originale, ce qui permet de faciliter l'apprentissage non supervis\xe9 des repr\xe9sentations de donn\xe9es.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Autoencoder"})," - Ce sont des architectures neuronales entra\xeen\xe9es pour compresser l'entr\xe9e en un code condens\xe9 puis la reconstruire."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"7."})," Un processus dans les mod\xe8les neuronaux qui attribue de l'importance \xe0 diff\xe9rentes parties des donn\xe9es trait\xe9es, permettant au mod\xe8le de se concentrer davantage sur les informations pertinentes pour la t\xe2che \xe0 accomplir.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"M\xe9canisme attention"})," - Il s'agit d'un processus qui attribue de l'importance \xe0 diff\xe9rentes parties des donn\xe9es dans les mod\xe8les neuronaux."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"8."})," Une op\xe9ration qui agr\xe8ge l'information de voisinage local d'une image de caract\xe9ristiques dans un r\xe9seau neuronal, souvent utilis\xe9e pour r\xe9duire la r\xe9solution spatiale et pour obtenir une invariance spatiale.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Pooling"})," - Cette op\xe9ration agr\xe8ge l'information de voisinage local dans un r\xe9seau neuronal, souvent utilis\xe9e pour r\xe9duire la r\xe9solution spatiale."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"9."})," Technique visant \xe0 att\xe9nuer le surapprentissage dans les r\xe9seaux neuronaux en omettant de mani\xe8re al\xe9atoire un sous-ensemble de caract\xe9ristiques ou d'activations pendant la phase d'apprentissage afin de favoriser la g\xe9n\xe9ralisation.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dropout"})," - Cette technique vise \xe0 att\xe9nuer le surapprentissage en omettant al\xe9atoirement un sous-ensemble de caract\xe9ristiques ou d'activations."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"10."})," Un ph\xe9nom\xe8ne dans I'entra\xeenement de r\xe9seaux neuronaux profonds o\xf9 les mises \xe0 jour de poids deviennent de plus en plus petites au fur et \xe0 mesure qu'elles se propagent dans le r\xe9seau, rendant I'apprentissage inefficace pour les premi\xe8res couches.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dilution du gradient"})," - Ce ph\xe9nom\xe8ne d\xe9crit la diminution progressive de l'amplitude des mises \xe0 jour de poids dans les r\xe9seaux neuronaux profonds."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"question-2",children:"Question 2"}),"\n",(0,i.jsx)(n.p,{children:"S\xe9lectionnez les \xe9nonc\xe9s parmi les suivants qui sont vrais relativement aux r\xe9seaux de neurones \xe0 convolution."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"A."})," Les fonctions de pooling permettent de transformer les donn\xe9es vers un espace de plus grande dimensionnalit\xe9","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Faux."})," Les fonctions de pooling r\xe9duisent la dimensionnalit\xe9 des donn\xe9es, pas l'inverse."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"B."})," L'application de plusieurs filtres convolutifs sur des couches successives permets la compositionalit\xe9 recherch\xe9e en apprentissage profond","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," L'application de plusieurs filtres convolutifs sur des couches successives permet la compositionnalit\xe9 en apprentissage profond."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"C."})," Les valeurs num\xe9riques des filtres convolu\xe9s sont apprises par l'algorithme r\xe9tropropagation des erreurs","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," Les valeurs num\xe9riques des filtres convolutifs sont bien apprises par l'algorithme de r\xe9tropropagation des erreurs."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"D."})," Une difficult\xe9 avec les r\xe9seaux \xe0 convolution est qu'il n'est pas possible d'en faire l'entra\xeenement sur des cartes graphiques de type GPU","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Faux."})," Les r\xe9seaux de neurones \xe0 convolution peuvent tr\xe8s bien \xeatre entra\xeen\xe9s sur des GPU, ce qui est d'ailleurs une pratique courante en raison de l'acc\xe9l\xe9ration significative du processus d'entra\xeenement."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"E."})," Les convolutions 2D permettent d'extraire des saillances (features) r\xe9pondant \xe0 certains filtres sans \xe9gard \xe0 leur position dans l'image","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," Les convolutions 2D permettent d'extraire des caract\xe9ristiques qui r\xe9pondent \xe0 certains filtres ind\xe9pendamment de leur position dans l'image, ce qui contribue \xe0 la propri\xe9t\xe9 d'invariance de position."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"F."})," Les fonctions de transfert ReLU ne sont d'aucune utilit\xe9 dans les r\xe9seaux \xe0 convolution","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Faux."})," Les fonctions de transfert ReLU sont tr\xe8s utiles dans les r\xe9seaux de neurones \xe0 convolution, car elles introduisent des non-lin\xe9arit\xe9s n\xe9cessaires \xe0 l'apprentissage de caract\xe9ristiques complexes."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"G."})," Les convolutions permettent l'apprentissage de mod\xe8les de traitements plus compacts que ceux g\xe9n\xe9ralement appris avec des r\xe9seaux pleinement connect\xe9s (tels que le perceptron multicouche)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," Les convolutions permettent effectivement d'apprendre des mod\xe8les de traitement plus compacts par rapport aux r\xe9seaux enti\xe8rement connect\xe9s, car elles utilisent un nombre r\xe9duit de param\xe8tres gr\xe2ce au partage de poids et \xe0 la localit\xe9 des connexions."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"H."})," M\xeame sans augmentation des donn\xe9es, les r\xe9seaux de neurones \xe0 convolution sont robustes \xe0 la rotation des images","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Faux."})," Sans techniques sp\xe9cifiques telles que l'augmentation des donn\xe9es, les r\xe9seaux de neurones \xe0 convolution ne sont pas intrins\xe8quement robustes \xe0 la rotation des images. Ils apprennent \xe0 reconna\xeetre des motifs dans les orientations vues pendant l'entra\xeenement."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"question-3",children:"Question 3"}),"\n",(0,i.jsx)(n.p,{children:"S\xe9lectionnez les \xe9l\xe9ments parmi les suivants qui ont \xe9t\xe9 des d\xe9veloppements importants pour l'av\xe8nement des r\xe9seaux de neurones profonds."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"A."})," L'utilisation de mod\xe8les adapt\xe9s aux donn\xe9es \xe0 traiter, pouvant bien g\xe9rer la mal\xe9diction de la dimensionnalit\xe9.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," L'utilisation de mod\xe8les adapt\xe9s aux donn\xe9es \xe0 traiter, qui g\xe8rent bien la mal\xe9diction de la dimensionnalit\xe9, a \xe9t\xe9 un \xe9l\xe9ment cl\xe9 dans le d\xe9veloppement des r\xe9seaux de neurones profonds."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"B."})," L'utilisation de cartes graphiques (GPU) pour l'entra\xeenement de r\xe9seaux profonds.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," L'utilisation de cartes graphiques (GPU) pour l'entra\xeenement des r\xe9seaux profonds a \xe9t\xe9 cruciale, car elle a permis une acc\xe9l\xe9ration significative du processus d'apprentissage."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"C."})," La simplification de r\xe9seaux profonds par des r\xe9seaux \xab ob\xe8ses \xbb (large), ayant moins de couches, mais plus de neurones par couche, permettant ainsi l'obtention d'approximateurs universels.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Faux."})," Bien que les r\xe9seaux larges (\xab ob\xe8ses \xbb) aient leur utilit\xe9, l'aspect \xab profond \xbb des r\xe9seaux de neurones, c'est-\xe0-dire l'utilisation de nombreuses couches, a \xe9t\xe9 un d\xe9veloppement majeur dans ce domaine."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"D."})," L'utilisation de la fonction d'activation ReLU (unit\xe9 lin\xe9aire rectifi\xe9e)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," L'utilisation de la fonction d'activation ReLU a \xe9t\xe9 un progr\xe8s important, car elle a aid\xe9 \xe0 r\xe9soudre le probl\xe8me de la disparition du gradient et a facilit\xe9 l'entra\xeenement de r\xe9seaux plus profonds."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"E."})," L'utilisation de repr\xe9sentation locale (ex. bas\xe9e sur le voisinage) pour un classement performant de donn\xe9es complexes.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Faux."})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"F."})," L'utilisation de dropout pour une d\xe9sactivation al\xe9atoire des poids d'un r\xe9seau \xe0 chaque pr\xe9sentation de donn\xe9es d'entra\xeenement.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vrai."})," L'utilisation du dropout, une technique de r\xe9gularisation qui d\xe9sactive al\xe9atoirement certains neurones pendant l'entra\xeenement, a aid\xe9 \xe0 pr\xe9venir le surapprentissage dans les r\xe9seaux de neurones profonds."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"question-4",children:"Question 4"}),"\n",(0,i.jsx)(n.p,{children:"Soit les sch\xe9mas ici-bas repr\xe9sentant diff\xe9rents r\xe9seaux de neurones ou composantes de r\xe9seaux. Pour chacun des r\xe9seaux nomm\xe9s par la suite, associez le sch\xe9ma le plus appropri\xe9."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"schema-reseaux_1",src:s(86).Z+"",width:"1024",height:"608"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Autoencodeur | Autoencoder : ",(0,i.jsx)(n.strong,{children:"(a)"})]}),"\n",(0,i.jsxs)(n.li,{children:["Mod\xe8le de diffusion | Diffusion model : ",(0,i.jsx)(n.strong,{children:"Aucun"})]}),"\n",(0,i.jsxs)(n.li,{children:["Long Short-Term Memory (LSTM) : ",(0,i.jsx)(n.strong,{children:"(c)"})]}),"\n",(0,i.jsxs)(n.li,{children:["Domain Adversarial Neural Network (DANN) : ",(0,i.jsx)(n.strong,{children:"Aucun"})]}),"\n",(0,i.jsxs)(n.li,{children:["DenseNet : ",(0,i.jsx)(n.strong,{children:"(f)"})]}),"\n",(0,i.jsxs)(n.li,{children:["Perceptron multicouche (PMC) | Multilayer Perceptron (MLP) : ",(0,i.jsx)(n.strong,{children:"(d)"})]}),"\n",(0,i.jsxs)(n.li,{children:["U-Net : ",(0,i.jsx)(n.strong,{children:"(b)"})]}),"\n",(0,i.jsxs)(n.li,{children:["ResNet : ",(0,i.jsx)(n.strong,{children:"(g)"})]}),"\n",(0,i.jsxs)(n.li,{children:["VGG : ",(0,i.jsx)(n.strong,{children:"Aucun"})]}),"\n",(0,i.jsxs)(n.li,{children:["R\xe9seau auto-attentif | Transformer Network : ",(0,i.jsx)(n.strong,{children:"(i)"})]}),"\n",(0,i.jsxs)(n.li,{children:["R\xe9seau g\xe9n\xe9ratif adversarial | Generative adversarial network (GAN) : ",(0,i.jsx)(n.strong,{children:"(e)"})]}),"\n",(0,i.jsxs)(n.li,{children:["AlexNet : ",(0,i.jsx)(n.strong,{children:"(h)"})]}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},86:(e,n,s)=>{s.d(n,{Z:()=>i});const i=s.p+"assets/images/schema-reseaux_1-d731719acf0c195ce28dcadd5848fc9c.png"},11151:(e,n,s)=>{s.d(n,{Z:()=>l,a:()=>o});var i=s(67294);const r={},t=i.createContext(r);function o(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);
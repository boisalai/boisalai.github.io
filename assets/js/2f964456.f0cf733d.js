"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8315],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>h});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var p=a.createContext({}),s=function(e){var n=a.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},m=function(e){var n=s(e.components);return a.createElement(p.Provider,{value:n},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},g=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),c=s(t),g=r,h=c["".concat(p,".").concat(g)]||c[g]||u[g]||l;return t?a.createElement(h,i(i({ref:n},m),{},{components:t})):a.createElement(h,i({ref:n},m))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var l=t.length,i=new Array(l);i[0]=g;var o={};for(var p in n)hasOwnProperty.call(n,p)&&(o[p]=n[p]);o.originalType=e,o[c]="string"==typeof e?e:r,i[1]=o;for(var s=2;s<l;s++)i[s]=t[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}g.displayName="MDXCreateElement"},3192:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>i,default:()=>u,frontMatter:()=>l,metadata:()=>o,toc:()=>s});var a=t(7462),r=(t(7294),t(3905));const l={},i="\ud83e\udd9c\ufe0f\ud83d\udd17 LangChain",o={unversionedId:"snippets/langchain",id:"snippets/langchain",title:"\ud83e\udd9c\ufe0f\ud83d\udd17 LangChain",description:"Hugging Face API",source:"@site/docs/snippets/langchain.md",sourceDirName:"snippets",slug:"/snippets/langchain",permalink:"/docs/snippets/langchain",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"\ud83e\udd17 Hugging Face",permalink:"/docs/snippets/hugging-face"},next:{title:"Llama",permalink:"/docs/snippets/llama"}},p={},s=[{value:"Hugging Face API",id:"hugging-face-api",level:2},{value:"Prompts",id:"prompts",level:2},{value:"Langchain with Llama2 GGML",id:"langchain-with-llama2-ggml",level:3},{value:"Agents",id:"agents",level:2}],m={toc:s},c="wrapper";function u(e){let{components:n,...t}=e;return(0,r.kt)(c,(0,a.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"\ufe0f-langchain"},"\ud83e\udd9c\ufe0f\ud83d\udd17 LangChain"),(0,r.kt)("h2",{id:"hugging-face-api"},"Hugging Face API"),(0,r.kt)("p",null,"We need a ",(0,r.kt)("a",{parentName:"p",href:"https://huggingface.co/settings/tokens"},"Hugging Face account and API key")," to use these endpoints."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import os\n\nos.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HF_API_KEY'\n")),(0,r.kt)("h2",{id:"prompts"},"Prompts"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'!pip install langchain\n!pip install huggingface_hub\n\nfrom langchain import PromptTemplate\nfrom langchain import HuggingFaceHub, LLMChain\n\ntemplate = """Question: {question}\n\nAnswer: """\nprompt = PromptTemplate(\n        template=template,\n    input_variables=[\'question\']\n)\n\n# user question\nquestion = "Which NFL team won the Super Bowl in the 2010 season?"\n\n# initialize Hub LLM\nhub_llm = HuggingFaceHub(\n        repo_id=\'google/flan-t5-xl\',\n    model_kwargs={\'temperature\':1e-10}\n)\n\n# create prompt template > LLM chain\nllm_chain = LLMChain(\n    prompt=prompt,\n    llm=hub_llm\n)\n\n# ask the user question about NFL 2010\nprint(llm_chain.run(question))\n')),(0,r.kt)("p",null,"To ask multiple questions, we can try two approaches:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Iterate through all questions using the ",(0,r.kt)("inlineCode",{parentName:"li"},"generate")," method, answering them one at a time."),(0,r.kt)("li",{parentName:"ul"},"Place all questions into a single prompt for the LLM; this will only work for more advanced LLMs.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"qs = [\n    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n    {'question': \"Who was the 12th person on the moon?\"},\n    {'question': \"How many eyes does a blade of grass have?\"}\n]\nres = llm_chain.generate(qs)\nres\n")),(0,r.kt)("h3",{id:"langchain-with-llama2-ggml"},"Langchain with Llama2 GGML"),(0,r.kt)("p",null,"This code can run on Google Colab."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'!pip install -q ctransformers langchain\n\nfrom langchain.llms import CTransformers\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nllm = CTransformers(\n        model="TheBloke/Llama-2-7B-Chat-GGML", \n        model_file=\'llama-2-7b-chat.ggmlv3.q2_K.bin\', \n        callbacks=[StreamingStdOutCallbackHandler()])\n\ntemplate = """\n[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Your answers are always brief.\n<</SYS>>\n{text}[/INST]\n"""\n\nprompt = PromptTemplate(template=template, input_variables=["text"])\n\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\nresponse = llm_chain.run("Why some days are terrible?")\n')),(0,r.kt)("h2",{id:"agents"},"Agents"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'pip install langchain\npip install wikipedia\npip install openai\npip install openai\n\nfrom langchain.agents import load_tools\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType\nfrom langchain.llms import OpenAI\n\nimport os\n\nos.environ[\'OPENAI_API_KEY\'] = str("xxxxxxxxxxxxxxxxx")\n\nllm = OpenAI(temperature=0,model_name=\'gpt-4-0314\')\n\ntools = load_tools(["wikipedia"], llm=llm)\n\nagent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)\n\nagent.run("""What is the square root of the year the founder of SpaceX and Tesla born \nand what is the name of the first company he founded?""")\n')))}u.isMDXComponent=!0}}]);
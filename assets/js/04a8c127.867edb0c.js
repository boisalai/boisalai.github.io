"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[40],{3905:(e,a,t)=>{t.d(a,{Zo:()=>s,kt:()=>d});var l=t(7294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);a&&(l=l.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,l)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function o(e,a){if(null==e)return{};var t,l,n=function(e,a){if(null==e)return{};var t,l,n={},r=Object.keys(e);for(l=0;l<r.length;l++)t=r[l],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(l=0;l<r.length;l++)t=r[l],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var m=l.createContext({}),p=function(e){var a=l.useContext(m),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},s=function(e){var a=p(e.components);return l.createElement(m.Provider,{value:a},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var a=e.children;return l.createElement(l.Fragment,{},a)}},h=l.forwardRef((function(e,a){var t=e.components,n=e.mdxType,r=e.originalType,m=e.parentName,s=o(e,["components","mdxType","originalType","parentName"]),c=p(t),h=n,d=c["".concat(m,".").concat(h)]||c[h]||u[h]||r;return t?l.createElement(d,i(i({ref:a},s),{},{components:t})):l.createElement(d,i({ref:a},s))}));function d(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var r=t.length,i=new Array(r);i[0]=h;var o={};for(var m in a)hasOwnProperty.call(a,m)&&(o[m]=a[m]);o.originalType=e,o[c]="string"==typeof e?e:n,i[1]=o;for(var p=2;p<r;p++)i[p]=t[p];return l.createElement.apply(null,i)}return l.createElement.apply(null,t)}h.displayName="MDXCreateElement"},4947:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>m,contentTitle:()=>i,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>p});var l=t(7462),n=(t(7294),t(3905));const r={sidebar_label:"Large Language Models (LLMs)",sidebar_position:2,tags:["LLM","GPT","Llama"]},i="Large Language Models (LLMs)",o={unversionedId:"references/llm",id:"references/llm",title:"Large Language Models (LLMs)",description:"Models",source:"@site/docs/references/llm.md",sourceDirName:"references",slug:"/references/llm",permalink:"/docs/references/llm",draft:!1,tags:[{label:"LLM",permalink:"/docs/tags/llm"},{label:"GPT",permalink:"/docs/tags/gpt"},{label:"Llama",permalink:"/docs/tags/llama"}],version:"current",sidebarPosition:2,frontMatter:{sidebar_label:"Large Language Models (LLMs)",sidebar_position:2,tags:["LLM","GPT","Llama"]},sidebar:"tutorialSidebar",previous:{title:"Command Line",permalink:"/docs/references/command-line"},next:{title:"SAS",permalink:"/docs/references/sas"}},m={},p=[{value:"Models",id:"models",level:2},{value:"OpenAI GPT",id:"openai-gpt",level:3},{value:"Llama",id:"llama",level:3},{value:"Falcon",id:"falcon",level:3},{value:"WizardLM",id:"wizardlm",level:3},{value:"Methods",id:"methods",level:2},{value:"Tools",id:"tools",level:2},{value:"Evaluation",id:"evaluation",level:2},{value:"Instructions",id:"instructions",level:2},{value:"Using Llama 2 on Mac M1/M2",id:"using-llama-2-on-mac-m1m2",level:3},{value:"Courses",id:"courses",level:2}],s={toc:p},c="wrapper";function u(e){let{components:a,...t}=e;return(0,n.kt)(c,(0,l.Z)({},s,t,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"large-language-models-llms"},"Large Language Models (LLMs)"),(0,n.kt)("h2",{id:"models"},"Models"),(0,n.kt)("h3",{id:"openai-gpt"},"OpenAI GPT"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://platform.openai.com/overview"},"OpenAI platform"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/models/gpt-4"},"GPT-4"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/models/gpt-3-5"},"GPT-3.5"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("inlineCode",{parentName:"li"},"gpt-3.5-turbo")," has been optimized for chat using the ",(0,n.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/api-reference/chat"},"Chat completions API"),". ")),(0,n.kt)("h3",{id:"llama"},"Llama"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2302.13971"},"LLaMA: Open and Efficient Foundation Language Models"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ai.meta.com/llama/"},"Meta AI Introducing Llama 2"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/papers/2307.09288"},"Llama 2 Research Paper"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/meta-llama"},"Llama 2 on Hugging Face"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/llama-recipes/tree/main"},"Meta Examples and recipes for Llama model"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://labs.perplexity.ai/?utm_content=first_codellama&s=u&utm_source=twitter&utm_campaign=labs"},"LLaMa Chat")," on Perplexity.",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.mosaicml.com/blog/llama2-inference"},"Introducing Llama2-70B-Chat with MosaicML Inference"),"."))),(0,n.kt)("li",{parentName:"ul"},"Code Llama",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/codellama"},"Code Llama")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/blog/codellama"},"Llama 2 learns to code"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2308.12950.pdf"},"Code Llama: Open Foundation Models for Code")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/codellama"},"Llama repository")))),(0,n.kt)("li",{parentName:"ul"},"Reddit",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.reddit.com/r/LocalLLaMA/"},"r/LocalLLaMA/")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.reddit.com/r/LocalLLaMA/wiki/models/"},"r/LocalLLaMA/wiki/models/"))))),(0,n.kt)("h3",{id:"falcon"},"Falcon"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/tiiuae/falcon-40b"},"Falcon-40B"),".")),(0,n.kt)("h3",{id:"wizardlm"},"WizardLM"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/nlpxucan/WizardLM"},"WizardLM repository"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0"},"WizardLM/WizardCoder-Python-34B-V1.0"),".")),(0,n.kt)("h2",{id:"methods"},"Methods"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Fine-Tuning"),(0,n.kt)("li",{parentName:"ul"},"Retrieval-Augmented Generation (RAG)"),(0,n.kt)("li",{parentName:"ul"},"Chain of Thought",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html"},"Language Models Perform Reasoning via Chain of Thought"),".\nThis method enables models to decompose multi-step problems into intermediate steps. "),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/2201.11903.pdf"},"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"),".")))),(0,n.kt)("h2",{id:"tools"},"Tools"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Microsoft ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/microsoft/DeepSpeed"},"DeepSpeed"),": Optimization library. "),(0,n.kt)("li",{parentName:"ul"},"OpenAI ",(0,n.kt)("a",{parentName:"li",href:"https://platform.openai.com/docs/api-reference"},"API Reference"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/ggerganov/llama.cpp"},"llama.cpp"),": Port of Facebook's LLaMA model in C/C++."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://python.langchain.com/docs/get_started/introduction.html"},"LangChain")," is a framework\nfor developing applications powered by language models. ",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/langchain-ai/langchain"},"LangChain Github"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://blog.langchain.dev/"},"LangChain Blog"),".")))),(0,n.kt)("h2",{id:"evaluation"},"Evaluation"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/BLEU"},"BLEU")," (bilingual evaluation understudy) is an algorithm for evaluating the quality of\ntext which has been machine-translated from one natural language to another.\nSee also ",(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/spaces/evaluate-metric/bleu"},"here"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/openai/evals"},"Evals")," is a framework for evaluating LLMs and LLM systems,\nand an open-source registry of benchmarks."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"},"\ud83e\udd17 Open LLM Leaderboard"),".",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/blog/evaluating-mmlu-leaderboard"},"What's going on with the Open LLM Leaderboard?"),"."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://huggingface.co/spaces/bigcode/multilingual-code-evals"},"\ud83e\udd17 Multilingual Code Models Evaluation"),"."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://www.mosaicml.com/llm-evaluation"},"Mosaic LLM Evaluation Leaderboard"),".")),(0,n.kt)("h2",{id:"instructions"},"Instructions"),(0,n.kt)("h3",{id:"using-llama-2-on-mac-m1m2"},"Using Llama 2 on Mac M1/M2"),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Created 2023-08-26. Last updated 2023-08-26.")),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"Download the original version of Llama from ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/llama"},"https://github.com/facebookresearch/llama")," and extract it to a ",(0,n.kt)("inlineCode",{parentName:"li"},"llama-main")," folder."),(0,n.kt)("li",{parentName:"ol"},"Download the cpu version from ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/krychu/llama"},"https://github.com/krychu/llama"),", extract it and replace files in the ",(0,n.kt)("inlineCode",{parentName:"li"},"llama-main")," folder."),(0,n.kt)("li",{parentName:"ol"},"Go to the ",(0,n.kt)("inlineCode",{parentName:"li"},"llama-main")," folder."),(0,n.kt)("li",{parentName:"ol"},"Follow the instructions in the ",(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/llama"},"README")," to run the ",(0,n.kt)("inlineCode",{parentName:"li"},"download.sh")," script.\n",(0,n.kt)("a",{parentName:"li",href:"https://ai.meta.com/resources/models-and-libraries/llama-downloads/"},"Request a new download link"),".\nThen run the ",(0,n.kt)("inlineCode",{parentName:"li"},"download.sh")," script, passing the URL provided when prompted to start the download. "),(0,n.kt)("li",{parentName:"ol"},"Create a virtual environment with ",(0,n.kt)("inlineCode",{parentName:"li"},"python3 -m venv env")," and activate it with ",(0,n.kt)("inlineCode",{parentName:"li"},"source env/bin/activate"),"."),(0,n.kt)("li",{parentName:"ol"},"Install the cpu version of pytorch with ",(0,n.kt)("inlineCode",{parentName:"li"},"python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"),"."),(0,n.kt)("li",{parentName:"ol"},"Install dependencies of llama with ",(0,n.kt)("inlineCode",{parentName:"li"},"python3 -m pip install -e ."),"."),(0,n.kt)("li",{parentName:"ol"},"Run ",(0,n.kt)("inlineCode",{parentName:"li"},"torchrun")," like below.")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"$ git clone https://github.com/facebookresearch/llama\n$ mv llama llama-main\n$ git clone https://github.com/krychu/llama\n$ cp -r llama/ llama-main/\n$ cd llama-main \n$ chmod u+x download.sh\n$ ./download.sh\nEnter the URL from email: https://download.llamameta.net/*?Policy=eyJTdGF0Z...\n$ python3 -m venv env\n$ source env/bin/activate\n$ python3 -m pip install torch torchvision torchaudio \\\n  --index-url https://download.pytorch.org/whl/cpu\n$ python3 -m pip install -e .\n$ torchrun --nproc_per_node 1 \\\n  example_text_completion.py \\\n  --ckpt_dir llama-2-7b/ \\\n  --tokenizer_path tokenizer.model \\\n  --max_seq_len 128 --max_batch_size 1 #(instead of 4)\n")),(0,n.kt)("p",null,"I get a failure with this message: ",(0,n.kt)("inlineCode",{parentName:"p"},"RuntimeError: Distributed package doesn't have NCCL built in")),(0,n.kt)("p",null,"People are using ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/ggerganov/llama.cpp"},"https://github.com/ggerganov/llama.cpp"),", which is a Port of Facebook's LLaMA model in C/C++."),(0,n.kt)("p",null,"Found this link ",(0,n.kt)("a",{parentName:"p",href:"https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0"},"https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0"),". Will try this."),(0,n.kt)("p",null,"Reference:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/llama"},"https://github.com/facebookresearch/llama")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/llama/issues/433#issuecomment-1650002750"},"https://github.com/facebookresearch/llama/issues/433#issuecomment-1650002750")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/krychu/llama"},"https://github.com/krychu/llama")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/aggiee/llama-v2-mps"},"https://github.com/aggiee/llama-v2-mps")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://ryandam.net/blog/2023/8/2/using-llama2/index.html"},"https://ryandam.net/blog/2023/8/2/using-llama2/index.html"))),(0,n.kt)("h2",{id:"courses"},"Courses"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Standford ",(0,n.kt)("a",{parentName:"li",href:"https://stanford-cs324.github.io/winter2022/"},"CS324 - Large Language Models"),".")))}u.isMDXComponent=!0}}]);
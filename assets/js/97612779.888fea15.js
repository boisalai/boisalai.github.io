"use strict";(self.webpackChunkmy_doc=self.webpackChunkmy_doc||[]).push([[8293],{8122:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>m});var t=l(85893),i=l(11151);const r={},a="MLX: Array framework for Apple silicon",s={id:"references/ml/mlx/mlx",title:"MLX: Array framework for Apple silicon",description:"- MLX repo",source:"@site/docs/references/ml/mlx/mlx.md",sourceDirName:"references/ml/mlx",slug:"/references/ml/mlx/",permalink:"/docs/references/ml/mlx/",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/references/ml/mlx/mlx.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Hugging Face",permalink:"/docs/references/ml/hugging-face"},next:{title:"Large Language Models (LLMs)",permalink:"/docs/references/llms/"}},o={},m=[{value:"Install MLX",id:"install-mlx",level:2},{value:"Install MLX_LM",id:"install-mlx_lm",level:2},{value:"Examples",id:"examples",level:2},{value:"Default device",id:"default-device",level:3},{value:"Matrix multiplication",id:"matrix-multiplication",level:3},{value:"Gradient checkpoint transform",id:"gradient-checkpoint-transform",level:3},{value:"Serialization",id:"serialization",level:3},{value:"LLMs",id:"llms",level:2},{value:"Code Llama",id:"code-llama",level:3},{value:"Deepseek Coder",id:"deepseek-coder",level:3},{value:"Mistral-7B-Instruct-v0.2",id:"mistral-7b-instruct-v02",level:3},{value:"Mixtral-8x7B",id:"mixtral-8x7b",level:3},{value:"Phixtral",id:"phixtral",level:3},{value:"stabilityai/stablelm-2-1_6b",id:"stabilityaistablelm-2-1_6b",level:3},{value:"GGUF support",id:"gguf-support",level:3},{value:"RAG",id:"rag",level:3},{value:"MLX Data",id:"mlx-data",level:2},{value:"See also",id:"see-also",level:2}];function c(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"mlx-array-framework-for-apple-silicon",children:"MLX: Array framework for Apple silicon"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/ml-explore/mlx",children:"MLX repo"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://ml-explore.github.io/mlx/build/html/index.html",children:"Documentation"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"install-mlx",children:"Install MLX"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python3 -m venv .env\nsource .env/bin/activate  # Linux or macOS\n# .env\\Scripts\\activate  # Windows\npython3 -m pip install --upgrade pip\npip install mlx\n"})}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://ml-explore.github.io/mlx/build/html/install.html",children:"Build and Install MLX"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:['In Visual Studio Code, open the project, select "Command Palette" from the "View" menu\n(',(0,t.jsx)(n.code,{children:"Cmd+Shift+P"})," on Mac or ",(0,t.jsx)(n.code,{children:"Ctrl+Shift+P"}),' on Windows),\nrun the "Python: Select Interpreter" command, and\nselect the Python interpreter in the virtual directory (',(0,t.jsx)(n.code,{children:".env/bin/python3.9"}),")."]}),"\n",(0,t.jsxs)(n.p,{children:["Create a ",(0,t.jsx)(n.code,{children:"main.py"})," file and this code."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:">> import mlx.core as mx\n>> a = mx.array([1, 2, 3, 4])\n>> print(a.shape)\n[4]\n"})}),"\n",(0,t.jsx)(n.p,{children:"You should see this in your terminal in Visual Studio Code."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"s01",src:l(76367).Z+"",width:"1220",height:"698"})}),"\n",(0,t.jsx)(n.h2,{id:"install-mlx_lm",children:"Install MLX_LM"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"2024-02-01"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/ml-explore/mlx-examples.git\ncd mlx-examples\ncd llms\npython3 -m venv mlx_llm_test\nsource mlx_llm_test/bin/activate\npip install mlx_lm\npip install asitop\n"})}),"\n",(0,t.jsx)(n.p,{children:"On another terminal, run this code."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd mlx-examples/llms\nsource mlx_llm_test/bin/activate\nsudo asitop\n"})}),"\n",(0,t.jsx)(n.p,{children:"Run this script."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from mlx_lm import load, generate\n\nmodel, tokenizer = load("mistralai/Mistral-7B-Instruct-v0.2")\ngenerate(model, tokenizer, prompt="write a quick sort in C++", verbose=True)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=7DQsZQzCVuE",children:"Local LLMs on Apple Mac - powered by MLX!"})," on Youtube."]}),"\n",(0,t.jsxs)(n.p,{children:["See also ",(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community",children:"MLX Community"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(n.h3,{id:"default-device",children:"Default device"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(mx.default_device())\n# Device(gpu, 0)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"matrix-multiplication",children:"Matrix multiplication"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import time\nimport mlx.core as mx\n\nstart_time = time.time()\n\ndef fun(a, b, d1, d2):\n  x = mx.matmul(a, b, stream=d1)\n  for _ in range(500):\n      b = mx.exp(b, stream=d2)\n  return x, b\n\na = mx.random.uniform(shape=(4096, 512))\nb = mx.random.uniform(shape=(512, 4))\nd1 = mx.gpu\nd2 = mx.cpu\nx, b = fun(a, b, d1, d2)\n\nend_time = time.time()\nelapsed_time = (end_time - start_time) * 1000\nprint(f"Elapsed time: {elapsed_time} ms")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"gradient-checkpoint-transform",children:"Gradient checkpoint transform"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"2024-02-01"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"@mx.checkpoint\ndef fun(x):\n    return mx.sum(mx.exp(x))\n\n# Needs less memory!\nx = mx.random.uniform(shape=(4096, 512))\ndfdx = mx.grad(fun)(x)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://github.com/ml-explore/mlx-examples/tree/main/transformer_lm",children:"here"})," for Transformer LM example with gradient checkpointing."]}),"\n",(0,t.jsx)(n.h3,{id:"serialization",children:"Serialization"}),"\n",(0,t.jsx)(n.p,{children:"Save MLX arrays."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from safetensors.mlx import save_file\nimport mlx.core as mx\nparams = {"weight": mx.array([1.0, 2.0])}\nsave_file(params, "model.safetensors")\n'})}),"\n",(0,t.jsx)(n.p,{children:"Load PyTorch tensor."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'f = safe_open("model.safetensors", framework="pt")\nf.get_tensor("weight")\n# tensor([1., 2.])\n'})}),"\n",(0,t.jsx)(n.h2,{id:"llms",children:"LLMs"}),"\n",(0,t.jsx)(n.h3,{id:"code-llama",children:"Code Llama"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'pip install mlx-lm\npython -m mlx_lm.generate --model mlx-community/CodeLlama-13b-Python-4bit --prompt "write a quick sort in C++"\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from mlc_chat import ChatModule\n\ncm = ChatModule(\n    model="dist/CodeLlama-70b-Pythin-hf-q4f16_1-MLC/",\n    device="metal"\n)\n\nprompt = """\\\n# Self-attention block for Llama implementation\nclass LlamaSttentionBlock(nn.Module):\n    def __init__"""\n\noutput = cm.generate(prompt)\nprint(prompt+output)\n'})}),"\n",(0,t.jsx)(n.p,{children:"For more details:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community",children:"mlx-community"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community/CodeLlama-70b-hf-4bit-MLX",children:"mlx-community/CodeLlama-70b-hf-4bit-MLX"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community/CodeLlama-34b-Instruct-hf-4bit",children:"mlx-community/CodeLlama-34b-Instruct-hf-4bit"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community/CodeLlama-13b-Python-4bit-MLX",children:"mlx-community/CodeLlama-13b-Python-4bit-MLX"})}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"deepseek-coder",children:"Deepseek Coder"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'!pip install -U mlx-lm \n!pip install tiktoken\n\nfrom mlx_lm import load, generate\n\nmodel, tokenizer = load("mlx-community/deepseek-coder-6.7b-base-4bit-mlx")\nresponse = generate(model, tokenizer, prompt="#write a quick sort algorithm", verbose=True)\n'})}),"\n",(0,t.jsx)(n.p,{children:"The previous code should generate this output."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-txt",children:"==========\nPrompt: #write a quick sort algorithm\n\n\ndef quick_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    pivot = arr[0]\n    left = []\n    right = []\n    for i in range(1, len(arr)):\n        if arr[i] < pivot:\n            left.append(arr[i])\n        else:\n            right.append(arr[i])\n    return quick_sort(left)\n==========\nPrompt: 14.920 tokens-per-sec\nGeneration: 47.862 tokens-per-sec\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'response = generate(model, tokenizer, prompt="#write a quick sort algorithm in VBA\\Excel", verbose=True)\n'})}),"\n",(0,t.jsx)(n.p,{children:"The previous code should generate this output."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-txt",children:"==========\nPrompt: #write a quick sort algorithm in VBA\\Excel\n\n\nSub QuickSort(arr As Variant, l As Long, r As Long)\n    Dim pivot As Long\n    If l < r Then\n        pivot = Partition(arr, l, r)\n        QuickSort arr, l, pivot - 1\n        QuickSort arr, pivot + 1, r\n    End If\nEnd Sub\n\nSub Partition(arr As Variant, l As Long, r As Long)\n   \n==========\nPrompt: 11.611 tokens-per-sec\nGeneration: 48.339 tokens-per-sec\n"})}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community/deepseek-coder-6.7b-base-4bit-mlx",children:"mlx-community/deepseek-coder-6.7b-base-4bit-mlx"})," for more details."]}),"\n",(0,t.jsx)(n.h3,{id:"mistral-7b-instruct-v02",children:"Mistral-7B-Instruct-v0.2"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'pip install -U mlx\ngit clone https://github.com/ml-explore/mlx-examples.git\ncd mlx-examples/llms/hf_llm\npython generate.py --model mistralai/Mistral-7B-Instruct-v0.2 --prompt "What the dog doin?"\npython generate.py --model mlx-community/Mistral-7B-Instruct-v0.1-4bit-mlx --prompt "My name is"\npython generate.py --model mlx-community/Mistral-7B-Instruct-v0.2-4bit-mlx --prompt "Write a rap song about on-device inference via a mac, keep it classy."\n'})}),"\n",(0,t.jsx)(n.p,{children:"You can also quantise the models and directly upload them to the Hub"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# See https://huggingface.co/mlx-community/CodeLlama-7b-Python-hf-4bit-mlx\npython convert.py --hf-path "codellama/CodeLlama-7b-Python-hf" -q --upload-name CodeLlama-7b-Python-hf-4bit-mlx\n'})}),"\n",(0,t.jsx)(n.h3,{id:"mixtral-8x7b",children:"Mixtral-8x7B"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'!pip install -U mlx-lm \n!pip install tiktoken\n\nfrom mlx_lm import load, generate\n\nmodel, tokenizer = load("mlx-community/Mixtral-8x7B-v0.1-hf-4bit-mlx")\nresponse = generate(model, tokenizer, prompt="hello", verbose=True)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community/Mixtral-8x7B-v0.1-hf-4bit-mlx",children:"mlx-community/Mixtral-8x7B-v0.1-hf-4bit-mlx"})," for more details."]}),"\n",(0,t.jsx)(n.h3,{id:"phixtral",children:"Phixtral"}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://github.com/ml-explore/mlx-examples/tree/main/llms/phixtral",children:"llms/phixtral"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"stabilityaistablelm-2-1_6b",children:"stabilityai/stablelm-2-1_6b"}),"\n",(0,t.jsxs)(n.p,{children:["This code use the ",(0,t.jsx)(n.a,{href:"https://pypi.org/project/mlx-lm/",children:(0,t.jsx)(n.code,{children:"mlx-lm"})})," package, LLMs on Apple silicon with MLX and the Hugging Face Hub."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'!pip install -U mlx-lm \n!pip install tiktoken\n\nfrom mlx_lm import load, generate\n\nmodel, tokenizer = load("mlx-community/stablelm-2-zephyr-1_6b-4bit")\nresponse = generate(model, tokenizer, prompt="hello", verbose=True)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["See this ",(0,t.jsx)(n.a,{href:"https://huggingface.co/mlx-community/stablelm-2-zephyr-1_6b-4bit",children:"page"})," for more details."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'pip install -U mlx-lm\npython -m mlx_lm.generate \\\n--model mlx-community/stablelm-2-zephyr-1_6b \\\n--max-tokens 500 \\\n--prompt "Write a quick sort in C++" \\\n--colorize\n--trust-remote-code\n'})}),"\n",(0,t.jsxs)(n.p,{children:["See this ",(0,t.jsx)(n.a,{href:"https://x.com/awnihannun/status/1750952108168520133?s=20",children:"tweet"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'pip install -U mlx-lm\npython -m mlx_lm.generate \\\n--model mlx-community/stablelm-2-zephyr-1_6b-4bit \\\n--max-tokens 500 \\\n--prompt "Write a quick sort in C++" \\\n--colorize\n--trust-remote-code\n'})}),"\n",(0,t.jsxs)(n.p,{children:["See this ",(0,t.jsx)(n.a,{href:"https://x.com/awnihannun/status/1750986911827832992?s=20",children:"tweet"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"gguf-support",children:"GGUF support"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'pip install -U mlx\npython generate. py \\\n  --repo TheBloke/Mistral-7B-Instruct-v0.2-GGUF \\\n  --gguf mistral-7b-instruct-v0.2.Q4_0.gguf \\\n  --prompt "Write a recipe for making extremely spicy mayonnaise?"\n'})}),"\n",(0,t.jsxs)(n.p,{children:["See this ",(0,t.jsx)(n.a,{href:"https://x.com/reach_vb/status/1750628181088887020?s=20",children:"link"})," and ",(0,t.jsx)(n.a,{href:"https://github.com/ml-explore/mlx-examples/tree/main/llms/gguf_llm",children:"gguf_llm"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"rag",children:"RAG"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'git clone https://github.com/vegaluisjose/mlx-rag.git\ncd mlx-rag\npython3 -m venv .venv\nsource .venv/bin/activate\nwhich python3\n.venv/bin/python3 -m pip install --upgrade pip\npython3 -m pip install -r requirements.txt\npython3 create_vdb.py --pdf flash_attention.pdf --vdb vdb.npz\npython3 query_vdb.py --question "what is flash attention?"\n'})}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://github.com/vegaluisjose/mlx-rag/tree/main",children:"mlx-rag"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"mlx-data",children:"MLX Data"}),"\n",(0,t.jsxs)(n.p,{children:["See ",(0,t.jsx)(n.a,{href:"https://ml-explore.github.io/mlx-data/build/html/index.html",children:"mlx-data"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"see-also",children:"See also"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://towardsdatascience.com/mlx-vs-mps-vs-cuda-a-benchmark-c5737ca6efc9",children:"MLX vs MPS vs CUDA: a Benchmark"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://apeatling.com/articles/simple-guide-to-local-llm-fine-tuning-on-a-mac-with-mlx/",children:"A simple guide to local LLM fine-tuning on a Mac with MLX"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},76367:(e,n,l)=>{l.d(n,{Z:()=>t});const t=l.p+"assets/images/s01-7fdb8b185aa13f289c97f234e36ebe85.png"},11151:(e,n,l)=>{l.d(n,{Z:()=>s,a:()=>a});var t=l(67294);const i={},r=t.createContext(i);function a(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);
"use strict";(self.webpackChunkmy_doc=self.webpackChunkmy_doc||[]).push([[9544],{66634:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>m});var a=n(85893),t=n(11151);const i={sidebar_label:"Devoir 4 du 22 novembre 2023",sidebar_position:24,sidebar_class_name:"hidden"},l="Devoir 4",r={id:"courses/university/gif-7005/devoir-4",title:"Devoir 4",description:"D4Q1 - R\xe9seau de neurones \xe0 convolution",source:"@site/docs/courses/university/gif-7005/devoir-4.md",sourceDirName:"courses/university/gif-7005",slug:"/courses/university/gif-7005/devoir-4",permalink:"/docs/courses/university/gif-7005/devoir-4",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/courses/university/gif-7005/devoir-4.md",tags:[],version:"current",sidebarPosition:24,frontMatter:{sidebar_label:"Devoir 4 du 22 novembre 2023",sidebar_position:24,sidebar_class_name:"hidden"},sidebar:"tutorialSidebar",previous:{title:"Devoir 3 du 8 novembre 2023",permalink:"/docs/courses/university/gif-7005/devoir-3"},next:{title:"Devoir 5 du 8 d\xe9cembre 2023",permalink:"/docs/courses/university/gif-7005/devoir-5"}},c={},m=[{value:"D4Q1 - R\xe9seau de neurones \xe0 convolution",id:"d4q1---r\xe9seau-de-neurones-\xe0-convolution",level:2},{value:"Code pr\xe9ambule",id:"code-pr\xe9ambule",level:3},{value:"Q1A",id:"q1a",level:3},{value:"Q1B",id:"q1b",level:3},{value:"Q1C",id:"q1c",level:3},{value:"D4Q2 - Transfert de repr\xe9sentation",id:"d4q2---transfert-de-repr\xe9sentation",level:2},{value:"Code pr\xe9ambule (D4Q2)",id:"code-pr\xe9ambule-d4q2",level:3},{value:"Q2A",id:"q2a",level:3},{value:"Q2B",id:"q2b",level:3},{value:"D4Q3 - Transfert de style",id:"d4q3---transfert-de-style",level:2},{value:"Code pr\xe9ambule (D4Q3)",id:"code-pr\xe9ambule-d4q3",level:3},{value:"Q3A",id:"q3a",level:3},{value:"Q3B",id:"q3b",level:3},{value:"Pr\xe9traitement",id:"pr\xe9traitement",level:4},{value:"Post-traitement",id:"post-traitement",level:4},{value:"Objectif",id:"objectif",level:4},{value:"Q3C",id:"q3c",level:3},{value:"Q3D",id:"q3d",level:3},{value:"Q3E",id:"q3e",level:3},{value:"Q3F",id:"q3f",level:3},{value:"Q3F R\xe9ponse",id:"q3f-r\xe9ponse",level:3}];function o(e){const s={a:"a",annotation:"annotation",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mn:"mn",mo:"mo",mover:"mover",mrow:"mrow",msub:"msub",msubsup:"msubsup",msup:"msup",mtext:"mtext",ol:"ol",p:"p",path:"path",pre:"pre",semantics:"semantics",span:"span",strong:"strong",svg:"svg",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.h1,{id:"devoir-4",children:"Devoir 4"}),"\n",(0,a.jsx)(s.h2,{id:"d4q1---r\xe9seau-de-neurones-\xe0-convolution",children:"D4Q1 - R\xe9seau de neurones \xe0 convolution"}),"\n",(0,a.jsx)(s.h3,{id:"code-pr\xe9ambule",children:"Code pr\xe9ambule"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"!pip install torchvision\n"})}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"import os\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\n\nimport gzip\nimport pandas\nimport time\nimport numpy\n\nfrom IPython import display\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.optim import SGD\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models import resnet18\nimport torchvision.transforms as T\n\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (9.0, 7.0)\nfrom matplotlib import pyplot\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Retirer ce code avant de soumettre.\nimport torch\nif torch.backends.mps.is_available():\n    DEVICE = torch.device('mps')\nelif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\n\ndef create_balanced_sampler(dataset):\n    def make_weights_for_balanced_classes(images, n_classes):\n        count = [0] * n_classes\n        for item in images:\n            count[item[1]] += 1\n        weight_per_class = [0.] * n_classes\n        N = float(sum(count))\n        for i in range(n_classes):\n            weight_per_class[i] = N/float(count[i])\n        weight = [0] * len(images)\n        for idx, val in enumerate(images):\n            weight[idx] = weight_per_class[val[1]]\n        return weight\n\n    n_classes = numpy.unique(dataset.targets)\n    weights = make_weights_for_balanced_classes(dataset.data, len(n_classes))\n    weights = torch.DoubleTensor(weights)\n    sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n    return sampler\n\ndef compute_accuracy(model, dataloader, device='cpu'):\n    training_before = model.training\n    model.eval()\n    all_predictions = []\n    all_targets = []\n\n    for i_batch, batch in enumerate(dataloader):\n        images, targets = batch\n        images = images.to(device)\n        targets = targets.to(device)\n        with torch.no_grad():\n            predictions = model(images)\n        all_predictions.append(predictions.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n\n    if all_predictions[0].shape[-1] > 1:\n        predictions_numpy = numpy.concatenate(all_predictions, axis=0)\n        predictions_numpy = predictions_numpy.argmax(axis=1)\n        targets_numpy = numpy.concatenate(all_targets, axis=0)\n    else:\n        predictions_numpy = numpy.concatenate(all_predictions).squeeze(-1)\n        targets_numpy = numpy.concatenate(all_targets)\n        predictions_numpy[predictions_numpy >= 0.5] = 1.0\n        predictions_numpy[predictions_numpy < 0.5] = 0.0\n\n    if training_before:\n        model.train()\n\n    return (predictions_numpy == targets_numpy).mean()\n\n"})}),"\n",(0,a.jsxs)(s.p,{children:["Pour cette question, vous devez faire l'entra\xeenement d'un r\xe9seau de neurones sur le jeu de donn\xe9es\n",(0,a.jsx)(s.a,{href:"https://www.kaggle.com/fmena14/volcanoesvenus/",children:"Volcanoes on Venus"}),". Il s'agit d'un probl\xe8me de classification pour\nlequel nous vous fournissons une version abr\xe9g\xe9e du jeu de donn\xe9es\nd'",(0,a.jsx)(s.a,{href:"https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/volcanoes_train.pt.gz",children:"entra\xeenement"}),"\net de ",(0,a.jsx)(s.a,{href:"https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/volcanoes_test.pt.gz",children:"test"})," (attention: 120 Mo)."]}),"\n",(0,a.jsx)(s.p,{children:"Pour vous mettre en contexte, voici une synth\xe8se des trois \xe9tapes requises pour l'entra\xeenement de votre mod\xe8le\ndans un contexte de classification:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"G\xe9rer les donn\xe9es"}),": La premi\xe8re \xe9tape est la gestion des donn\xe9es. Elle se fait en deux temps. En premier, il faut\nd\xe9finir une classe (dans le sens programmation orient\xe9e objet du terme) qui s'occupe des donn\xe9es. Elle permet de\ncontr\xf4ler le chargement et l'application des transformations. Chaque fois qu'une donn\xe9e (ici une image) est demand\xe9e\npar le syst\xe8me, cette classe est appel\xe9e. Cette classe permet de faire une copie des images du disque dur vers la\nm\xe9moire vive de votre machine. Ce transfert est un moment propice pour appliquer les transformations, tout en r\xe9duisant\nle temps de d\xe9placement des donn\xe9es vers le GPU. Dans PyTorch, ceci est effectu\xe9 par une classe d\xe9nomm\xe9e ",(0,a.jsx)(s.code,{children:"Dataset"}),".\nEnsuite, il faut d\xe9finir une classe, nomm\xe9e ",(0,a.jsx)(s.code,{children:"DataLoader"})," dans PyTorch, qui contr\xf4le la fa\xe7on dont les donn\xe9es sont\ns\xe9lectionn\xe9es dans le jeu de donn\xe9es, car on doit pouvoir d\xe9cider si on veut les piger al\xe9atoirement ou dans un ordre\nparticulier. Elle permet alors de d\xe9finir la m\xe9thode d'\xe9chantillonnage et la taille des lots (batch) que l'on souhaite\nobtenir. Notez \xe9galement que PyTorch fonctionne principalement avec des\n",(0,a.jsx)(s.a,{href:"https://fr.wikipedia.org/wiki/Tenseur",children:"tenseurs"})," -- g\xe9n\xe9ralisation \xe0 plusieurs dimensions des matrices."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"D\xe9velopper le mod\xe8le"}),": La seconde \xe9tape est de d\xe9finir le mod\xe8le de r\xe9seau de neurones que l'on souhaite utiliser.\nCe r\xe9seau peut \xeatre construit et personnalis\xe9 dans une classe PyTorch, que l'on nomme ",(0,a.jsx)(s.code,{children:"VolcanoesNet"})," pour la question\ncourante. Elle permet de d\xe9finir et d'initialiser les couches du r\xe9seau dans la fonction ",(0,a.jsx)(s.code,{children:"init"}),". La fonction ",(0,a.jsx)(s.code,{children:"forward"}),"\npermet de contr\xf4ler dans quel ordre se fera l'inf\xe9rence sur les couches d\xe9finies dans ",(0,a.jsx)(s.code,{children:"init"}),". Elle permet aussi de\nvarier la forme du tenseur entre les couches, au besoin."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Entra\xeener le mod\xe8le"}),": La derni\xe8re \xe9tape est d'entra\xeener le mod\xe8le. Pour ce faire, vous devez d\xe9velopper les boucles\nd'entra\xeenement. On entra\xeene un mod\xe8le it\xe9ratif, o\xf9 une \xe9poque repr\xe9sente une boucle compl\xe8te sur toutes les donn\xe9es\nd'entra\xeenement et une batch repr\xe9sente un lot de donn\xe9es utilis\xe9es pour une inf\xe9rence, \xe9chantillonn\xe9es par le\n",(0,a.jsx)(s.code,{children:"DataLoader"}),". Pour chaque batch, les op\xe9rations d'entra\xeenement d'un r\xe9seau (remise \xe0 z\xe9ro des gradients, inf\xe9rence,\ncalcul de la perte, r\xe9tropropagation) doivent \xeatre appliqu\xe9es. La s\xe9paration du jeu de donn\xe9es en batch permet de ne\npas d\xe9passer la capacit\xe9 m\xe9moire des GPUs, comme on traite chacune d'entre elles ind\xe9pendamment. Pour chaque batch,\nles donn\xe9es sont transf\xe9r\xe9es de la m\xe9moire vive du CPU vers le GPU (et inversement \xe0 la fin de la batch) pour appliquer\nles op\xe9rations d'entra\xeenement."]}),"\n"]}),"\n",(0,a.jsx)(s.h3,{id:"q1a",children:"Q1A"}),"\n",(0,a.jsxs)(s.p,{children:["Pour commencer, vous vous familiarisez avec les donn\xe9es Volcanoes afin de pouvoir les manipuler dans l'entra\xeenement. Pour\nce faire, d\xe9finissez la classe ",(0,a.jsx)(s.code,{children:"VolcanoesDataset"}),", qui h\xe9rite de la classe abstraite ",(0,a.jsx)(s.code,{children:"torch.utils.data.Dataset"}),", et\nsurchargez les m\xe9thodes ",(0,a.jsx)(s.code,{children:"__getitem__"})," et ",(0,a.jsx)(s.code,{children:"__len__"}),", comme mentionn\xe9 dans la documentation. Ceci doit r\xe9sulter en un jeu\nde donn\xe9es utilisable par PyTorch."]}),"\n",(0,a.jsxs)(s.p,{children:["De plus, vous devez tester votre classe ",(0,a.jsx)(s.code,{children:"VolcanoesDataset"})," en affichant quatre images choisies al\xe9atoirement, dans une\nfigure unique. Indiquez la classe correspondante dans le titre de chacune des sous-figures. \xc9galement, vous devez\nrepr\xe9senter la distribution des donn\xe9es par classe du jeu d'entra\xeenement dans un histogramme."]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"class VolcanoesDataset(Dataset):\n    \"\"\"\n    Cette classe sert \xe0 d\xe9finir le dataset Volcanoes pour PyTorch\n    propos\xe9 de Francisco Mena sur kaggle : https://bit.ly/2DasPF1\n\n    Args:\n        path (str): le chemin du fichier .pt du dataset\n\n    This class is used to define the Volcanoes dataset for PyTorch\n    proposed by Francisco Mena on kaggle : https://bit.ly/2DasPF1\n\n    Args:\n        path (str): path to dataset .pt file\n    \"\"\"\n\n    def __init__(self, path):\n        super().__init__()\n        # garde les param\xe8tres en m\xe9moire / store parameters in memory\n        self.path = path\n        # charger les donn\xe9es / load data\n        with gzip.open(path, 'rb') as f:\n            self.data = torch.load(f)\n        # Pour faciliter la lecture des valeurs cibles / ease reading the targets\n        self.targets = numpy.array(list(zip(*self.data))[1])\n\n    def __getitem__(self, index):\n        # *** TODO ***\n        # Fourni l'instance \xe0 un certain indice du jeu de donn\xe9es\n        # Provide an instance of the dataset according to the index\n        image, label = self.data[index]\n        return image, label\n        # ******\n\n    def __len__(self):\n        # *** TODO ***\n        # Fournis la taille du jeu de donn\xe9es\n        # Provide the lenght of the dataset\n        return len(self.data)\n        # ******\n\n# Creation du dataset / Creating the dataset\n# train_set = VolcanoesDataset('/pax/shared/GIF-4101-7005/volcanoes_train.pt.gz')\n\n# Retirer ce code avant soumission!\nDATA_FOLDER = \"/Users/alain/workspace/Volcanoes-on-venus\"\nfile_path = os.path.join(DATA_FOLDER, 'volcanoes_train.pt.gz')\ntrain_set = VolcanoesDataset(file_path)\n\nfig, subfigs = pyplot.subplots(2, 2, tight_layout=True)\nfor subfig in subfigs.reshape(-1):\n    # *** TODO ***\n    # Affichage de quatre images al\xe9atoires\n    # Displaying four random images\n    index = numpy.random.randint(0, len(train_set))\n    image, label = train_set[index]\n    subfig.imshow(image.squeeze(), cmap='gray')\n    subfig.set_title('Classe: {}'.format(label))\n    subfig.axis('off')\n    # ******\n\nfig, subfig = pyplot.subplots()\n\n# *** TODO ***\n# Tracer histogramme de la distribution des donn\xe9es par classe de train_set\n# Plot class distribution histogram for train_set\n# Calcul des fr\xe9quences pour chaque classe\nfrequencies = {}\nfor _, label in train_set:\n    label = label.item()\n    if label not in frequencies:\n        frequencies[label] = 0\n    frequencies[label] += 1\n\n# Tracer l'histogramme pour les classes 0 et 1.\nsubfig.bar(frequencies.keys(), frequencies.values(), color=['red', 'blue'], edgecolor='black')\nsubfig.set_title('Distribution des classes dans le jeu d\u2019entra\xeenement')\nsubfig.set_xticks([0, 1])\nsubfig.set_xlabel('Classe')\nsubfig.set_ylabel('Nombre d\u2019images')\npyplot.show()\n# ******\n"})}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"output_7_0",src:n(29766).Z+"",width:"731",height:"690"})}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"output_7_1",src:n(1395).Z+"",width:"781",height:"625"})}),"\n",(0,a.jsx)(s.h3,{id:"q1b",children:"Q1B"}),"\n",(0,a.jsx)(s.p,{children:"Vous devez maintenant cr\xe9er le r\xe9seau de neurones et d\xe9finir les m\xe9thodes ainsi que les attributs n\xe9cessaires pour\nqu'il puisse \xeatre entra\xeen\xe9."}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["Commencez par initialiser les couches de votre r\xe9seau dans la m\xe9thode ",(0,a.jsx)(s.code,{children:"__init__"})," de ",(0,a.jsx)(s.code,{children:"VolcanoesNet"}),", en utilisant"]}),"\n",(0,a.jsxs)(s.li,{children:["les couches de convolution (",(0,a.jsx)(s.code,{children:"Conv2D"}),"), de normalisation (",(0,a.jsx)(s.code,{children:"BatchNorm2D"}),") et lin\xe9aire (",(0,a.jsx)(s.code,{children:"Linear"}),"), selon l'architecture suivante."]}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"Architecture",src:n(35634).Z+"",width:"885",height:"171"})}),"\n",(0,a.jsx)(s.p,{children:"L'architecture pr\xe9sent\xe9e dans l'image semble \xeatre un r\xe9seau de neurones convolutif (CNN) typique pour la classification\nd'images. Voici une description de ses composants, de gauche \xe0 droite :"}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Inputs"}),": Les donn\xe9es d'entr\xe9e qui seraient des images."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Conv2d (kernel 5)"}),": Une couche de convolution avec des filtres de taille 5x5. Le nombre de filtres n'est pas\npr\xe9cis\xe9 mais le nombre 32 \xe0 c\xf4t\xe9 peut indiquer le nombre de canaux de sortie ou de filtres."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"BatchNorm"}),": Normalisation par lots, utilis\xe9e pour normaliser les activations de la couche pr\xe9c\xe9dente, pour chaque lot."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"ReLU"}),": La fonction d'activation ReLU (Rectified Linear Unit), qui ajoute de la non-lin\xe9arit\xe9 au mod\xe8le."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Conv2d (kernel 5)"}),": Une autre couche de convolution avec des filtres de taille 5x5. Ici, 64 peut indiquer le nombre de canaux de sortie."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"BatchNorm"}),": Une autre couche de normalisation par lots."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"ReLU"}),": Une autre application de la fonction d'activation ReLU."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Conv2d (kernel 3)"}),": Une couche de convolution avec des filtres de taille 3x3, indiquant possiblement une extraction de caract\xe9ristiques plus fines."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"BatchNorm"}),": Une troisi\xe8me couche de normalisation par lots."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"ReLU"}),": Une troisi\xe8me application de la fonction d'activation ReLU."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Conv2d (kernel 3)"}),": Encore une couche de convolution avec des filtres de taille 3x3."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"BatchNorm"}),": Normalisation par lots."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"ReLU"}),": Fonction d'activation ReLU."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Average Pooling"}),": Une couche de pooling moyen qui r\xe9duit la dimension spatiale des caract\xe9ristiques en calculant la moyenne des valeurs dans chaque fen\xeatre de pooling."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Linear"}),": Une couche lin\xe9aire ou compl\xe8tement connect\xe9e qui est g\xe9n\xe9ralement utilis\xe9e pour la classification."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"Sigmoid"}),": La fonction d'activation sigmo\xefde qui est souvent utilis\xe9e pour la classification binaire."]}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"Chaque couche de convolution est suivie d'une normalisation par lots et d'une fonction d'activation ReLU, ce qui est\nune pratique courante pour am\xe9liorer la convergence pendant l'entra\xeenement et ajouter de la non-lin\xe9arit\xe9. L'architecture\nse termine par une couche de pooling moyen pour r\xe9duire la dimensionnalit\xe9 suivie d'une couche lin\xe9aire pour la\nclassification, et une fonction d'activation sigmo\xefde qui est typique pour les probl\xe8mes de classification binaire o\xf9\nl'output est la probabilit\xe9 d'appartenir \xe0 la classe 1."}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["Pour les convolutions, vous devez respecter le nombre de filtres (",(0,a.jsx)(s.em,{children:"filters"}),") et la taille des noyaux (",(0,a.jsx)(s.em,{children:"kernels"}),") de\nconvolution. Vous devez aussi, et ce pour toutes les convolutions, sp\xe9cifier un pas (",(0,a.jsx)(s.em,{children:"stride"}),") de 2. Aussi, vous devez\nretirer le biais de la convolution si cette derni\xe8re est suivie d'une couche de normalisation, car elle contient d\xe9j\xe0\nun param\xe8tre pour le biais."]}),"\n",(0,a.jsxs)(s.li,{children:["\xc9crivez les lignes de code manquantes pour d\xe9finir l'ordre d'inf\xe9rence des couches dans le r\xe9seau dans la\nm\xe9thode ",(0,a.jsx)(s.code,{children:"forward"})," de ",(0,a.jsx)(s.code,{children:"VolcanoesNet"}),". Les modules ",(0,a.jsx)(s.code,{children:"average_pooling"}),", ",(0,a.jsx)(s.code,{children:"linear"})," et ",(0,a.jsx)(s.code,{children:"sigmoid"})," sont d\xe9j\xe0 impl\xe9ment\xe9es\ndans la librairie PyTorch."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'class VolcanoesNet(nn.Module):\n    """\n    Cette classe d\xe9finit un r\xe9seau pleinement convolutionnel simple\n    permettant de classifier des images satellite de Venus.\n    This class defines a simple fully convolutional network\n    to classify satellite images from Venus.\n    """\n\n    def __init__(self):\n        super().__init__()\n        # *** TODO ***\n        # Initialiser ici les modules contenant des param\xe8tres \xe0 optimiser.\n        # Ces modules seront utilis\xe9s dans la m\xe9thode \'forward\'\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=2, padding=2, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.relu = nn.ReLU()\n\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=2, bias=False)\n        self.bn2 = nn.BatchNorm2d(64)\n\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(64)\n\n        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn4 = nn.BatchNorm2d(64)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(64, 1)\n        self.sigmoid = nn.Sigmoid()\n        # ******\n\n    def forward(self, x):\n        # *** TODO ***\n        # Effectuer l\'inf\xe9rence du r\xe9seau. L\'ordre d\'ex\xe9cution est importante.\n        # Perform network inference. The order of execution is important.\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.relu(self.bn3(self.conv3(x)))\n        x = self.relu(self.bn4(self.conv4(x)))\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)  # Le tenseur est aplati pour le connecter \xe0 la couche lin\xe9aire.\n        x = self.fc(x)\n        x = self.sigmoid(x)\n        return x\n        # ******\n'})}),"\n",(0,a.jsx)(s.h3,{id:"q1c",children:"Q1C"}),"\n",(0,a.jsx)(s.p,{children:"Il faut maintenant d\xe9velopper les outils n\xe9cessaires pour effectuer l'entra\xeenement du r\xe9seau de neurones, selon le code\nque vous avez d\xe9velopp\xe9 aux sous-questions pr\xe9c\xe9dentes. L'entra\xeenement est d\xe9fini par une boucle qui it\xe8re sur l'ensemble\ndes donn\xe9es d'entra\xeenement, chaque it\xe9ration correspondant \xe0 une \xe9poque. Pour chaque \xe9poque, il faut it\xe9rer sur tous\nles lots (batch) qu'elle contient."}),"\n",(0,a.jsx)(s.p,{children:"Pour cette question, vous devez:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"\xc9crire le code manquant pour la pr\xe9paration de l'entra\xeenement."}),"\n",(0,a.jsx)(s.li,{children:"\xc9crire le code manquant \xe0 l'int\xe9rieur de la boucle d'entra\xeenement."}),"\n",(0,a.jsx)(s.li,{children:"\xc9crire le code manquant \xe0 l'int\xe9rieur de la fonction de calcul de l'erreur et des matrices de confusion."}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"La matrice de confusion est particuli\xe8rement utile pour visualiser les performances de votre r\xe9seau. On assigne la\ndonn\xe9e \xe0 la premi\xe8re classe 0 lorsque la probabilit\xe9 en sortie est plus petite que 0,5, sinon la donn\xe9es est assign\xe9e \xe0 la deuxi\xe8me classe."}),"\n",(0,a.jsx)(s.p,{children:"\xc9galement, discutez bri\xe8vement les performances du r\xe9seau selon la matrice de confusion obtenue."}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"# Initialisation des param\xe8tres d'entra\xeenement\n# Param\xe8tres recommand\xe9s:\n# - Nombre d'epochs (nb_epoch = 10)\n# - Taux d'apprentissage (learning_rate = 0.01)\n# - Momentum (momentum = 0.9)\n# - Taille du lot (batch_size = 32)\n#\n# Initialization of training parameters\n# Recommended parameters:\n# - Number of epochs (nb_epoch = 10)\n# - Learning rate (learning_rate = 0.01)\n# - Momentum (momentum = 0.9)\n# - Batch size (batch_size = 32)\nnb_epoch = 10\nlearning_rate = 0.01\nmomentum = 0.9\nbatch_size = 32\n\n# Chargement des donn\xe9es d'entra\xeenement et de test\n# Loading training and testing set\n# train_set = VolcanoesDataset('/pax/shared/GIF-4101-7005/volcanoes_train.pt.gz')\n# test_set = VolcanoesDataset('/pax/shared/GIF-4101-7005/volcanoes_test.pt.gz')\n\n# Retirer ce code avant soumission!\nDATA_FOLDER = \"/Users/alain/workspace/Volcanoes-on-venus\"\ntrain_path = os.path.join(DATA_FOLDER, 'volcanoes_train.pt.gz')\ntest_path = os.path.join(DATA_FOLDER, 'volcanoes_test.pt.gz')\ntrain_set = VolcanoesDataset(train_path)\ntest_set = VolcanoesDataset(test_path)\n\n# Cr\xe9ation du sampler avec les classes balanc\xe9es\n# Create the sampler with balanced classes\nbalanced_train_sampler = create_balanced_sampler(train_set)\nbalanced_test_sampler = create_balanced_sampler(test_set)\n\n# Cr\xe9ation du dataloader d'entra\xeenement\n# Create training dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, sampler=balanced_train_sampler)\ntest_loader = DataLoader(test_set, batch_size=batch_size, sampler=balanced_test_sampler)\n\ndef compute_confusion_matrix(model, dataloader, device):\n\n    # *** TODO ***\n    # Mettre le model en mode \xe9valuation\n    model.eval()\n\n    # Calculer toutes les pr\xe9dictions sur le dataloader\n    # Put the model in evaluation mode\n    # Compute all predictions on the dataloader\n    all_predictions = []\n    all_targets = []\n    for i_batch, batch in enumerate(dataloader):\n        images, targets = batch\n        images = images.to(device)\n        targets = targets.to(device)\n        with torch.no_grad():\n            predictions = model(images)\n        all_predictions.append(predictions.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n\n    predictions_numpy = numpy.concatenate(all_predictions).squeeze()\n    targets_numpy = numpy.concatenate(all_targets).squeeze()\n    # ******\n\n    # *** TODO ***\n    # Assigner la classe 0 ou 1 aux pr\xe9dictions\n    # Calculer la matrice de confusion. Attention de bien avoir\n    # une matrice 2 par 2 en sortie\n    #\n    # Assign class 0 or 1 to the predictions\n    # Compute the confusion matrix. Be careful to have\n    # a 2 by 2 matrix as output.\n    predictions_numpy = (predictions_numpy >= 0.5).astype(int)\n    matrix = numpy.zeros((2, 2), dtype=int)\n    for true_label, predicted_label in zip(targets_numpy, predictions_numpy):\n        matrix[int(true_label), predicted_label] += 1\n    # ******\n\n    return matrix  # Retourner matrice de confusion / return confusion matrix\n\n# *** TODO ***\n# Instancier votre r\xe9seau VolcanoesNet dans une variable nomm\xe9e \"model\"\n# Instantiate your VolcanoesNet network in a variable named \"model\"\nmodel = VolcanoesNet()\n# ******\n\n# Transf\xe9rer le r\xe9seau sur GPU ou CPU en fonction de la variable \"DEVICE\"\n# Transfer the network to GPU or CPU depending on the \"DEVICE\" variable\nmodel.to(DEVICE)\n\n# *** TODO ***\n# Instancier une fonction d'erreur BinaryCrossEntropy\n# et la mettre dans une variable nomm\xe9e criterion\n# Instantiate an error function BinaryCrossEntropy\n# and put it in a variable named criterion\ncriterion = nn.BCELoss()\n\n# Instancier l'algorithme d'optimisation SGD\n# Ne pas oublier de lui donner les hyperparam\xe8tres\n# d'entra\xeenement : learning rate et momentum!\n# Instantiate the SGD optimization algorithm\n# Don't forget to give it the training hyperparameters:\n# learning rate and momentum!\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n\n# Mettre le r\xe9seau en mode entra\xeenement\n# Set the network in training mode\nmodel.train()\n# ******\n\n# Boucle d'entra\xeenement / Training loop\nfor i_epoch in range(nb_epoch):\n\n    start_time, train_losses = time.time(), []\n    for i_batch, batch in enumerate(train_loader):\n        images, targets = batch\n        targets = targets.type(torch.FloatTensor).unsqueeze(-1)\n\n        images = images.to(DEVICE)\n        targets = targets.to(DEVICE)\n\n        # *** TODO ***\n        # Mettre les gradients \xe0 z\xe9ro\n        # Set gradients to zero\n        optimizer.zero_grad()\n\n        # Calculer:\n        # 1. l'inf\xe9rence dans une variable \"predictions\"\n        # 2. l'erreur dans une variable \"loss\"\n        # Compute:\n        # 1. the inference in a \"predictions\" variable\n        # 2. the error in a \"loss\" variable\n        predictions = model(images)\n        loss = criterion(predictions, targets)\n\n        # R\xe9tropropager l'erreur et effectuer\n        # une \xe9tape d'optimisation\n        # Backpropagate the error and perform\n        # an optimization step\n        loss.backward()\n        optimizer.step()\n        # ******\n\n        # Accumulation du loss de la batch\n        # Accumulating batch loss\n        train_losses.append(loss.item())\n\n    print(' [-] epoch {:4}/{:}, train loss {:.6f} in {:.2f}s'.format(\n        i_epoch+1, nb_epoch, numpy.mean(train_losses), time.time()-start_time))\n\n# Affichage du score en test / Display test score\ntest_acc = compute_accuracy(model, test_loader, DEVICE)\nprint(' [-] test acc. {:.6f}%'.format(test_acc * 100))\n\n# Affichage de la matrice de confusion / Display confusion matrix\nmatrix = compute_confusion_matrix(model, test_loader, DEVICE)\nprint(matrix)\n\n# Lib\xe8re la cache sur le GPU *important sur un cluster de GPU*\n# Free GPU cache *important on a GPU cluster*\ntorch.cuda.empty_cache()\n\n# *** TODO ***\n# Entrez vos commentaires de la discussion ici.\n# Enter your discussion comments here\ndiscussion = \"\"\"\nRemarquons que les performances obtenues varient l\xe9g\xe8rement d'une ex\xe9cution \xe0 l'autre.\nMes commentaires ci-dessous reposent sur les performances obtenues suivantes...\n\"\"\"\n# ******\n\nframe = {\"Comments\":[discussion]}\ndf = pandas.DataFrame(frame)\ndisplay.display(df)\n"})}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"# *** TODO ***\n# Entrez vos commentaires de la discussion ici.\n# Enter your discussion comments here\ndiscussion = \"\"\"\nD'abord, remarquons que les performances obtenues varient l\xe9g\xe8rement d'une ex\xe9cution \xe0 l'autre.\nMes commentaires ci-dessous reposent sur les performances obtenues suivantes:\nTest acc. 69.265545%, VN=1266, FP=18, FN=1056, VP=394.\n\n- **VP=394** : Le mod\xe8le a correctement identifi\xe9 394 cas o\xf9 un volcan est pr\xe9sent (classe r\xe9elle = 1,\n  classe pr\xe9dite = 1).\n- **FP=18** : Le mod\xe8le a incorrectement identifi\xe9 18 cas comme pr\xe9sentant un volcan alors qu'en r\xe9alit\xe9,\n  il n'y en avait pas (classe r\xe9elle = 0, classe pr\xe9dite = 1).\n- **FN=1056** : Le mod\xe8le a manqu\xe9 1056 cas o\xf9 un volcan \xe9tait pr\xe9sent, les identifiant \xe0 tort comme\n  ne contenant pas de volcan (classe r\xe9elle = 1, classe pr\xe9dite = 0).\n  Le mod\xe8le a tendance \xe0 sous-estimer la pr\xe9sence de volcans.\n- **VN=1266** : Le mod\xe8le a correctement identifi\xe9 1266 cas o\xf9 aucun volcan n'\xe9tait pr\xe9sent (classe\n  r\xe9elle = 0, classe pr\xe9dite = 0).\nLe mod\xe8le est assez fiable pour identifier les cas sans volcan.\n- **Pr\xe9cision** : Le mod\xe8le semble avoir une bonne pr\xe9cision (=VP/(VP+FP)=394/(394+18)=0.96), car il\n  y a un faible nombre de faux positifs (18).\nCela indique que, lorsque le mod\xe8le pr\xe9dit la pr\xe9sence de volcan, il est g\xe9n\xe9ralement correct.\n- **Rappel** : Par contre, le rappel est probl\xe9matique (=VP/(VP+FN)=394/(394+1056)=0.27), consid\xe9rant\n  le nombre \xe9lev\xe9 de faux n\xe9gatifs (1056).\n  Le mod\xe8le ne d\xe9tecte pas beaucoup de volcans qui sont effectivement pr\xe9sents.\n- **Exactitude (Accuracy)** : L'exactitude globale du mod\xe8le est de 61.27%, ce qui peut sembler correct,\nmais ce chiffre est influenc\xe9 par le nombre \xe9lev\xe9 de faux n\xe9gatifs.\n- **Conclusion** : Un grand nombre de faux n\xe9gatifs peut indiquer que le mod\xe8le est biais\xe9 en faveur de\nla classe la plus repr\xe9sent\xe9e. Ce qui est effectivement le cas comme le montre l'histogramme produit pr\xe9c\xe9demment.\n\"\"\"\n# ******\n\nframe = {\"Comments\":[discussion]}\ndf = pandas.DataFrame(frame)\ndisplay.display(df)\n"})}),"\n",(0,a.jsx)(s.h2,{id:"d4q2---transfert-de-repr\xe9sentation",children:"D4Q2 - Transfert de repr\xe9sentation"}),"\n",(0,a.jsx)(s.h3,{id:"code-pr\xe9ambule-d4q2",children:"Code pr\xe9ambule (D4Q2)"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"import os\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\n\nimport gzip\nimport time\nimport numpy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.optim import SGD\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models import resnet18\nimport torchvision.transforms as T\nfrom tqdm import tqdm\n\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (9.0, 7.0)\nfrom matplotlib import pyplot\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Retirer ce code avant de soumettre.\nimport torch\nif torch.backends.mps.is_available():\n    DEVICE = torch.device('mps')\nelif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\n\ndef compute_accuracy(model, dataloader, device='cpu'):\n    training_before = model.training\n    model.eval()\n    all_predictions = []\n    all_targets = []\n\n    for i_batch, batch in enumerate(dataloader):\n        images, targets = batch\n        images = images.to(device)\n        targets = targets.to(device)\n        with torch.no_grad():\n            predictions = model(images)\n        all_predictions.append(predictions.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n\n    if all_predictions[0].shape[-1] > 1:\n        predictions_numpy = numpy.concatenate(all_predictions, axis=0)\n        predictions_numpy = predictions_numpy.argmax(axis=1)\n        targets_numpy = numpy.concatenate(all_targets, axis=0)\n    else:\n        predictions_numpy = numpy.concatenate(all_predictions).squeeze(-1)\n        targets_numpy = numpy.concatenate(all_targets)\n        predictions_numpy[predictions_numpy >= 0.5] = 1.0\n        predictions_numpy[predictions_numpy < 0.5] = 0.0\n\n    if training_before:\n        model.train()\n\n    return (predictions_numpy == targets_numpy).mean()\n"})}),"\n",(0,a.jsxs)(s.p,{children:["Pour cette question, vous devez programmer un cas de transfert de repr\xe9sentation permettant de r\xe9utiliser un r\xe9seau\nexistant. Un r\xe9seau ",(0,a.jsx)(s.em,{children:"ResNet-18"})," pr\xe9alablement entra\xeen\xe9 sur le jeu d'images naturelles ",(0,a.jsx)(s.em,{children:"ImageNet"})," est utilis\xe9 comme mod\xe8le\nsource. Ce r\xe9seau a \xe9t\xe9 pr\xe9entra\xeen\xe9 sur un jeu de donn\xe9es diff\xe9rent, mais de m\xeame nature, soit pour de la reconnaissance\nd'objets. L'adaptation du r\xe9seau original pour la nouvelle t\xe2che s'effectue en rempla\xe7ant la t\xeate du r\xe9seau\n(couche de sortie) pour que le r\xe9seau puisse fonctionner sur le jeu de donn\xe9es\n",(0,a.jsx)(s.a,{href:"https://www.kaggle.com/joosthazelzet/lego-brick-images",children:"Lego Brick"}),", s\xe9par\xe9 en un ensemble\nd'",(0,a.jsx)(s.a,{href:"https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-train.zip",children:"entra\xeenement"})," et\nde ",(0,a.jsx)(s.a,{href:"https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-test.zip",children:"test"})," (attention: 190 Mo au total, les\nfichiers sont directement disponibles sur PAX). Vous devriez \xeatre en mesure d'atteindre de tr\xe8s bonnes performances\nsur ce jeu en seulement une \xe9poque d'entra\xeenement."]}),"\n",(0,a.jsxs)(s.p,{children:["En bref, vous devez modifier la derni\xe8re couche pleinement connect\xe9e du r\xe9seau de neurones (couche ",(0,a.jsx)(s.code,{children:"fc"}),") afin de\nl'adapter au nombre de classes du jeu de donn\xe9es (16 classes ici). De plus, vous devez geler les autres couches du\nr\xe9seau ",(0,a.jsx)(s.em,{children:"ResNet-18"})," se trouvant avant la nouvelle couche pleinement connect\xe9e de sortie. \xc9crivez \xe9galement la ligne\nde code n\xe9cessaire \xe0 l'inf\xe9rence du r\xe9seau dans la m\xe9thode ",(0,a.jsx)(s.code,{children:"forward"}),"."]}),"\n",(0,a.jsx)(s.h3,{id:"q2a",children:"Q2A"}),"\n",(0,a.jsxs)(s.p,{children:["Changez la derni\xe8re couche pleinement connect\xe9e du r\xe9seau de neurones (couche ",(0,a.jsx)(s.code,{children:"fc"}),") afin de l'adapter au nombre de\nclasses du jeu de donn\xe9es (16 classes ici). De plus, gelez les autres couches du r\xe9seau ",(0,a.jsx)(s.em,{children:"ResNet-18"})," se trouvant\navant la nouvelle couche pleinement connect\xe9e de sortie. \xc9crivez \xe9galement la ligne de code n\xe9cessaire \xe0 l'inf\xe9rence\ndu r\xe9seau dans la m\xe9thode ",(0,a.jsx)(s.code,{children:"forward"}),"."]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"class LegoNet(nn.Module):\n\n    def __init__(self, pretrained=False):\n        super().__init__()\n\n        # Cr\xe9e le r\xe9seau de neurone pr\xe9-entra\xeen\xe9\n        # Create the pretrained neural network\n        self.model = resnet18(pretrained=pretrained, progress=False)\n\n        # R\xe9cup\xe8re le nombre de neurones avant la couche de classement\n        # Get the number of features before the classification layer\n        dim_before_fc = self.model.fc.in_features\n\n        # *** TODO ***\n        # Changer la derni\xe8re couche pleinement connect\xe9 pour avoir le bon\n        # nombre de neurones de sortie\n        # Change the last fully connected layer to have the right\n        # number of output neurons\n        self.model.fc = nn.Linear(dim_before_fc, 16)\n        # ******\n\n        if pretrained:\n            # *** TODO ***\n            # Geler les param\xe8tres qui ne font pas partie de la derni\xe8re couche fc\n            # Conseil: utiliser l'it\xe9rateur named_parameters() et la variable requires_grad\n            # Freeze parameters that are not part of the last fc layer\n            # Tip: use named_parameters() iterator and requires_grad variable\n            for name, parameter in self.model.named_parameters():\n                if name not in ['fc.weight', 'fc.bias']:\n                    parameter.requires_grad = False\n            # ******\n\n    def forward(self, x):\n        # *** TODO ***\n        # Appeler la fonction forward du r\xe9seau pr\xe9entra\xeen\xe9 (resnet18) de LegoNet\n        # Call the forward function of the pre-trained network (resnet18) of LegoNet\n        return self.model(x)\n        # ******\n"})}),"\n",(0,a.jsx)(s.h3,{id:"q2b",children:"Q2B"}),"\n",(0,a.jsx)(s.p,{children:"\xc9crivez les lignes de code manquantes pour la pr\xe9paration de l'entra\xeenement et celles \xe0 l'int\xe9rieur de la\nboucle d'entra\xeenement selon deux modes:"}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsxs)(s.li,{children:["Entra\xeener le r\xe9seau en ex\xe9cutant le code ",(0,a.jsx)(s.strong,{children:"sans"})," pr\xe9entra\xeenement, le r\xe9seau devrait \xeatre entra\xeen\xe9 en moins de 30 minutes sur CPU (et quelques minutes sur GPU)."]}),"\n",(0,a.jsxs)(s.li,{children:["Entra\xeener le r\xe9seau en ex\xe9cutant le code ",(0,a.jsx)(s.strong,{children:"avec"})," pr\xe9entra\xeenement (",(0,a.jsx)(s.em,{children:"fine tuning"}),")."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"def train(pretrained: bool):\n\n    # D\xe9finit les param\xe8tres d'entra\xeenement\n    # Nous vous conseillons ces param\xe8tres, mais vous pouvez les changer\n    # Defines the training parameters\n    # We recommend these settings, but you can change them\n    nb_epoch = 1\n    learning_rate = 0.01\n    momentum = 0.9\n    batch_size = 64\n\n    # D\xe9finit les transformations n\xe9cessaires pour le chargement du jeu de donn\xe9es\n    # Defines the transformations needed to load the dataset\n    totensor = T.ToTensor()\n    normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225])\n    composition = T.Compose([totensor, normalize])\n\n    # Charge le dataset d'entra\xeenement\n    # Load the training dataset\n    # train_set = ImageFolder('/pax/shared/GIF-4101-7005/lego-train', transform=composition)\n\n    # Selectionne 10% du jeu de test al\xe9atoirement pour all\xe9ger le calcul\n    # Select 10% of the test set randomly to simplify the calculation\n    # test_set = ImageFolder('/pax/shared/GIF-4101-7005/lego-test', transform=composition)\n\n    train_set = ImageFolder(\"/Users/alain/workspace/lego-brick-images/lego-train\", transform=composition)\n    test_set = ImageFolder(\"/Users/alain/workspace/lego-brick-images/lego-test\", transform=composition)\n\n    idx = numpy.random.randint(0, len(test_set), int(0.1 * len(test_set)))\n    test_set.samples = [test_set.samples[i] for i in idx]\n\n    # *** TODO ***\n    # Cr\xe9er les dataloader PyTorch avec la classe DataLoader\n    # Create PyTorch dataloaders with the DataLoader class\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n\n    # Instancier un r\xe9seau LegoNet dans une variable nomm\xe9e \"model\"\n    # Instantiate a LegoNet network in a variable named \"model\n    model = LegoNet(pretrained=pretrained)\n    # ******\n\n    # Place le r\xe9seau au bon endroit, variable DEVICE d\xe9finit si cuda est utilis\xe9 ou non\n    # Places the network in the right place, variable DEVICE defines if cuda is used or not\n    model.to(DEVICE)\n\n    # *** TODO ***\n    # Instancier une fonction d'erreur CrossEntropyLoss et\n    # la mettre dans une variable nomm\xe9e criterion\n    # Instantiate a CrossEntropyLoss error function and\n    # put it in a variable named criterion\n    criterion = nn.CrossEntropyLoss()\n\n    # Instancier l'algorithme d'optimisation SGD\n    # Conseil: Filtrez les param\xe8tres non-gel\xe9s!\n    # Ne pas oublier de lui donner les hyperparam\xe8tres d'entra\xeenement :\n    # learning rate et momentum!\n    # Instantiate the SGD optimization algorithm\n    # Tip: Filter out unfrozen parameters!\n    # Don't forget to give it the training hyperparameters :\n    # learning rate and momentum!\n    if pretrained:\n        # Si le mod\xe8le est pr\xe9entrain\xe9, optimiser que la derni\xe8re couche `fc`.\n        optimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, momentum=momentum)\n    else:\n        # Si le mod\xe8le n'est pas pr\xe9entrain\xe9, optimiser tous les param\xe8tres.\n        optimizer = SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n\n    # Mettre le r\xe9seau en mode entra\xeenement\n    # Set the network in training mode\n    model.train()\n    # ******\n\n    # R\xe9cup\xe8re le nombre total de batch pour une \xe9poque\n    # Retrieves the total number of batches for an epoch.\n    total_batch = len(train_loader)\n\n    for i_epoch in tqdm(range(nb_epoch)):\n        progress_dataloader = tqdm(train_loader, desc=\"Epoch {}/{}\".format(i_epoch+1, nb_epoch))\n        progress_dataloader.set_description(\"Epoch {}/{}\".format(i_epoch+1, nb_epoch))\n\n        train_losses = []\n        for batch in progress_dataloader:\n            images, targets = batch\n\n            images = images.to(DEVICE)\n            targets = targets.to(DEVICE)\n\n            # *** TODO ***\n            # Mettre les gradients \xe0 z\xe9ro\n            # Set gradients to zero\n            optimizer.zero_grad()\n\n            # Calculer:\n            # 1. l'inf\xe9rence dans une variable \"predictions\"\n            # 2. l'erreur dans une variable \"loss\"\n            # Compute:\n            # 1. the inference in a \"predictions\" variable\n            # 2. the error in a \"loss\" variable\n            predictions = model(images)\n            loss = criterion(predictions, targets)\n\n            # R\xe9tropropager l'erreur et effectuer une \xe9tape d'optimisation\n            # Backpropagate the error and perform an optimization step\n            loss.backward()\n            optimizer.step()\n            # ******\n\n            # Ajoute le loss de la batch\n            # Adds the batch loss\n            train_losses.append(loss.item())\n\n    # Affiche le score \xe0 l'\xe9cran\n    # Display score\n    test_acc = compute_accuracy(model, test_loader, DEVICE)\n    if pretrained:\n        print(' [-] pretrained test acc. {:.6f}%'.format(test_acc * 100))\n    else:\n        print(' [-] not pretrained test acc. {:.6f}%'.format(test_acc * 100))\n\n# Lib\xe8re la cache sur le GPU : *Important sur un cluster de GPU*\n# Free the cache on the GPU: *Important on a GPU cluster*\ntorch.cuda.empty_cache()\n\ntrain(False)\ntrain(True)\n"})}),"\n",(0,a.jsx)(s.h2,{id:"d4q3---transfert-de-style",children:"D4Q3 - Transfert de style"}),"\n",(0,a.jsx)(s.h3,{id:"code-pr\xe9ambule-d4q3",children:"Code pr\xe9ambule (D4Q3)"}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"import os\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\n\nimport numpy\nimport os\nimport requests\nimport time\nimport pandas\npandas.set_option('display.max_colwidth', 0)\n\nfrom IPython import display\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\n\nimport torchvision\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom tqdm import tqdm\n\nfrom PIL import Image\n\n# Constantes / Constants\nIMG_SIZE = 256\nIMAGENET_MEAN = [0.485, 0.456, 0.406] # Moyenne pour chaque canal de couleur\nIMAGENET_STD = [0.229, 0.224, 0.225]  # Std pour chaque canal de couleur\nSTYLE_IMAGE = 'style_image'\nCONTENT_IMAGE = 'content_image'\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# Retirer ce code avant de soumettre.\nimport torch\nif torch.backends.mps.is_available():\n    DEVICE = torch.device('mps')\nelif torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\n\n# Variables\nresults = {'Name':[],\n           'Shape':[],\n           'Mean':[],\n           'Std':[],\n          }\n\ndef fetch_image(file_id):\n    \"\"\"\n    Cette fonction t\xe9l\xe9charge une image que vous partagez de votre Google Drive.\n    Elle retourne l'image dans un format PIL.\n    This function downloads an image you share from your Google Drive.\n    It returns the image in a PIL format.\n    \"\"\"\n    URL = \"https://drive.google.com/uc?\"\n    session = requests.Session()\n\n    r = session.get(URL, params = { 'id' : file_id, 'alt' : 'media'}, stream = True)\n    error_msg = f'ERROR: impossible to download the image (code={r.status_code})'\n    assert(r.status_code == 200), error_msg\n\n    params = { 'id' : file_id, 'confirm' : 'download_warning' }\n    r = session.get(URL, params = params, stream = True)\n    stream = BytesIO(r.content)\n    image = Image.open(stream)\n    return image\n\n# Gram matrix\ndef gram_matrix(tensor):\n    \"\"\"\n    Calcul de la matrice de Gram pour un tenseur donn\xe9\n    Calculation of the Gram matrix for a given tensor\n    Gram Matrix: https://en.wikipedia.org/wiki/Gramian_matrix\n    \"\"\"\n\n    # Get the (B, C, H, W) of the Tensor\n    _, d, h, w = tensor.size()\n\n    # Reshape tensor to multiply the features for each channel\n    tensor = tensor.view(d, h * w)\n\n    # Calculate the Gram matrix\n    gram = torch.mm(tensor, tensor.t())\n\n    return gram\n\ndef extract_features(image, model_features, layers=None):\n    \"\"\"\n    Inf\xe8re l'image dans le mod\xe8le et extrait les features pour\n    les couches d\xe9sir\xe9es. Les couches par d\xe9faut concordent\n    avec celles du r\xe9seau VGG19 de Gatys et al. (2016).\n    Infers the image into the model and extracts the features for\n    the desired layers. The default layers are consistent with\n    those of the VGG19 network of Gatys et al. (2016).\n    \"\"\"\n    if layers is None:\n        layers = {'0': 'conv1_1',\n                  '2': 'conv1_2',\n                  '5': 'conv2_1',\n                  '7': 'conv2_2',\n                  '10': 'conv3_1',\n                  '12': 'conv3_2',\n                  '19': 'conv4_1',\n                  '21': 'conv4_2',\n                  '28': 'conv5_1',\n                  '30': 'conv5_2'}\n\n    features = {}\n    x = image\n    for layer_idx, layer in enumerate(model_features):\n        x = layer(x)\n        if str(layer_idx) in layers:\n            features[layers[str(layer_idx)]] = x\n\n    return features\n"})}),"\n",(0,a.jsx)(s.p,{children:"De mani\xe8re g\xe9n\xe9rale, l'entra\xeenement des r\xe9seaux de neurones en classement implique un entra\xeenement o\xf9 on observe la\nperformance selon sa fonction de perte que l'on souhaite minimiser en validation, afin d'obtenir un mod\xe8le qui g\xe9n\xe9ralise\nbien. Le classement n'est pas le seul contexte d'apprentissage pour les r\xe9seaux de neurones, il existe plusieurs autres\nutilisations de r\xe9seaux de neurones, notamment pour permettre la g\xe9n\xe9ration d'images. Le contexte de g\xe9n\xe9ration d'images\noffre ainsi un retour visuel qui permet de donner une appr\xe9ciation qualitative du fonctionnement du syst\xe8me. Si les\nimages g\xe9n\xe9r\xe9es semblent r\xe9elles, on peut pr\xe9sumer que le mod\xe8le fonctionne bien! L'exercice suivant a alors \xe9t\xe9 con\xe7u\npour vous permettre de mieux visualiser les performances, avec un retour visuel qui devrait \xeatre \xe9vocateur."}),"\n",(0,a.jsxs)(s.p,{children:["\xc0 l'aide de PyTorch, vous allez mettre en application ce qu'on appelle le ",(0,a.jsx)(s.em,{children:"transfert de style"}),", qui est un probl\xe8me qui\nfait appel \xe0 la notion de transfert de repr\xe9sentation. \xc0 l'aide d'un r\xe9seau VGG19, on vous demande de suivre\nl'impl\xe9mentation d'un article de recherche\n",(0,a.jsx)(s.a,{href:"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf",children:"Gatys et coll., 2016"}),"\nafin de g\xe9n\xe9rer une image artistique. En utilisant un mod\xe8le fourni pr\xe9entra\xeen\xe9 sur ImageNet, nous voulons extraire le\nstyle d'une premi\xe8re image (\xe0 gauche) avec le r\xe9seau et l'appliquer sur le contenu d'une seconde image (\xe0 droite):"]}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"content_style_mona.png",src:n(94469).Z+"",width:"1672",height:"1062"})}),"\n",(0,a.jsx)(s.p,{children:"L'objectif est de cr\xe9er une image hybride qui contient \xe0 la fois le style ainsi que le contenu de deux images. Il s'agit\nd'un exercice plus visuel qui vous permettra d'am\xe9liorer votre intuition sur le fonctionnement d'un r\xe9seau de neurones\n\xe0 convolution en vous basant sur l'information d'un article scientifique. Pour vous donner une id\xe9e du r\xe9sultat, voici\nl'image hybride g\xe9n\xe9r\xe9e \xe0 partir des images pr\xe9sent\xe9es plus haut:"}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"style_transfer_mona.gif",src:n(67052).Z+"",width:"397",height:"558"})}),"\n",(0,a.jsxs)(s.p,{children:["Le r\xe9seau de neurones \xe0 convolution VGG19 est compos\xe9 de 2 groupes: les ",(0,a.jsx)(s.em,{children:"features"})," et les couches de classification.\nLe style correspond au r\xe9sultat du passage des filtres de la couche de ",(0,a.jsx)(s.em,{children:"features"})," sur l'image d'entr\xe9e, alors que le\ncontenu correspond aux valeurs des pixels de la deuxi\xe8me image."]}),"\n",(0,a.jsx)(s.h3,{id:"q3a",children:"Q3A"}),"\n",(0,a.jsx)(s.p,{children:"Le transfert de style ne demande que deux images comme jeu de donn\xe9es pour son application:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["Une image qui contient un style que vous souhaitez extraire (",(0,a.jsx)(s.code,{children:"style_image"}),");"]}),"\n",(0,a.jsxs)(s.li,{children:["Une image de contenu sur laquelle vous souhaitez appliquer le style (",(0,a.jsx)(s.code,{children:"content_image"}),")."]}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"L'objectif du r\xe9seau est d'optimiser les pixels de l'image hybride en pond\xe9rant le style et le contenu des images\nsources. Il est \xe0 noter que le r\xe9seau utilis\xe9, VGG19, doit pr\xe9alablement \xeatre entra\xeen\xe9 sur un tr\xe8s grand nombre de\ndonn\xe9es. Toutefois, puisqu'on utilise un r\xe9seau pr\xe9entra\xeen\xe9, vous n'avez pas besoin de toutes ces images pour son entra\xeenement."}),"\n",(0,a.jsxs)(s.p,{children:["La premi\xe8re \xe9tape du probl\xe8me est de t\xe9l\xe9charger vos images de style et de contenu. Avec l'aide de la fonction\n",(0,a.jsx)(s.code,{children:"fetch_image"}),", vous pouvez t\xe9l\xe9charger vos propres images \xe0 partir de votre Google Drive. Pour se faire, t\xe9l\xe9versez\nune image de style ainsi qu'une image de contenu sur votre Google Drive et partagez-les publiquement en cr\xe9ant un\nlien URL de partage. Le lien aura la forme suivante:"]}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.code,{children:"https://drive.google.com/file/d/<FILE_ID>/view?usp=sharing"})}),"\n",(0,a.jsxs)(s.p,{children:["Copiez-collez le ",(0,a.jsx)(s.code,{children:"<FILE_ID>"})," et passez-le comme cha\xeene de caract\xe8res en entr\xe9e de la fonction ",(0,a.jsx)(s.code,{children:"fetch_image('<FILE_ID>')"}),"\npour t\xe9l\xe9charger votre image dans le notebook."]}),"\n",(0,a.jsx)(s.p,{children:"Quelques exemples d'images de contenu:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.a,{href:"https://drive.google.com/file/d/11c650QrD0vP7le1EHiZ5nkjRuoUYmF6H/view?usp=sharing",children:"Great Sea Turtle"})," (",(0,a.jsx)(s.code,{children:"<FILE_ID> : 11c650QrD0vP7le1EHiZ5nkjRuoUYmF6H"}),")"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.a,{href:"https://drive.google.com/file/d/11ec7XKIPQXVq6jq0Swq96abJ3t4r6JQV/view?usp=sharing",children:"Tuebingen"})," (",(0,a.jsx)(s.code,{children:"<FILE_ID> : 11ec7XKIPQXVq6jq0Swq96abJ3t4r6JQV"}),")"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.a,{href:"https://drive.google.com/file/d/11hj6wRTK3LvfNH1H2eGZCRAFA_h-f3Ag/view?usp=sharing",children:"Grace Hopper"})," (",(0,a.jsx)(s.code,{children:"<FILE_ID> : 11hj6wRTK3LvfNH1H2eGZCRAFA_h-f3Ag"}),")"]}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"Quelques exemples d'images de style:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.a,{href:"https://drive.google.com/file/d/11lRkyOtVCSZFrYT5r44y1rYXlywOmdaU/view?usp=sharing",children:"The Great Wave off Kanagawa"})," (",(0,a.jsx)(s.code,{children:"<FILE_ID> : 11lRkyOtVCSZFrYT5r44y1rYXlywOmdaU"}),")"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.a,{href:"https://drive.google.com/file/d/11utiecLh-3JQspwfOVHowkoWOHsD4Zx5/view?usp=sharing",children:"Kadinsky"})," (",(0,a.jsx)(s.code,{children:"<FILE_ID> : 11utiecLh-3JQspwfOVHowkoWOHsD4Zx5"}),")"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.a,{href:"https://drive.google.com/file/d/11vgRvxUxwh8Q5uwaD8O9aYKO7yucm57A/view?usp=sharing",children:"Van Gogh"})," (",(0,a.jsx)(s.code,{children:"<FILE_ID> : 11vgRvxUxwh8Q5uwaD8O9aYKO7yucm57A"}),")"]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'# Avec la fonction fetch_image, t\xe9l\xe9chargez vos propres images.\n# Pour se faire, ajoutez vos images sur votre Google Drive en les\n# t\xe9l\xe9versant et partagez-les avec un lien URL. Dans ce lien,\n# vous retrouverez le <FILE_ID> qu\'il faut copier-coller dans la\n# fonction fetch_image.\n# Exemple: https://drive.google.com/file/d/<FILE_ID>/view?usp=sharing\n# With the fetch_image function, upload your own images.\n# To do so, add your images to your Google Drive by\n# uploading them and share them with a URL link. In this link,\n# you will find the <FILE_ID> that you need to copy and paste into the\n# function fetch_image.\n# Example: https://drive.google.com/file/d/<FILE_ID>/view?usp=sharing\n\n# *** TODO ***\n# T\xe9l\xe9charger une image contenant le style \xe0 extraire\n# Download an image containing the style to extract\nstyle_image_file_id = "1zrY2R7tniKzX4XXgg9IxWb-9-sGtm5Sl"\n# ******\nstyle_image = fetch_image(style_image_file_id)\n\n# *** TODO **\n# T\xe9l\xe9charger une image sur laquelle appliquer le style\n# Download an image on which to apply the style\ncontent_image_file_id = "1PqHZ1Qu0zjHYDqqJmpBdyhFiZhiTT84m"\n# ******\ncontent_image = fetch_image(content_image_file_id)\n\nimages = {STYLE_IMAGE:style_image,\n          CONTENT_IMAGE:content_image}\n\n# Afficher les 2 images c\xf4te-\xe0-c\xf4te\n# Display the 2 images side by side\nplt.figure(figsize=(15,15))\n\n# Affichage du style_image\n# Displaying the image_style\nplt.subplot(1, 2, 1)\nplt.imshow(images[STYLE_IMAGE])\n\n# Affichage du content_image\n# Displaying the content_image\nplt.subplot(1, 2, 2)\nplt.imshow(images[CONTENT_IMAGE])\n'})}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"output_28_1",src:n(94468).Z+"",width:"1232",height:"577"})}),"\n",(0,a.jsx)(s.h3,{id:"q3b",children:"Q3B"}),"\n",(0,a.jsx)(s.h4,{id:"pr\xe9traitement",children:"Pr\xe9traitement"}),"\n",(0,a.jsx)(s.p,{children:"Le pr\xe9traitement des images est n\xe9cessaire pour s'assurer que celles-ci aient les m\xeames caract\xe9ristiques (taille,\nintensit\xe9 moyenne, etc.) que celles des images utilis\xe9es pour l'entra\xeenement. Il est \xe9galement utilis\xe9 pour faire de\nl'augmentation de jeu de donn\xe9es, en ajoutant de la diversit\xe9 dans le jeu d'entra\xeenement pour augmenter le nombre\nd'images disponibles. Dans le cas du transfert de style, on l'utilise pour que les images respectent la m\xeame distribution\nque pour l'entra\xeenement du r\xe9seau VGG19 utilis\xe9."}),"\n",(0,a.jsxs)(s.p,{children:["Puisqu'un r\xe9seau pr\xe9entra\xeen\xe9 est utilis\xe9 pour le transfert de style, il est important d'appliquer les m\xeames param\xe8tres\nde normalisation que ceux utilis\xe9s pour l'entra\xeenement. Le CNN ayant \xe9t\xe9 entra\xeen\xe9 sur ImageNet, on applique les m\xeames\nparam\xe8tres que dans la ",(0,a.jsx)(s.a,{href:"https://pytorch.org/vision/stable/models.html",children:"documentation"}),". Il est \xe0 noter que ces param\xe8tres\nrepr\xe9sentent la moyenne et la d\xe9viation standard pour chaque canal de l'image. Une image standard de type RGB dispose de\n3 canaux (Red, Green, Blue)."]}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"ImageNet_mean = [0.485, 0.456, 0.406]"}),"\n",(0,a.jsx)(s.li,{children:"ImageNet_std = [0.229, 0.224, 0.225]"}),"\n"]}),"\n",(0,a.jsx)(s.h4,{id:"post-traitement",children:"Post-traitement"}),"\n",(0,a.jsx)(s.p,{children:"Le post-traitement est n\xe9cessaire pour s'assurer que les images qui sont g\xe9n\xe9r\xe9es par le r\xe9seau de neurones respectent\nles propri\xe9t\xe9s naturelles d'une image r\xe9elle pour pouvoir \xeatre affich\xe9es avec Matplotlib. Une image standard de type\nRGB contient trois canaux de couleurs qui sont compos\xe9s de pixels. L'intensit\xe9 de la couleur de chacun des pixels se\ntrouve dans une plage [0,1]. Toutefois, rien ne garantit que les pixels inf\xe9r\xe9s par le r\xe9seau de neurones respecteront\ncette plage. En effet, comme le r\xe9seau VGG19 fait usage de la fonction d'activation sigmo\xefde, les pixels en sortie sont\ncontenus entre [-1,1] et doivent donc \xeatre ramen\xe9s entre [0,1]. Il va de m\xeame pour la normalisation. Comme le r\xe9seau\nVGG19 a \xe9t\xe9 pr\xe9entra\xeen\xe9 sur ImageNet avec des param\xe8tres de normalisation sp\xe9cifique \xe0 ce jeu de donn\xe9es, on normalise\nles images de style et de contenu de la m\xeame mani\xe8re en pr\xe9traitement. Toutefois, afin d'afficher l'image hybride, il\nest important de renverser la normalisation pour obtenir un r\xe9sultat visuellement int\xe9ressant."}),"\n",(0,a.jsx)(s.h4,{id:"objectif",children:"Objectif"}),"\n",(0,a.jsxs)(s.p,{children:["\xc0 partir du patron de pr\xe9traitement qui vous est donn\xe9 et de la classe maison ",(0,a.jsx)(s.code,{children:"AddDimension"})," qui vous permet d'ajouter\nune dimension, vous devez impl\xe9menter les transformations inverses (post-traitement) afin d'annuler les transformations\nqui ont \xe9t\xe9 faites en amont de l'optimisation. Pour se faire, vous devez impl\xe9menter les modules de transformations\nsuivants:"]}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"RemoveDimension"}),": Retirer la dimension B de la ",(0,a.jsx)(s.code,{children:"batch_size"})," (taille de lot). On veut que le format passe de"]}),"\n",(0,a.jsxs)(s.li,{children:["(B,C,H,W) -> (C,H,W). Utilisez la fonction PyTorch ",(0,a.jsx)(s.code,{children:"squeeze"}),"."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"DeNormalize"}),": Retirer la normalisation en appliquant son inverse sur les valeurs des pixels de l'image. On\nveut annuler l'effet de ",(0,a.jsx)(s.em,{children:"ImageNet_mean"})," (\xe9gal \xe0 [0.485, 0.456, 0.406]) et de ",(0,a.jsx)(s.em,{children:"ImageNet_std"})," (\xe9gal \xe0 [0.229, 0.224, 0.225]).\nVous devez faire les manipulations manuellement."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"Clamp"}),": Fixer les valeurs des pixels de l'image dans les bornes [0,1]. Utilisez la fonction PyTorch ",(0,a.jsx)(s.code,{children:"clamp"}),"."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"Permute"}),": Faire une permutation de l'ordre des dimensions pour permettre \xe0 la librairie Matplotlib de lire l'image."]}),"\n",(0,a.jsxs)(s.li,{children:["On veut que le format passe de (C,H,W) -> (H,W,C). Utilisez la fonction PyTorch ",(0,a.jsx)(s.code,{children:"permute"}),"."]}),"\n"]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"# Classe de transformation Custom pour ajouter un channel \xe0 la position \"dim\".\n# Cette classe vous est donn\xe9e comme exemple pour l'impl\xe9mentation des autres transformations.\n# Custom transformation class to add a channel at the \"dim\" position.\n# This class is given as an example for the implementation of other transformations.\nclass AddDimension(object):\n    def __init__(self, dim):\n        self.dim = dim\n\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C,H,W).\n\n        Returns:\n            tensor (Tensor): Tensor image with an added channel, now of size (1,C,H,W).\n        \"\"\"\n\n        new_x = x.unsqueeze(self.dim)\n        return new_x\n\n# \xc9tapes de pr\xe9traitement\n# 1. Redimensionner l'images \xe0 la taille d\xe9sir\xe9e -> (3, 256, 256)\n# 2. Transformer l'image PIL en tenseur\n# 3. Appliquer la normalisation ImageNet\n# 4. Ajouter une dimension pour PyTorch (C,H,W) -> (B,C,H,W)\n#    o\xf9 B est la taille de batch (lot).\n#\n# Preprocessing steps\n# Resize the image to the desired size -> (3, 256, 256)\n# 2. Transform the PIL image into a tensor\n# 3. Apply ImageNet normalization\n# 4. Add a dimension for PyTorch (C,H,W) -> (B,C,H,W)\n# where B is the batch size.\npreprocessing = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize(mean=IMAGENET_MEAN,\n                                                         std=IMAGENET_STD),\n                                    AddDimension(0),\n                                   ])\n\n# Puisque PyTorch travaille sur des lots (batch)\n# d'images, une dimension suppl\xe9mentaire (B) est\n# ajout\xe9e pour son fonctionnement. L'image en entr\xe9e\n# passe donc de la taille (3, 256, 256) \xe0 la taille\n# (B, 3, 256, 256) o\xf9 B, ici, est de taille 1, car il\n# n'y a qu'une seule image par lot.\n#\n# Since PyTorch works on batches of images,\n# an extra dimension (B) is added for its operation. The input\n# image goes from the size (3, 256, 256) to the size\n# (B, 3, 256, 256) where B, here, is of size 1, because\n# there is only one image per batch.\n#\n# Toutefois, afin d'afficher l'image hybride, il est important\n# de retirer cette dimension suppl\xe9mentaire, car les outils\n# d'affichage s'attendent \xe0 afficher une image unique\n# Cette prochaine classe doit donc vous permettre de\n# retirer cette dimension suppl\xe9mentaire.\n#\n# However, in order to display the hybrid image, it is important\n# to remove this extra dimension, because the display tools\n# expect to display a single image.\n# This next class should allow you to\n# remove this extra dimension.\nclass RemoveDimension(object):\n    def __init__(self, dim):\n        self.dim = dim\n\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (Tensor): Tensor image of size (1,C,H,W).\n\n        Returns:\n            new_x (Tensor): Tensor image with the removed channel, now of size (C,H,W).\n        \"\"\"\n\n        # *** TODO ***\n        # Impl\xe9mentation d'une transformation Custom\n        # pour retirer un channel \xe0 la position \"dim\"\n        # Utilisez la fonction Pytorch Squeeze()\n        # Implementation of a Custom transformation\n        # to remove a channel at the \"dim\" position\n        # Use the Pytorch Squeeze() function\n\n        new_x = x.squeeze(self.dim)  # On retire la dimension B\n        return new_x\n        # ******\n\n# Comme le r\xe9seau VGG19 a \xe9t\xe9 pr\xe9-entra\xeen\xe9 sur ImageNet\n# avec des param\xe8tres de normalisation sp\xe9cifique \xe0 ce\n# jeu de donn\xe9es, on assume qu'il sera plus performant sur\n# une nouvelle distribution d'images si celle-ci partage\n# \xe9galement cette normalisation. Ainsi, pour l'extraction\n# des features de style et de contenu, le mod\xe8le VGG19 doit\n# travailler sur des images normalis\xe9es.\n#\n# As the VGG19 network has been pre-trained on ImageNet\n# with specific normalization parameters for this dataset,\n# it is assumed that it will perform better on a new\n# image distribution if it shares this normalization. Thus, for the extraction\n# of style and content features, the VGG19 model must\n# work on normalized images.\n#\n# Toutefois, afin d'afficher l'image hybride, il est\n# important de retirer la normalisation si on\n# souhaite avoir un r\xe9sultat visuellement int\xe9ressant,\n# car la normalisation a un impact sur la distribution\n# des valeurs de pixels dans l'image. La classe suivante\n# doit vous permettre d'appliquer l'inverse de la\n# normalisation.\n#\n# However, in order to display the hybrid image, it is\n# important to remove the normalization\n# to get a visually interesting result,\n# because normalization has an impact on the distribution\n# of pixel values in the image. The following class\n# should allow you to apply the inverse of the\n# normalization.\nclass DeNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (Tensor): Tensor image of shape (C,H,W).\n        Returns:\n            new_x (Tensor): DeNormalized tensor image (C,H,W).\n        \"\"\"\n\n        # *** TODO ***\n        # Impl\xe9mentation d'une transformation Custom\n        # pour appliquer l'inverse de la normalisation.\n        # Vous devez impl\xe9menter cette fonction manuellement\n        # en utilisant des op\xe9rations sur les tenseurs.\n        #\n        # Implementation of a custom transformation\n        # to apply the inverse normalization.\n        # You must create this function manually using\n        # tensor operations.\n        mean = torch.tensor(self.mean).view(-1, 1, 1)\n        std = torch.tensor(self.std).view(-1, 1, 1)\n        new_x = x * std + mean  # Annule la normalisation\n        return new_x\n        # ******\n\n# Pour que les images s'affichent, la valeur des pixels doit\n# \xeatre retourn\xe9e entre [0,1]. La classe suivante doit vous permettre de borner\n# les valeurs des pixels de l'image hybride entre [0,1].\n#\n# For the images to be displayed, the pixel value must be between [0,1].\n# The following class should allow you to bound\n# the pixel values of the hybrid image between [0,1].\nclass Clamp(object):\n    def __init__(self, min, max):\n        self.min = float(min)\n        self.max = float(max)\n\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (Tensor): Tensor of the image.\n\n        Returns:\n            new_x (Tensor): Tensor with values clipped within [0,1].\n        \"\"\"\n\n        # *** TODO ***\n        # Impl\xe9mentation d'une transformation maison\n        # pour borner les valeurs dans la plage [0, 1]\n        # Utilisez la fonction PyTorch: Clamp()\n        #\n        # Implementation of a custom transformation\n        # to clamp the values in the range [0, 1].\n        # Use the PyTorch: Clamp() function\n        new_x = x.clamp(self.min, self.max)  # On borne les valeurs\n        return new_x\n        # ******\n\n# Pour que la librairie Matplotlib puisse afficher le\n# contenu des images, les canaux doivent \xeatre\n# donn\xe9s dans le bon ordre. PyTorch utilise les images sous\n# la forme (B,C,H,W) et Matplotlib doit recevoir les images sous\n# la forme (H,W,C). Comme le Permute est appel\xe9 apr\xe8s le\n# RemoveDimension(), vous aurez ici, en entr\xe9e, un tenseur\n# (C,H,W) que vous devez transformer dans la forme\n# d\xe9sir\xe9e pour l'affichage de Matplotlib.\n#\n# In order for the Matplotlib library to display the\n# content of the images, the channels must\n# be given in the right order. PyTorch uses images in the form\n# (B,C,H,W) and Matplotlib must receive the images under\n# the form (H,W,C). As the Permute is called after the\n# RemoveDimension(), you will have here, as input, a tensor\n# (C,H,W) that you must transform into the\n# desired form for the display of Matplotlib.\nclass Permute(object):\n    def __init__(self, dims):\n        self.dims = dims\n\n    def __call__(self, x):\n        \"\"\"\n        Args:\n            x (Tensor): Tensor of the image.\n\n        Returns:\n            new_x (Tensor): Tensor of the image with permuted dimensions.\n        \"\"\"\n\n        # *** TODO ***\n        # Impl\xe9mentation d'une transformation Custom pour\n        # faire une permutation.\n        # Utilisez la fonction PyTorch: Permute()\n        #\n        # Implementation of a custom permute tranformation.\n        # Use the function Pytorch: Permute()\n        new_x = x.permute(self.dims)  # On permute les dimensions pour Matplotlib\n        return new_x\n        # ******\n\n# *** TODO ***\n# transforms.Compose applique s\xe9quentiellement les\n# transformations. \xc9tapes de post-traitement (voir les modules pr\xe9c\xe9dents)\n# 1. Retirer la 1\xe8re dimension (B,C,H,W)->(C,H,W)\n# 2. Appliquer l'inverse de la normalisation ImageNet\n# 3. Permuter les dimension pour Matplotlib (C,H,W)->(H,W,C)\n# 4. Clamp les valeurs des tenseurs entre [0,1]\n# Vous devez ici passer les param\xe8tres d\xe9sir\xe9s dans l'appel des classes\n# de transformation.\n#\n# transforms.Compose applies sequentially the\n# transforms. Postprocessing steps (see previous modules)\n# 1. Remove the 1st dimension (B,C,H,W)->(C,H,W)\n# 2. Apply the inverse of the ImageNet normalization\n# 3. Swap dimensions for Matplotlib (C,H,W)->(H,W,C)\n# 4. Clamp the tensor values between [0,1]\n# Here you have to pass the desired parameters in the call of\n# transformation classes.\npostprocessing = transforms.Compose([RemoveDimension(dim=0),\n                                     DeNormalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n                                     Permute(dims=(1, 2, 0)),\n                                     Clamp(min=0.0, max=1.0)])\n\n# ******\n\n# Le code suivant est donn\xe9 pour permettre d'afficher\n# certaines informations utiles qui vous permettront\n# de comprendre si vos transformations post-traitement\n# sont fonctionnelles.\n#\n# The following code is given to allow you to display\n# some useful information that will allow you to\n# understand if your postprocessing transformations\n# are functional.\n\n# Afficher les statistiques des images naturelles\n# Display the statistics of natural images\nfor name, img in images.items():\n    results['Name'].append(f'raw_{name}')\n    results['Shape'].append(img.size)\n    mean = numpy.mean(img)/255\n    results['Mean'].append(mean)\n    std = numpy.std(img)/255\n    results['Std'].append(std)\n\n# Appliquer le pr\xe9traitement sur les images\n# Apply preprocessing on the images\npre_images = {}\nfor k,v in images.items():\n    pre_images[k] = preprocessing(v)\n    pre_images[k] = pre_images[k].to(DEVICE)\n\n# Afficher les statistiques des images transform\xe9es\n# Display the statistics of the transformed images\nfor name, img in pre_images.items():\n    results['Name'].append(f'pre_{name}')\n    results['Shape'].append(img.shape)\n    results['Mean'].append(img.mean().item())\n    results['Std'].append(img.std().item())\n\npost_images = {}\n\n# Appliquer le post-traitement sur les images\n# Apply postprocessing to images\nfor name,img in pre_images.items():\n    image = img.cpu().detach()\n    post_images[name] = postprocessing(image)\n\n# Afficher les statistiques des images transform\xe9es\n# Display the statistics of the transformed images\nfor name, img in post_images.items():\n    results['Name'].append(f'post_{name}')\n    results['Shape'].append(img.shape)\n    results['Mean'].append(img.mean().item())\n    results['Std'].append(img.std().item())\n\n# Affichage des r\xe9sultats\n# N.B. Bien que la taille de l'image ait \xe9t\xe9 chang\xe9e par le resize,\n#      les valeurs de moyenne et de d\xe9viation standard devraient \xeatre\n#      tr\xe8s proches avant le pr\xe9traitement et apr\xe8s le post-traitement.\n# Displaying the results\n# N.B. Although the size of the image has been changed by the resize,\n# the mean and standard deviation values should be very close\n# before preprocessing and after postprocessing.\ndf = pandas.DataFrame(results)\ndisplay.display(df)\n"})}),"\n",(0,a.jsxs)(s.table,{children:[(0,a.jsx)(s.thead,{children:(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.th,{}),(0,a.jsx)(s.th,{children:"Name"}),(0,a.jsx)(s.th,{children:"Shape"}),(0,a.jsx)(s.th,{children:"Mean"}),(0,a.jsx)(s.th,{children:"Std"})]})}),(0,a.jsxs)(s.tbody,{children:[(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"0"}),(0,a.jsx)(s.td,{children:"raw_style_image"}),(0,a.jsx)(s.td,{children:"(1024, 1024)"}),(0,a.jsx)(s.td,{children:"0.537838"}),(0,a.jsx)(s.td,{children:"0.316222"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"1"}),(0,a.jsx)(s.td,{children:"raw_content_image"}),(0,a.jsx)(s.td,{children:"(1024, 679)"}),(0,a.jsx)(s.td,{children:"0.499688"}),(0,a.jsx)(s.td,{children:"0.229498"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"2"}),(0,a.jsx)(s.td,{children:"pre_style_image"}),(0,a.jsx)(s.td,{children:"(1, 3, 256, 256)"}),(0,a.jsx)(s.td,{children:"0.391451"}),(0,a.jsx)(s.td,{children:"1.303074"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"3"}),(0,a.jsx)(s.td,{children:"pre_content_image"}),(0,a.jsx)(s.td,{children:"(1, 3, 256, 256)"}),(0,a.jsx)(s.td,{children:"0.225736"}),(0,a.jsx)(s.td,{children:"0.992561"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"4"}),(0,a.jsx)(s.td,{children:"post_style_image"}),(0,a.jsx)(s.td,{children:"(256, 256, 3)"}),(0,a.jsx)(s.td,{children:"0.537964"}),(0,a.jsx)(s.td,{children:"0.301508"})]}),(0,a.jsxs)(s.tr,{children:[(0,a.jsx)(s.td,{children:"5"}),(0,a.jsx)(s.td,{children:"post_content_image"}),(0,a.jsx)(s.td,{children:"(256, 256, 3)"}),(0,a.jsx)(s.td,{children:"0.499748"}),(0,a.jsx)(s.td,{children:"0.217978"})]})]})]}),"\n",(0,a.jsx)(s.h3,{id:"q3c",children:"Q3C"}),"\n",(0,a.jsxs)(s.p,{children:["Maintenant que nous avons les donn\xe9es pour l'entra\xeenement et qu'elles sont format\xe9es et normalis\xe9es, il faut t\xe9l\xe9charger le mod\xe8le pr\xe9entra\xeen\xe9 VGG19 de la librairie PyTorch. Puisque nous n'avons pas besoin des couches de classification, seules les couches de ",(0,a.jsx)(s.em,{children:"features"})," sont stock\xe9es dans la variable ",(0,a.jsx)(s.code,{children:"vgg"}),". Pour ce faire, affichez les noms des modules et couches du mod\xe8le et ne s\xe9lectionnez que ce qui correspond aux couches de ",(0,a.jsx)(s.em,{children:"features"}),". Vous ne voulez pas conserver les couches de classification, car elles ne sont pas utiles pour la suite du probl\xe8me. Ensuite, vous devez geler les param\xe8tres du r\xe9seau, car ils ne seront pas modifi\xe9s."]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"import torchvision\nprint(torchvision.__version__)\n"})}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"# *** TODO ***\n# T\xe9l\xe9charger la portion \"features\" du VGG19\n# Nous n'avons pas besoin des couches de classification.\n# !!! Veuillez passer en param\xe8tre progress=False dans la  !!!\n# !!! fonction. Autrement, l'ex\xe9cution vous retournera une !!!\n# !!! erreur.                                              !!!\n# Geler les couches pr\xe9-entra\xeen\xe9es\n\n# Download the features portion of the VGG19\n# We don't need the classification layers.\n# !!! Please pass in the progress=False parameter in the !!!\n# !!! function. Otherwise, the execution will return an !!!\n# !!! error. !!!\n# Freeze pre-trained layers\n\n# L'utilisation du param\xe8tre 'pretrained' est d\xe9pr\xe9ci\xe9e dans la version\n# de torchvision que j'utilise (version 0.16). \xc0 la place, j'utilise le\n# param\xe8tre 'weights' pour charger un mod\xe8le pr\xe9-entra\xeen\xe9.\nfrom torchvision.models import vgg19, VGG19_Weights\n\n# T\xe9l\xe9charger la portion \"features\" du VGG19 avec les poids pr\xe9-entra\xeen\xe9s\nvgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features\n\n# Geler les couches pr\xe9-entra\xeen\xe9es\nfor param in vgg.parameters():\n    param.requires_grad = False\n# ******\n\n# Si GPU disponible, monter le mod\xe8le sur le GPU\n# If GPU available, mount the model on the GPU\nvgg.to(DEVICE)\n"})}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-txt",children:"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU(inplace=True)\n  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU(inplace=True)\n  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (6): ReLU(inplace=True)\n  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (8): ReLU(inplace=True)\n  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (11): ReLU(inplace=True)\n  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (13): ReLU(inplace=True)\n  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (15): ReLU(inplace=True)\n  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (17): ReLU(inplace=True)\n  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (20): ReLU(inplace=True)\n  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (22): ReLU(inplace=True)\n  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (24): ReLU(inplace=True)\n  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (26): ReLU(inplace=True)\n  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (29): ReLU(inplace=True)\n  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (31): ReLU(inplace=True)\n  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (33): ReLU(inplace=True)\n  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (35): ReLU(inplace=True)\n  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n)\n"})}),"\n",(0,a.jsx)(s.h3,{id:"q3d",children:"Q3D"}),"\n",(0,a.jsxs)(s.p,{children:["Afin de pouvoir d\xe9velopper les fonctions de perte (",(0,a.jsx)(s.em,{children:"loss"}),") et lancer la g\xe9n\xe9ration de l'image hybride, il faut tout\nd'abord initialiser les pond\xe9rations et calculer quelques param\xe8tres importants. Vous devez donc:"]}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsxs)(s.li,{children:["Extraire les ",(0,a.jsx)(s.em,{children:"features"})," de l'image de style avec la fonction ",(0,a.jsx)(s.code,{children:"extract_features"}),";"]}),"\n",(0,a.jsxs)(s.li,{children:["Extraire les ",(0,a.jsx)(s.em,{children:"features"})," de l'image de contenu avec la fonction ",(0,a.jsx)(s.code,{children:"extract_features"}),";"]}),"\n",(0,a.jsx)(s.li,{children:"Cr\xe9er une copie de l'image de contenu (appel\xe9e image cible) pour permettre de l'ajuster it\xe9rativement tout en\ngardant une copie du contenu original."}),"\n"]}),"\n",(0,a.jsxs)(s.p,{children:["\xc9galement, vous \xeates invit\xe9s \xe0 ajuster les pond\xe9rations et les param\xe8tres ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," et ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]})," pour rendre votre rendu le\nplus \xe0 votre go\xfbt possible. Notez bien que vous n'\xeates pas \xe9valu\xe9 sur la qualit\xe9 du rendu, mais on vous encourage\nfortement \xe0 tester d'autres configurations de param\xe8tres pour bien en comprendre le fonctionnement."]}),"\n",(0,a.jsxs)(s.p,{children:["Dans le contexte du transfert de style en utilisant des r\xe9seaux de neurones convolutionnels, comme dans votre cas avec le\nmod\xe8le VGG19, les param\xe8tres ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," et ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]})," sont utilis\xe9s pour \xe9quilibrer les contributions respectives de la\nperte de contenu et de la perte de style dans la fonction de perte totale lors de la g\xe9n\xe9ration de l'image cible."]}),"\n",(0,a.jsx)(s.p,{children:"Dans votre code, ces param\xe8tres sont repr\xe9sent\xe9s par :"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"content_weight"})," pour ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),", qui est la pond\xe9ration de la perte de contenu."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.code,{children:"style_weight"})," pour ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]}),", qui est la pond\xe9ration de la perte de style."]}),"\n"]}),"\n",(0,a.jsxs)(s.p,{children:["La fonction de perte totale ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"L"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"L"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"})]})})]})," dans le transfert de style est souvent repr\xe9sent\xe9e comme suit :"]}),"\n",(0,a.jsx)(s.span,{className:"katex-display",children:(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsx)(s.mi,{children:"\u03b1"}),(0,a.jsx)(s.mo,{children:"\xd7"}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsx)(s.mtext,{children:"content"})]}),(0,a.jsx)(s.mo,{children:"+"}),(0,a.jsx)(s.mi,{children:"\u03b2"}),(0,a.jsx)(s.mo,{children:"\xd7"}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsx)(s.mtext,{children:"style"})]})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"L = \\alpha \\times L_{\\text{content}} + \\beta \\times L_{\\text{style}}"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6667em",verticalAlign:"-0.0833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"\xd7"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2806em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:(0,a.jsx)(s.span,{className:"mord text mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"content"})})})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"+"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"\xd7"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:(0,a.jsx)(s.span,{className:"mord text mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"style"})})})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})]})]})}),"\n",(0,a.jsxs)(s.p,{children:["o\xf9 ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsx)(s.mtext,{children:"content"})]})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"L_{\\text{content}}"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2806em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:(0,a.jsx)(s.span,{className:"mord text mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"content"})})})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})})]})," est la perte de contenu calcul\xe9e entre les features de l'image de contenu et celles de l'image\ncible, et ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsx)(s.mtext,{children:"style"})]})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"L_{\\text{style}}"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.9694em",verticalAlign:"-0.2861em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:(0,a.jsx)(s.span,{className:"mord text mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"style"})})})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})})]})," est la perte de style calcul\xe9e entre les matrices de Gram des features de l'image de style et de l'image cible."]}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["Une valeur \xe9lev\xe9e de ",(0,a.jsx)(s.code,{children:"content_weight"})," (",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),") signifie que vous voulez que l'image cible ressemble davantage \xe0 l'image de contenu en termes de caract\xe9ristiques de contenu."]}),"\n",(0,a.jsxs)(s.li,{children:["Une valeur \xe9lev\xe9e de ",(0,a.jsx)(s.code,{children:"style_weight"})," (",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]}),") signifie que vous voulez que l'image cible incorpore davantage les caract\xe9ristiques stylistiques de l'image de style."]}),"\n"]}),"\n",(0,a.jsx)(s.p,{children:"Ajuster ces param\xe8tres vous permet de contr\xf4ler l'\xe9quilibre entre le maintien du contenu original de l'image et l'adoption\ndu style de l'image de style. C'est un processus exp\xe9rimental et subjectif pour obtenir un r\xe9sultat qui correspond \xe0 votre go\xfbt personnel."}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:"# ** TODO ***\n# Extraire les features de l'image de style avec la fonction\n# extract_features.\n# Extract the features of the style image with the function\n# extract_features.\nstyle_features = extract_features(pre_images[STYLE_IMAGE], vgg)\n# ******\n\n# *** TODO ***\n# Extraire les features de l'image de content avec la fonction\n# extract_features.\n# Extract the features of the content image with the function\n# extract_features.\ncontent_features = extract_features(pre_images[CONTENT_IMAGE], vgg)\n# ******\n\n# Pr\xe9-calculer la matrice de Gram pour chaque couche de style\n# Pre-compute the Gram matrix for each style layer\nstyle_grams = {}\nfor layer in style_features:\n    style_grams[layer] = gram_matrix(style_features[layer])\n\n# *** TODO ***\n# Cr\xe9ation d'une image cible temporaire. Utilisez la fonction clone() de\n# la librairie PyTorch. N'oubliez pas le gradient! Consid\xe9rez \xe9galement le\n# device utilis\xe9 (CPU vs GPU). Il faut travailler sur une copie de\n# l'image cible pour changer son style it\xe9rativement.\n#\n# Create a temporary target image. Use the clone() function of\n# the PyTorch library. Don't forget the gradient! Also consider the\n# device used (CPU vs GPU). You have to work on a copy of the\n# the target image to change its style iteratively.\ntarget = pre_images[CONTENT_IMAGE].clone().requires_grad_(True).to(DEVICE)\n# ******\n\n# Poids appliqu\xe9s pour chaque couche de style\n# Weights applied for each style layer\n# Valeurs par d\xe9faut / default values:\n# 'conv1_1': 1.\n# 'conv2_1': 0.75\n# 'conv3_1': 0.2\n# 'conv4_1': 0.2\n# 'conv5_1': 0.2\nstyle_layers_weights = {'conv1_1': 1.,\n                        'conv2_1': 0.75,\n                        'conv3_1': 0.2,\n                        'conv4_1': 0.2,\n                        'conv5_1': 0.2}\n\n# Par d\xe9faut: content_weight = 1\n# By default: content_weight = 1\ncontent_weight = 1\n\n# Par d\xe9faut: style_weight = 1e7\n# By default: style_weight = 1e7\nstyle_weight = 1e7\n"})}),"\n",(0,a.jsx)(s.h3,{id:"q3e",children:"Q3E"}),"\n",(0,a.jsxs)(s.p,{children:["Le transfert de style, comme vous pouvez le comprendre dans l'article de\n",(0,a.jsx)(s.a,{href:"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf",children:"Gatys et coll."}),",\nne requi\xe8re pas d'entra\xeenement \xe0 proprement parler. En effet, puisqu'on utilise un r\xe9seau pr\xe9entra\xeen\xe9 et qu'on en g\xe8le\nles poids, le r\xe9seau n'apprend rien. Toutefois, les pixels de l'image cible (hybride) doivent \xeatre optimis\xe9s pour\ncontenir \xe0 la fois le ",(0,a.jsx)(s.em,{children:"style"})," ainsi que le ",(0,a.jsx)(s.em,{children:"contenu"})," d\xe9sir\xe9. On fait donc une descente de gradient avec fonction de\nperte pour minimiser la diff\xe9rence de contenu entre l'image originale et l'image g\xe9n\xe9r\xe9e, tout en int\xe9grant le nouveau style \xe0 l'image g\xe9n\xe9r\xe9e."]}),"\n",(0,a.jsxs)(s.p,{children:["Pour se faire, deux fonctions de pertes doivent \xeatre d\xe9velopp\xe9es: une qui permet de mesurer la diff\xe9rence de contenu\nentre l'image cible et l'image de contenu (",(0,a.jsx)(s.em,{children:"perte de contenu"}),") ainsi qu'une seconde qui permet de mesurer la diff\xe9rence\nde style entre la matrice Gram de l'image cible et celle de l'image de style (",(0,a.jsx)(s.em,{children:"perte de style"}),"). La somme pond\xe9r\xe9e de\nces deux fonctions permet de g\xe9n\xe9rer la ",(0,a.jsx)(s.em,{children:"perte totale"})," qui sera utilis\xe9e pour l'optimisation des pixels de l'image hybride."]}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsxs)(s.li,{children:["Impl\xe9menter la fonction ",(0,a.jsx)(s.code,{children:"calculate_content_loss"})," qui prend en param\xe8tre le nom de la couche ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"l"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"l"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"l"})]})})]})," \xe0 \xe9valuer et qui"]}),"\n",(0,a.jsxs)(s.li,{children:["retourne la perte de contenu entre les param\xe8tres de l'image cible (",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"F"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"F"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"F"})]})})]}),") et les param\xe8tres de l'image de contenu"]}),"\n",(0,a.jsxs)(s.li,{children:["(",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"P"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"P"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"P"})]})})]}),"). La fonction de calcul de la perte est la suivante:"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"c"}),(0,a.jsx)(s.mi,{children:"o"}),(0,a.jsx)(s.mi,{children:"n"}),(0,a.jsx)(s.mi,{children:"t"}),(0,a.jsx)(s.mi,{children:"e"}),(0,a.jsx)(s.mi,{children:"n"}),(0,a.jsx)(s.mi,{children:"t"})]})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"p"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mi,{children:"l"}),(0,a.jsx)(s.mo,{stretchy:"false",children:")"}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsxs)(s.mfrac,{children:[(0,a.jsx)(s.mn,{children:"1"}),(0,a.jsx)(s.mn,{children:"2"})]}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mo,{children:"\u2211"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"i"}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mi,{children:"j"})]})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.msubsup,{children:[(0,a.jsx)(s.mi,{children:"F"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"i"}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mi,{children:"j"})]}),(0,a.jsx)(s.mi,{children:"l"})]}),(0,a.jsx)(s.mo,{children:"\u2212"}),(0,a.jsxs)(s.msubsup,{children:[(0,a.jsx)(s.mi,{children:"P"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"i"}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mi,{children:"j"})]}),(0,a.jsx)(s.mi,{children:"l"})]}),(0,a.jsxs)(s.msup,{children:[(0,a.jsx)(s.mo,{stretchy:"false",children:")"}),(0,a.jsx)(s.mn,{children:"2"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"L_{content}(\\vec{p},\\vec{x},l) = \\frac{1}{2}\\sum_{i,j}(F_{i,j}^l - P_{i,j}^l)^2,"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2806em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"co"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"n"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"e"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"n"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"})]})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"p"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.1522em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.1944em"},children:(0,a.jsx)(s.span,{})})})]})}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2077em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"l"}),(0,a.jsx)(s.span,{className:"mclose",children:")"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1.2849em",verticalAlign:"-0.4358em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mopen nulldelimiter"}),(0,a.jsx)(s.span,{className:"mfrac",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8451em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.655em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"2"})})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.23em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,a.jsxs)(s.span,{style:{top:"-3.394em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"1"})})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.345em"},children:(0,a.jsx)(s.span,{})})})]})}),(0,a.jsx)(s.span,{className:"mclose nulldelimiter"})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(s.span,{className:"mop",children:[(0,a.jsx)(s.span,{className:"mop op-symbol small-op",style:{position:"relative",top:"0em"},children:"\u2211"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.162em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.4003em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"}),(0,a.jsx)(s.span,{className:"mpunct mtight",children:","}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.05724em"},children:"j"})]})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.4358em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"F"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8491em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.4413em",marginLeft:"-0.1389em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"}),(0,a.jsx)(s.span,{className:"mpunct mtight",children:","}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.05724em"},children:"j"})]})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3948em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"\u2212"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1.2439em",verticalAlign:"-0.3948em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"P"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8491em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.4413em",marginLeft:"-0.1389em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"}),(0,a.jsx)(s.span,{className:"mpunct mtight",children:","}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.05724em"},children:"j"})]})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3948em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsxs)(s.span,{className:"mclose",children:[(0,a.jsx)(s.span,{className:"mclose",children:")"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.8141em"},children:(0,a.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"2"})})]})})})})})]}),(0,a.jsx)(s.span,{className:"mpunct",children:","})]})]})]})," o\xf9 la couche qui doit \xeatre"]}),"\n",(0,a.jsx)(s.li,{children:"utilis\xe9e pour calculer la perte de contenu est la 21e couche du mod\xe8le VGG19. Vous retrouverez le nom de cette"}),"\n",(0,a.jsx)(s.li,{children:"couche dans le"}),"\n",(0,a.jsx)(s.li,{children:"graphe du mod\xe8le."}),"\n",(0,a.jsxs)(s.li,{children:["Impl\xe9menter la fonction ",(0,a.jsx)(s.code,{children:"calculate_style_loss"})," qui retourne la perte de style entre la matrice Gram de l'image cible"]}),"\n",(0,a.jsxs)(s.li,{children:["(",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"G"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"G"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"G"})]})})]}),") et la matrice Gram de l'image de style (",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"A"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"A"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"A"})]})})]}),"). La fonction de calcul de cette perte est:"]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"E"}),(0,a.jsx)(s.mi,{children:"i"})]}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsxs)(s.mfrac,{children:[(0,a.jsx)(s.mn,{children:"1"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mn,{children:"4"}),(0,a.jsxs)(s.msubsup,{children:[(0,a.jsx)(s.mi,{children:"N"}),(0,a.jsx)(s.mi,{children:"l"}),(0,a.jsx)(s.mn,{children:"2"})]}),(0,a.jsxs)(s.msubsup,{children:[(0,a.jsx)(s.mi,{children:"M"}),(0,a.jsx)(s.mi,{children:"l"}),(0,a.jsx)(s.mn,{children:"2"})]})]})]}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mo,{children:"\u2211"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"i"}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mi,{children:"j"})]})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.msubsup,{children:[(0,a.jsx)(s.mi,{children:"G"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"i"}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mi,{children:"j"})]}),(0,a.jsx)(s.mi,{children:"l"})]}),(0,a.jsx)(s.mo,{children:"\u2212"}),(0,a.jsxs)(s.msubsup,{children:[(0,a.jsx)(s.mi,{children:"A"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"i"}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsx)(s.mi,{children:"j"})]}),(0,a.jsx)(s.mi,{children:"l"})]}),(0,a.jsxs)(s.msup,{children:[(0,a.jsx)(s.mo,{stretchy:"false",children:")"}),(0,a.jsx)(s.mn,{children:"2"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"E_i = \\frac{1}{4N_l^2M_l^2}\\sum_{i,j}(G_{i,j}^l - A_{i,j}^l)^2,"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3117em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1.4657em",verticalAlign:"-0.6166em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mopen nulldelimiter"}),(0,a.jsx)(s.span,{className:"mfrac",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8451em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.6264em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mtight",children:"4"}),(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.10903em"},children:"N"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8051em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.1528em",marginLeft:"-0.109em",marginRight:"0.0714em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.5em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size3 size1 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]}),(0,a.jsxs)(s.span,{style:{top:"-2.8448em",marginRight:"0.0714em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.5em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size3 size1 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"2"})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3472em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.10903em"},children:"M"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8051em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.1528em",marginLeft:"-0.109em",marginRight:"0.0714em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.5em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size3 size1 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]}),(0,a.jsxs)(s.span,{style:{top:"-2.8448em",marginRight:"0.0714em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.5em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size3 size1 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"2"})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3472em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.23em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,a.jsxs)(s.span,{style:{top:"-3.394em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"1"})})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.6166em"},children:(0,a.jsx)(s.span,{})})})]})}),(0,a.jsx)(s.span,{className:"mclose nulldelimiter"})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(s.span,{className:"mop",children:[(0,a.jsx)(s.span,{className:"mop op-symbol small-op",style:{position:"relative",top:"0em"},children:"\u2211"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.162em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.4003em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"}),(0,a.jsx)(s.span,{className:"mpunct mtight",children:","}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.05724em"},children:"j"})]})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.4358em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"G"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8491em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.4413em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"}),(0,a.jsx)(s.span,{className:"mpunct mtight",children:","}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.05724em"},children:"j"})]})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3948em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"\u2212"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1.2439em",verticalAlign:"-0.3948em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"A"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.8491em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.4413em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"i"}),(0,a.jsx)(s.span,{className:"mpunct mtight",children:","}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.05724em"},children:"j"})]})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3948em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsxs)(s.span,{className:"mclose",children:[(0,a.jsx)(s.span,{className:"mclose",children:")"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.8141em"},children:(0,a.jsxs)(s.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mtight",children:"2"})})]})})})})})]}),(0,a.jsx)(s.span,{className:"mpunct",children:","})]})]})]})," o\xf9 ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"M"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"M"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.10903em"},children:"M"})]})})]})," et ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"N"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"N"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.10903em"},children:"N"})]})})]}),"\nsont des param\xe8tres que vous devez extraire de votre compr\xe9hension de l'article, suivi de:\n",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"s"}),(0,a.jsx)(s.mi,{children:"t"}),(0,a.jsx)(s.mi,{children:"y"}),(0,a.jsx)(s.mi,{children:"l"}),(0,a.jsx)(s.mi,{children:"e"})]})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"a"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:")"}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsxs)(s.msubsup,{children:[(0,a.jsx)(s.mo,{children:"\u2211"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"l"}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsx)(s.mn,{children:"0"})]}),(0,a.jsx)(s.mi,{children:"L"})]}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"w"}),(0,a.jsx)(s.mi,{children:"l"})]}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"E"}),(0,a.jsx)(s.mi,{children:"l"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"L_{style}(\\vec{a},\\vec{x})=\\sum_{l=0}^L w_l E_l,"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1.0361em",verticalAlign:"-0.2861em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"s"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"y"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"e"})]})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"a"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2355em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2077em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mclose",children:")"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1.2809em",verticalAlign:"-0.2997em"}}),(0,a.jsxs)(s.span,{className:"mop",children:[(0,a.jsx)(s.span,{className:"mop op-symbol small-op",style:{position:"relative",top:"0em"},children:"\u2211"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.9812em"},children:[(0,a.jsxs)(s.span,{style:{top:"-2.4003em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"}),(0,a.jsx)(s.span,{className:"mrel mtight",children:"="}),(0,a.jsx)(s.span,{className:"mord mtight",children:"0"})]})})]}),(0,a.jsxs)(s.span,{style:{top:"-3.2029em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"L"})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2997em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0269em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0576em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mpunct",children:","})]})]})]})," o\xf9 ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"w"}),(0,a.jsx)(s.mi,{children:"l"})]})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"w_l"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.5806em",verticalAlign:"-0.15em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"-0.0269em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]})]})})]})," est la pond\xe9ration donn\xe9e \xe0 la couche ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"l"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"l"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.6944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.01968em"},children:"l"})]})})]}),"."]}),"\n"]}),"\n",(0,a.jsxs)(s.p,{children:["Impl\xe9menter la fonction ",(0,a.jsx)(s.code,{children:"calculate_total_loss"})," qui retourne la perte totale pour l'it\xe9ration actuelle. La fonction pour vous permettre de calculer cette perte est:\n",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsxs)(s.mrow,{children:[(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"t"}),(0,a.jsx)(s.mi,{children:"o"}),(0,a.jsx)(s.mi,{children:"t"}),(0,a.jsx)(s.mi,{children:"a"}),(0,a.jsx)(s.mi,{children:"l"})]})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"a"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"p"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:")"}),(0,a.jsx)(s.mo,{children:"="}),(0,a.jsx)(s.mi,{children:"\u03b1"}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"c"}),(0,a.jsx)(s.mi,{children:"o"}),(0,a.jsx)(s.mi,{children:"n"}),(0,a.jsx)(s.mi,{children:"t"}),(0,a.jsx)(s.mi,{children:"e"}),(0,a.jsx)(s.mi,{children:"n"}),(0,a.jsx)(s.mi,{children:"t"})]})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"p"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:")"}),(0,a.jsx)(s.mo,{children:"+"}),(0,a.jsx)(s.mi,{children:"\u03b2"}),(0,a.jsxs)(s.msub,{children:[(0,a.jsx)(s.mi,{children:"L"}),(0,a.jsxs)(s.mrow,{children:[(0,a.jsx)(s.mi,{children:"s"}),(0,a.jsx)(s.mi,{children:"t"}),(0,a.jsx)(s.mi,{children:"y"}),(0,a.jsx)(s.mi,{children:"l"}),(0,a.jsx)(s.mi,{children:"e"})]})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:"("}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"a"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{separator:"true",children:","}),(0,a.jsxs)(s.mover,{accent:"true",children:[(0,a.jsx)(s.mi,{children:"x"}),(0,a.jsx)(s.mo,{children:"\u20d7"})]}),(0,a.jsx)(s.mo,{stretchy:"false",children:")"})]}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"L_{total}(\\vec{a},\\vec{p},\\vec{x})=\\alpha L_{content}(\\vec{p},\\vec{x}) + \\beta L_{style}(\\vec{a},\\vec{x})"})]})})}),(0,a.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"o"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"a"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"})]})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"a"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2355em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"p"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.1522em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.1944em"},children:(0,a.jsx)(s.span,{})})})]})}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2077em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mclose",children:")"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,a.jsx)(s.span,{className:"mrel",children:"="}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2806em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"co"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"n"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"e"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"n"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"})]})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.15em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"p"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.1522em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.1944em"},children:(0,a.jsx)(s.span,{})})})]})}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2077em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mclose",children:")"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,a.jsx)(s.span,{className:"mbin",children:"+"}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"1.0361em",verticalAlign:"-0.2861em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"}),(0,a.jsxs)(s.span,{className:"mord",children:[(0,a.jsx)(s.span,{className:"mord mathnormal",children:"L"}),(0,a.jsx)(s.span,{className:"msupsub",children:(0,a.jsxs)(s.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(s.span,{className:"vlist-r",children:[(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.3361em"},children:(0,a.jsxs)(s.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"2.7em"}}),(0,a.jsx)(s.span,{className:"sizing reset-size6 size3 mtight",children:(0,a.jsxs)(s.span,{className:"mord mtight",children:[(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"s"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"t"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.03588em"},children:"y"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",style:{marginRight:"0.01968em"},children:"l"}),(0,a.jsx)(s.span,{className:"mord mathnormal mtight",children:"e"})]})})]})}),(0,a.jsx)(s.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsx)(s.span,{className:"vlist",style:{height:"0.2861em"},children:(0,a.jsx)(s.span,{})})})]})})]}),(0,a.jsx)(s.span,{className:"mopen",children:"("}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"a"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2355em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mpunct",children:","}),(0,a.jsx)(s.span,{className:"mspace",style:{marginRight:"0.1667em"}}),(0,a.jsx)(s.span,{className:"mord accent",children:(0,a.jsx)(s.span,{className:"vlist-t",children:(0,a.jsx)(s.span,{className:"vlist-r",children:(0,a.jsxs)(s.span,{className:"vlist",style:{height:"0.714em"},children:[(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",children:"x"})]}),(0,a.jsxs)(s.span,{style:{top:"-3em"},children:[(0,a.jsx)(s.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(s.span,{className:"accent-body",style:{left:"-0.2077em"},children:(0,a.jsx)(s.span,{className:"overlay",style:{height:"0.714em",width:"0.471em"},children:(0,a.jsx)(s.svg,{xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin",children:(0,a.jsx)(s.path,{d:"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z"})})})})]})]})})})}),(0,a.jsx)(s.span,{className:"mclose",children:")"})]})]})]})]}),"\n",(0,a.jsx)(s.pre,{children:(0,a.jsx)(s.code,{className:"language-python",children:'# *** TODO ***\n# Impl\xe9menter la fonction qui calcule la perte de contenu pour\n# une couche donn\xe9e. La perte est calcul\xe9e comme l\'erreur quadratique\n# entre les param\xe8tres de l\'image cible et les param\xe8tres de l\'image\n# de contenu pour chaque couche.\n#\n# Implement the function that calculates the content loss for\n# a given layer. The loss is calculated as the squared error\n# between the parameters of the target image and the parameters\n# of the content image for each layer.\ndef calculate_content_loss(layer_name):\n    assert(layer_name in target_features.keys())\n    assert(layer_name in content_features.keys())\n    """\n    Calculates the content loss between the target image features and\n    the content image features.\n\n    Args:\n        layer_name (String) : Name of the layer to evaluate.\n\n    Returns:\n        tensor (Tensor): Tensor containing the loss of the squared mean\n                         difference between the target and content layers.\n    """\n    target_feature = target_features[layer_name]\n    content_feature = content_features[layer_name]\n    content_loss = F.mse_loss(target_feature, content_feature) / 2\n    return content_loss\n# ******\n\n# *** TODO ***\n# Impl\xe9menter la fonction qui calcule la perte de style pour une couche donn\xe9e.\n# Cette perte de style est calcul\xe9e par l\'erreur entre la matrice Gram\n# de contenu et la matrice Gram de style, pond\xe9r\xe9e par le poids donn\xe9 \xe0 chaque couche.\n#\n# Implement the function that calculates the style loss for a given layer.\n# This style loss is calculated as the error between the content Gram\n# matrix and the style Gram matrix, weighted by the weight given to each layer.\ndef calculate_style_loss(weight_layer, target_gram, style_gram, target_feature):\n    """\n    Calculates the style loss between the Gram matrix of the image features and\n    the Gram matrix of the content image features.\n\n    Args:\n        weight_layer (Float) : weighting for the current layer (w_l).\n        target_gram (Tensor) : Gram matrix of the target image (G).\n        style_gram (Tensor) : Gram matrix of the style image (A).\n        target_feature (Tensor) : tensor containing the target feature for\n                                  the current layer.\n\n    Returns:\n        style_loss (Tensor): Tensor with the computed style loss for the current layer.\n    """\n    N_l = target_feature.shape[1]\n    M_l = target_feature.shape[2] * target_feature.shape[3]\n    style_loss = weight_layer * F.mse_loss(target_gram, style_gram) / (4 * N_l**2 * M_l**2)\n    return style_loss\n# ******\n\n# *** TODO ***\n# Impl\xe9menter la fonction qui calcule la perte totale pour l\'it\xe9ration.\n# La perte totale est calcul\xe9e par la somme pond\xe9r\xe9e de la perte de contenu\n# et la perte de style.\n# Implement the function that calculates the total loss for the iteration.\n# The total loss is calculated by the weighted sum of the content loss\n# and the style loss.\ndef calculate_total_loss(content_weight, content_loss, style_weight, style_loss):\n    """\n    Calculates the total loss for the current iteration.\n\n    Args:\n        content_weight (Float) : Alpha weighting for the content.\n        content_loss (Float) : Content loss.\n        style_weight (Float) : Beta weighting for the style.\n        style_loss (Float) : Total loss.\n\n    Returns:\n        total_loss (Tensor): Tensor with the computed total loss for the current iteration.\n    """\n    total_loss = content_weight * content_loss + style_weight * style_loss\n    return total_loss\n# ******\n\n# Nombre total d\'it\xe9rations pour appliquer\n# le transfert de style (Min: 2000 | Recommand\xe9: 5000)\n# Total number of iterations to apply\n# style transfer (Min: 2000 | Recommended: 5000)\nsteps = 5000\n\n# Fr\xe9quence de mise \xe0 jour de l\'image (Valeur recommand\xe9e: 500)\n# Image update frequency (Recommended value: 500)\nshow_image_every = 500\n\n# Initialisation de l\'optimiseur Adam. Puisqu\'on modifie la cible,\n# on l\'applique directement sur les pixels de l\'image (learning_rate = 3e-3).\n# Initialization of the Adam optimizer. Since we modify the target,\n# we apply it directly on the pixels of the image (learning_rate = 3e-3).\n#\n# [Gatys et coll, 2016] font usage de L-BFGS mais pour simplifier l\'impl\xe9mentation et acc\xe9l\xe9rer\n# la convergence vers des r\xe9sultats visibles, Adam est plus appropri\xe9.\n# [Gatys et al, 2016] make use of L-BFGS but to simplify implementation and accelerate\n# convergence to visible results, Adam is more appropriate.\noptimizer = optim.Adam([target], lr=3e-3)\n\nfor s in tqdm(range(1, steps+1)):\n\n    # 1. Remise \xe0 z\xe9ro des gradients\n    # 1. Reset the gradients to zero\n    optimizer.zero_grad()\n\n    # 2. Extraire les features de l\'image cible\n    # 2. Extract the features of the target image\n    target_features = extract_features(target, vgg)\n\n    # *** TODO ***\n    # 3. Calculer la loss de contenu avec la fonction\n    # calculate_content_loss. Vous devez retrouver le\n    # nom de la couche dans le graphe du mod\xe8le.\n    # 3. Calculate the content loss with the function\n    # calculate_content_loss. You must find the\n    # name of the layer in the model graph.\n    layer_name = "conv4_2"\n    content_loss = calculate_content_loss(layer_name)\n    # ******\n\n    # 4. Calculer la loss de style en accumulant sa valeur pour chaque couche\n    # 4. Calculate the style loss by accumulating its value for each layer\n    style_loss = 0 # Initialiser la loss de style \xe0 z\xe9ro / Initialise style loss to zero\n    for l_name, l_weight in style_layers_weights.items():\n\n        # Extraire le contenu de la couche / Extract layer content\n        target_feature = target_features[l_name]\n\n        # Calculer la matrice de Gram du contenu / Compute content Gram matrix\n        target_gram = gram_matrix(target_feature)\n\n        # Extraire la matrice Gram pr\xe9-calcul\xe9e pour le style\n        # Extract the pre-computed Gram matrix for the style\n        style_gram = style_grams[l_name]\n\n        # Calculer la loss de style avec pond\xe9ration pour\n        # la couche donn\xe9e avec la fonction calculate_style_loss().\n        # Calculate the weighted syle loss for\n        # the given layer with the function calculate_style_loss().\n        layer_style_loss = calculate_style_loss(l_weight,\n                                                target_gram,\n                                                style_gram,\n                                                target_feature)\n\n        # Accumuler la loss de style / Accumulate style loss\n        style_loss += layer_style_loss\n\n    # 5. Calculer la loss totale avec la fonction calculate_total_loss()\n    # 5. Calculate the total loss with the function calculate_total_loss()\n    total_loss = calculate_total_loss(content_weight,\n                                      content_loss,\n                                      style_weight,\n                                      style_loss)\n\n    # 6. Mettre \xe0 jour l\'image cible\n    # 6. Update the target image\n    total_loss.backward()\n    optimizer.step()\n\n    # Afficher les images interm\xe9diaires\n    # Display intermediate images\n    if  s % show_image_every == 0:\n        # Appliquer le postprocessing sur les images\n        # Apply postprocessing to the images\n        plt.figure(figsize=(10,10))\n        img = target.cpu().detach()\n        img_post = postprocessing(img)\n        plt.imshow(img_post)\n        plt.axis(\'off\')\n        plt.show()\n\n# Lib\xe8re la cache sur le GPU *important sur un cluster de GPU*\n# Free the cache on the GPU *important on a GPU cluster*.\ntorch.cuda.empty_cache()\n'})}),"\n",(0,a.jsx)(s.p,{children:"J'obtiens cette image."}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"hybride",src:n(81257).Z+"",width:"557",height:"558"})}),"\n",(0,a.jsx)(s.h3,{id:"q3f",children:"Q3F"}),"\n",(0,a.jsxs)(s.p,{children:["Pour ce cas du transfert de style, plusieurs param\xe8tres peuvent \xeatre modifi\xe9s pour permettre de modifier le rendu de\nl'image hybride. La pond\xe9ration pour chacune des couches de style peut \xeatre modifi\xe9e ainsi que les param\xe8tres ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),"\net ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]}),". En fonction de votre compr\xe9hension de l'article et de vos tests, observez l'effet de chacun de ces param\xe8tres."]}),"\n",(0,a.jsx)(s.p,{children:"Dans la cellule de r\xe9ponse pr\xe9vue \xe0 cet effet, veuillez r\xe9pondre aux questions suivantes:"}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsx)(s.li,{children:"Quel est l'effet de pond\xe9rer diff\xe9remment les couches sur le style?"}),"\n",(0,a.jsx)(s.li,{children:"Que se passe-t-il si on pond\xe8re plus fortement les premi\xe8res couches?"}),"\n",(0,a.jsx)(s.li,{children:"Que se passe-t-il si on pond\xe8re plus fortement les derni\xe8res couches?"}),"\n",(0,a.jsxs)(s.li,{children:["Quel est l'effet du param\xe8tre ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),"?"]}),"\n",(0,a.jsxs)(s.li,{children:["Quel est l'effet du param\xe8tre ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]}),"?"]}),"\n",(0,a.jsx)(s.li,{children:"Qu'est-ce qui est, selon vous, une bonne configuration des param\xe8tres de pond\xe9ration des poids des couches de style,"}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," et ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]}),", et pourquoi?"]}),"\n"]}),"\n",(0,a.jsx)(s.h3,{id:"q3f-r\xe9ponse",children:"Q3F R\xe9ponse"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"1. Effet de la pond\xe9ration des couches sur le style"})," : Chaque couche du r\xe9seau VGG extrait diff\xe9rents aspects\ndu style de l'image. Les couches inf\xe9rieures capturent des d\xe9tails fins (textures, motifs) tandis que les couches\nsup\xe9rieures capturent des caract\xe9ristiques plus complexes et abstraites. Ainsi, pond\xe9rer diff\xe9remment ces couches\npermet de contr\xf4ler quel niveau de d\xe9tail et d'abstraction du style dans l'image hybride."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"2. Pond\xe9ration plus forte des premi\xe8res couches"})," : En pond\xe9rant plus fortement les premi\xe8res couches (couches inf\xe9rieures),\nl'image hybride aura tendance \xe0 refl\xe9ter davantage les textures et motifs de base de l'image de style, comme les coups\nde pinceau ou les gradients de couleur."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"3. Pond\xe9ration plus forte des derni\xe8res couches"})," : En augmentant la pond\xe9ration des derni\xe8res couches (couches sup\xe9rieures),\nl'image hybride tend \xe0 int\xe9grer des aspects plus abstraits et complexes du style, comme les formes globales ou la\ncomposition de l'image de style."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsxs)(s.strong,{children:["4. Effet du param\xe8tre ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})]})," : Ce param\xe8tre contr\xf4le combien de l'image de contenu originale est conserv\xe9e dans\nl'image hybride. Une valeur plus \xe9lev\xe9e pour ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," signifie que l'image hybride sera plus proche de l'image de\ncontenu, avec moins d'influence du style."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsxs)(s.strong,{children:["5. Effet du param\xe8tre ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]})]})," : Ce param\xe8tre d\xe9termine l'impact du style sur l'image hybride. Une valeur plus \xe9lev\xe9e pour ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]})," donne plus de poids au style de l'image de style, ce qui peut conduire \xe0 une image hybride o\xf9 le style est plus dominant par rapport au contenu original."]}),"\n",(0,a.jsxs)(s.li,{children:[(0,a.jsx)(s.strong,{children:"6. Configuration optimale des param\xe8tres"})," : La configuration optimale des param\xe8tres de pond\xe9ration d\xe9pend de l'effet\nd\xe9sir\xe9 et de la nature des images de style et de contenu.","\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsx)(s.li,{children:"Si l'image de style est riche en petits d\xe9tails (comme un tableau impressionniste), une pond\xe9ration plus \xe9lev\xe9e des premi\xe8res couches peut aider \xe0 capturer ces d\xe9tails."}),"\n",(0,a.jsx)(s.li,{children:"Si l'image de style a des caract\xe9ristiques stylistiques \xe0 plus grande \xe9chelle (comme des formes g\xe9om\xe9triques ou des compositions abstraites), une pond\xe9ration plus \xe9lev\xe9e des couches sup\xe9rieures peut \xeatre plus appropri\xe9e."}),"\n",(0,a.jsxs)(s.li,{children:["Pour une image hybride o\xf9 le contenu doit \xeatre clairement reconnaissable mais artistiquement stylis\xe9, un \xe9quilibre entre ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b1"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," et ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]})," sera est pr\xe9f\xe9rable."]}),"\n",(0,a.jsxs)(s.li,{children:["Pour un effet de style prononc\xe9, un ",(0,a.jsxs)(s.span,{className:"katex",children:[(0,a.jsx)(s.span,{className:"katex-mathml",children:(0,a.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(s.semantics,{children:[(0,a.jsx)(s.mrow,{children:(0,a.jsx)(s.mi,{children:"\u03b2"})}),(0,a.jsx)(s.annotation,{encoding:"application/x-tex",children:"\\beta"})]})})}),(0,a.jsx)(s.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(s.span,{className:"base",children:[(0,a.jsx)(s.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(s.span,{className:"mord mathnormal",style:{marginRight:"0.05278em"},children:"\u03b2"})]})})]})," \xe9lev\xe9 est n\xe9cessaire."]}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:s}={...(0,t.a)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(o,{...e})}):o(e)}},94469:(e,s,n)=>{n.d(s,{Z:()=>a});const a=n.p+"assets/images/content_style_mona-30648514c4b43b17df671ce39ca9be2e.png"},35634:(e,s,n)=>{n.d(s,{Z:()=>a});const a=n.p+"assets/images/d4q1_volcanoes_net-eac7e16aa0204cea1cf1ef9f5915174a.png"},81257:(e,s,n)=>{n.d(s,{Z:()=>a});const a=n.p+"assets/images/hybride-645d85f7ea2a41335487fdced8b1d4db.png"},94468:(e,s,n)=>{n.d(s,{Z:()=>a});const a=n.p+"assets/images/output_28_1-89203f1539b89dd5e73d1617cc9bbe56.png"},29766:(e,s,n)=>{n.d(s,{Z:()=>a});const a=n.p+"assets/images/output_7_0-8d6b5a5466e3e252c9454ea53a5638a1.png"},1395:(e,s,n)=>{n.d(s,{Z:()=>a});const a=n.p+"assets/images/output_7_1-1ed9a432b7f8191e9a605e5b3b4396e3.png"},67052:(e,s,n)=>{n.d(s,{Z:()=>a});const a=n.p+"assets/images/style_transfer_mona-62486c134f08db8e6f7a970aea0c48f9.gif"},11151:(e,s,n)=>{n.d(s,{Z:()=>r,a:()=>l});var a=n(67294);const t={},i=a.createContext(t);function l(e){const s=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),a.createElement(i.Provider,{value:s},e.children)}}}]);
"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1803],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>k});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var o=n.createContext({}),m=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},p=function(e){var t=m(e.components);return n.createElement(o.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=m(a),c=r,k=u["".concat(o,".").concat(c)]||u[c]||d[c]||i;return a?n.createElement(k,l(l({ref:t},p),{},{components:a})):n.createElement(k,l({ref:t},p))}));function k(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=c;var s={};for(var o in t)hasOwnProperty.call(t,o)&&(s[o]=t[o]);s.originalType=e,s[u]="string"==typeof e?e:r,l[1]=s;for(var m=2;m<i;m++)l[m]=a[m];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},9057:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>m});var n=a(7462),r=(a(7294),a(3905));const i={sidebar_label:"IFT-7022 Traitement automatique de la langue naturelle",sidebar_position:5,tags:["NLP"]},l="IFT-7022 Traitement automatique de la langue naturelle",s={unversionedId:"courses/ift-7022",id:"courses/ift-7022",title:"IFT-7022 Traitement automatique de la langue naturelle",description:"Informations g\xe9n\xe9rales",source:"@site/docs/courses/ift-7022.md",sourceDirName:"courses",slug:"/courses/ift-7022",permalink:"/docs/courses/ift-7022",draft:!1,tags:[{label:"NLP",permalink:"/docs/tags/nlp"}],version:"current",sidebarPosition:5,frontMatter:{sidebar_label:"IFT-7022 Traitement automatique de la langue naturelle",sidebar_position:5,tags:["NLP"]},sidebar:"tutorialSidebar",previous:{title:"GIF-7005 Introduction \xe0 l'apprentissage automatique",permalink:"/docs/courses/gif-7005"},next:{title:"Training & fine-tuning LLMs",permalink:"/docs/courses/fine-tuning-llms"}},o={},m=[{value:"Informations g\xe9n\xe9rales",id:"informations-g\xe9n\xe9rales",level:2},{value:"Calendrier",id:"calendrier",level:2},{value:"1. Expressions r\xe9guli\xe8res",id:"1-expressions-r\xe9guli\xe8res",level:2},{value:"Chapter 2 Regular Expression, Text Normalisation, Edit Distance",id:"chapter-2-regular-expression-text-normalisation-edit-distance",level:3},{value:"2. Pr\xe9traitement de textes et distance minimale d&#39;\xe9dition",id:"2-pr\xe9traitement-de-textes-et-distance-minimale-d\xe9dition",level:2},{value:"Mots",id:"mots",level:3},{value:"Tokenisation",id:"tokenisation",level:3},{value:"Normalisation de mots",id:"normalisation-de-mots",level:3},{value:"Analyse morphologique",id:"analyse-morphologique",level:4},{value:"Lemmatisation",id:"lemmatisation",level:4},{value:"Stemming",id:"stemming",level:4},{value:"Segmentation de phrases",id:"segmentation-de-phrases",level:3},{value:"Logiciels et ressources",id:"logiciels-et-ressources",level:3},{value:"3. Mod\xe8les de langue N-grammes",id:"3-mod\xe8les-de-langue-n-grammes",level:2},{value:"4. Classification de textes",id:"4-classification-de-textes",level:2},{value:"5. S\xe9mantique vectorielle (repr\xe9sentation des mots)",id:"5-s\xe9mantique-vectorielle-repr\xe9sentation-des-mots",level:2},{value:"6. Deep NLP: Plongements de mots (word embeddings) + intro aux r\xe9seaux de neurones",id:"6-deep-nlp-plongements-de-mots-word-embeddings--intro-aux-r\xe9seaux-de-neurones",level:2},{value:"7. \xc9tiquetage de s\xe9quences - analyse grammaticale (Part of speech tagging) et reconnaissance d&#39;entit\xe9s nomm\xe9es",id:"7-\xe9tiquetage-de-s\xe9quences---analyse-grammaticale-part-of-speech-tagging-et-reconnaissance-dentit\xe9s-nomm\xe9es",level:2},{value:"8. Deep NLP - R\xe9seaux r\xe9currents pour le traitement de s\xe9quences (RNN, GRU, LSTM)",id:"8-deep-nlp---r\xe9seaux-r\xe9currents-pour-le-traitement-de-s\xe9quences-rnn-gru-lstm",level:2},{value:"9. Deep NLP - Introduction aux mod\xe8les Transformers",id:"9-deep-nlp---introduction-aux-mod\xe8les-transformers",level:2},{value:"10. Deep NLP - Traduction automatique et mod\xe8le encodeur-d\xe9codeur",id:"10-deep-nlp---traduction-automatique-et-mod\xe8le-encodeur-d\xe9codeur",level:2},{value:"11. Deep NLP - Plongements contextuels et mod\xe8les de langue pr\xe9entra\xeen\xe9s (Bert et al.)",id:"11-deep-nlp---plongements-contextuels-et-mod\xe8les-de-langue-pr\xe9entra\xeen\xe9s-bert-et-al",level:2},{value:"12. Deep NLP - Prompting et instruct tuning",id:"12-deep-nlp---prompting-et-instruct-tuning",level:2},{value:"13. Deep NLP - Syst\xe8mes question-r\xe9ponse (QA)",id:"13-deep-nlp---syst\xe8mes-question-r\xe9ponse-qa",level:2},{value:"Annexe A. Logiciels pour le traitement automatique de la langue naturelle",id:"annexe-a-logiciels-pour-le-traitement-automatique-de-la-langue-naturelle",level:2},{value:"Annexe B. Travaux pratiques pour l&#39;automne 2022",id:"annexe-b-travaux-pratiques-pour-lautomne-2022",level:2},{value:"Travail pratique 1",id:"travail-pratique-1",level:3},{value:"Annexe C. Correction d&#39;orthographe (\xe0 titre informatif seulement)",id:"annexe-c-correction-dorthographe-\xe0-titre-informatif-seulement",level:2},{value:"Annexe D. Mod\xe8les de traduction statistique (\xe0 titre informatif seulement)",id:"annexe-d-mod\xe8les-de-traduction-statistique-\xe0-titre-informatif-seulement",level:2},{value:"Annexe E. Analyse syntaxique (\xe0 titre informatif seulement)",id:"annexe-e-analyse-syntaxique-\xe0-titre-informatif-seulement",level:2},{value:"Annexe F - Syst\xe8mes question-r\xe9ponse (QA) - Ancienne version",id:"annexe-f---syst\xe8mes-question-r\xe9ponse-qa---ancienne-version",level:2},{value:"Annexe G. Extraction d&#39;information (\xe0 titre informatif seulement)",id:"annexe-g-extraction-dinformation-\xe0-titre-informatif-seulement",level:2}],p={toc:m},u="wrapper";function d(e){let{components:t,...a}=e;return(0,r.kt)(u,(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"ift-7022-traitement-automatique-de-la-langue-naturelle"},"IFT-7022 Traitement automatique de la langue naturelle"),(0,r.kt)("h2",{id:"informations-g\xe9n\xe9rales"},"Informations g\xe9n\xe9rales"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Enseignant : Luc Lamontagne."),(0,r.kt)("li",{parentName:"ul"},"Cours \xe0 distance, tous les mardis, de 18h30 \xe0 21h30, du 5 sept. au 12 d\xe9c. 2023."),(0,r.kt)("li",{parentName:"ul"},"Fiche : ",(0,r.kt)("a",{parentName:"li",href:"https://www.ulaval.ca/etudes/cours/ift-7022-traitement-automatique-de-la-langue-naturelle"},"https://www.ulaval.ca/etudes/cours/ift-7022-traitement-automatique-de-la-langue-naturelle"),"."),(0,r.kt)("li",{parentName:"ul"},"Site du cours : ",(0,r.kt)("a",{parentName:"li",href:"https://sitescours.monportail.ulaval.ca/ena/site/accueil?idSite=158245&idPage=4010599"},"https://sitescours.monportail.ulaval.ca/ena/site/accueil?idSite=158245&idPage=4010599")),(0,r.kt)("li",{parentName:"ul"},"Portail : ",(0,r.kt)("a",{parentName:"li",href:"https://monportail.ulaval.ca/accueil/"},"https://monportail.ulaval.ca/accueil/")),(0,r.kt)("li",{parentName:"ul"},"Les dates des examens sont le mardi 17 octobre (mi-session) et le mardi 12 d\xe9cembre (final). ")),(0,r.kt)("p",null,"Expressions r\xe9guli\xe8res, normalisation de textes, mod\xe8les N-grammes, correction orthographique, classification de texte,\n\xe9tiquetage grammatical, analyse syntaxique, recherche d'information, extraction d'information, syst\xe8mes question-r\xe9ponse,\ntraduction automatique, s\xe9mantique lexicale, introduction aux plongements de mots et mod\xe8les neuronaux. "),(0,r.kt)("p",null,"Mat\xe9riel obligatoire :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\ud83d\udcd5 Dan Jurafsky et James Martin, ",(0,r.kt)("strong",{parentName:"li"},"Speech and Language Processing")," (3e \xe9dition) (disponible sur ",(0,r.kt)("a",{parentName:"li",href:"https://web.stanford.edu/~jurafsky/slp3/"},"https://web.stanford.edu/~jurafsky/slp3/"),").")),(0,r.kt)("p",null,"Bibliographie :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Christopher Manning et Hinrich Sch\xfctze (1999). ",(0,r.kt)("strong",{parentName:"li"},"Foundations of Statistical Natural Language processing"),", MIT Press (disponible sur le site ",(0,r.kt)("a",{parentName:"li",href:"http://nlp.stanford.edu/fsnlp/"},"http://nlp.stanford.edu/fsnlp/"),")."),(0,r.kt)("li",{parentName:"ul"},"Steven Bird, Ewan Klein, and Edward Loper (2009). ",(0,r.kt)("strong",{parentName:"li"},"Natural Language Processing with Python--- Analyzing Text with the Natural Language Toolkit"),", O'Reilly Media (disponible sur le site ",(0,r.kt)("a",{parentName:"li",href:"http://www.nltk.org/book/"},"http://www.nltk.org/book/"),")"),(0,r.kt)("li",{parentName:"ul"},"Jeffery E. F. Friedl (2006). ",(0,r.kt)("strong",{parentName:"li"},"Mastering Regular Expressions"),", 3e \xe9dition, O'Reilly."),(0,r.kt)("li",{parentName:"ul"},"Christopher Manning, Prabhakar Raghavan et Hinrick Schutze (2008). ",(0,r.kt)("strong",{parentName:"li"},"Introduction to Information Retrieval"),", Cambrige University Press (disponible sur ",(0,r.kt)("a",{parentName:"li",href:"http://nlp.stanford.edu/IR-book/"},"http://nlp.stanford.edu/IR-book/"),")."),(0,r.kt)("li",{parentName:"ul"},"Michael McCandless, Erik Hatcher, et Otis Gospodnetic (2010). ",(0,r.kt)("strong",{parentName:"li"},"Lucene in Action"),". Manning Publications co."),(0,r.kt)("li",{parentName:"ul"},"Grant S. Ingersoll, Thomas S. Morton, et Andrew L. Farris (2013). ",(0,r.kt)("strong",{parentName:"li"},"Taming text - How to Find, Organize, and Manipulate It"),", Manning Publications Co. "),(0,r.kt)("li",{parentName:"ul"},"Aur\xe9lien G\xe9ron (2017). ",(0,r.kt)("strong",{parentName:"li"},"Hands-on Machine Learning with Scikit-Learn & TensorFlow"),", O'Reilly. "),(0,r.kt)("li",{parentName:"ul"},"Yoav Goldberg (2017). ",(0,r.kt)("strong",{parentName:"li"},"Neural Network Methods in Natural Language Processing"),", Synthesis Lectures on Human Language Technologies, Morgan & Claypool Publishers. "),(0,r.kt)("li",{parentName:"ul"},"Hobson Lane, Cole Howard, Hannes Max Hapke (2019). ",(0,r.kt)("strong",{parentName:"li"},"Natural Language Processing in Action"),", Manning. "),(0,r.kt)("li",{parentName:"ul"},"Delip Rao et Brian McMahan (2019). ",(0,r.kt)("strong",{parentName:"li"},"Natural Language processing with PyTorch"),", O'Reilly. "),(0,r.kt)("li",{parentName:"ul"},"Lewis Tunstall,, Leandro von Werra & Thomas Wolf. (2022). ",(0,r.kt)("strong",{parentName:"li"},"Natural language processing with transformers"),", Revised edition. O'Reilly Media, Inc."),(0,r.kt)("li",{parentName:"ul"},"Olivier Caelen et Marie-Alice Blete (2023) ",(0,r.kt)("strong",{parentName:"li"},"Developing Apps with GPT-4 et ChatGPT"),". O'Reilly Media Inc. ")),(0,r.kt)("h2",{id:"calendrier"},"Calendrier"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Formation des \xe9quipes: du 4 septembre au 20 septembre 23h59 au plus tard."),(0,r.kt)("li",{parentName:"ul"},"Travail 1\t d\xfb le 29 sept. 2023 \xe0 23h59 (20 %)"),(0,r.kt)("li",{parentName:"ul"},"Travail 2\t d\xfb le 27 oct. 2023 \xe0 23h59 (20 %)"),(0,r.kt)("li",{parentName:"ul"},"Travail 3\t d\xfb le 15 d\xe9c. 2023 \xe0 23h59 (20 %)"),(0,r.kt)("li",{parentName:"ul"},"Examen de mi-session le 17 oct. 2023 de 18h30 \xe0 21h45 (20 %)"),(0,r.kt)("li",{parentName:"ul"},"Examen final le 12 d\xe9c. 2023 de 18h30 \xe0 21h45 (20 %)")),(0,r.kt)("h2",{id:"1-expressions-r\xe9guli\xe8res"},"1. Expressions r\xe9guli\xe8res"),(0,r.kt)("p",null,"S\xe9ance du 5 septembre 2023 :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"\ud83d\udcd5 Jurafsky & Martin, 3e \xe9dition, ",(0,r.kt)("a",{parentName:"li",href:"https://web.stanford.edu/~jurafsky/slp3/2.pdf"},"chapitre 2, section 2.1"),". ")),(0,r.kt)("h3",{id:"chapter-2-regular-expression-text-normalisation-edit-distance"},"Chapter 2 Regular Expression, Text Normalisation, Edit Distance"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Regular expression")," (often shortened to ",(0,r.kt)("strong",{parentName:"li"},"regex"),"), can be used to specify strings we might want to extract from a document."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Text normalization")," means converting it to a more convenient, standard form."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Tokenization")," is used in natural language processing (NLP) to split paragraphs and sentences into smaller units that can be more easily assigned meaning."),(0,r.kt)("li",{parentName:"ul"},"We need to tokenize ",(0,r.kt)("strong",{parentName:"li"},"emoticons")," like ",(0,r.kt)("inlineCode",{parentName:"li"},":)")," or ",(0,r.kt)("strong",{parentName:"li"},"hashtags")," like ",(0,r.kt)("inlineCode",{parentName:"li"},"#nlproc"),"."),(0,r.kt)("li",{parentName:"ul"},"Another part of text normalization is ",(0,r.kt)("strong",{parentName:"li"},"lemmatization"),", the task of determining that two words have the same root, despite their surface differences."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Stemming")," refers to a simpler version of lemmatization in which we mainly just strip suffixes from the end of the word."),(0,r.kt)("li",{parentName:"ul"},"Text normalization also includes ",(0,r.kt)("strong",{parentName:"li"},"sentence segmentation"),": breaking up a text into individual sentences, using cues like sentence segmentation periods or exclamation points."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Edit distance")," is a metric that measures how similar two strings are based on the number of edits (insertions, deletions, substitutions) it takes to change one string into the other.")),(0,r.kt)("p",null,"Before almost any natural language processing of a text, the text has to be normalized. At least three tasks are commonly applied as part of any normalization process:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Tokenizing (segmenting) words"),(0,r.kt)("li",{parentName:"ol"},"Normalizing word formats"),(0,r.kt)("li",{parentName:"ol"},"Segmenting sentences")),(0,r.kt)("p",null,"Most tokenization schemes have two parts: a ",(0,r.kt)("strong",{parentName:"p"},"token learner"),", and a ",(0,r.kt)("strong",{parentName:"p"},"token segmenter"),".\nThe token learner takes a raw training corpus (sometimes roughly preseparated into words, for example by whitespace) and induces a vocabulary, a set\nof tokens. The token segmenter takes a raw test sentence and segments it into the\ntokens in the vocabulary."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Case folding")," is another kind of normalization, mapping everything to lower case."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Lemmatization")," is the task of determining that two words have the same root, despite their surface differences."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Stemming")," refers to the process of reducing a word to its word stem that affixes to suffixes and prefixes or the roots."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Sentence segmentation"),". The most useful cues for segmenting a text into sentences are punctuation, like periods, question marks, and exclamation points."),(0,r.kt)("li",{parentName:"ul"},"The ",(0,r.kt)("strong",{parentName:"li"},"minimum edit distance")," between two strings is defined minimum edit distance\nas the minimum number of editing operations (operations like insertion, deletion,\nsubstitution) needed to transform one string into another."),(0,r.kt)("li",{parentName:"ul"},"The ",(0,r.kt)("strong",{parentName:"li"},"Levenshtein distance")," between two sequences is the simplest weighting factor in\nwhich each of the three operations has a cost of 1. ")),(0,r.kt)("p",null,"Exemples \xe0 faire avec ",(0,r.kt)("a",{parentName:"p",href:"https://regexr.com/"},"https://regexr.com/"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-txt"},"# Trouver les la, le, les, l', etc.\n/le|la|l'|les/g\n/les|le|l'|le/g\n/\\b(les|le|l'|le)/g  # D\xe9but des mots.\n/\\b(les|le|l'|le)\\b/g  # Fin des mots.\n/\\b[Ll](e|a|'|es|es|e|'|e)\\b/g  # Isoler les Ll.\n/\\b[Ll](e|a|'|es)\\b/g  # Enlever les doublons.\n/\\b[Ll][ea']s?\\b/g  # Rendre le s optionel.\n\n# Trouver les courriels.\n/[a-z]+/g\n/[a-z]+.[a-z]+.[0-9]+/g\n/[a-z]+.[a-z]+.[0-9]@[a-z]+.[a-z]+.[a-z]+/g\n/[\\w]+.[\\w]+.[\\d]@[\\w]+.[\\w]+.[\\w]+/g  # Simplifier.\n/[\\w]+\\.[\\w]+\\.[\\d]@[\\w]+\\.[\\w]+\\.[\\w]+/g  # Forcer le point.\n/([\\w]+)\\.([\\w]+)\\.[\\d]@([\\w]+\\.[\\w]+\\.[\\w]+)/g  # Cr\xe9er des groupes.\n/([\\w]+)\\.([\\w]+)\\.[\\d]{1,3}@([\\w]+\\.[\\w]+\\.[\\w]+)/g  # Nombre de r\xe9p\xe9titions.\n")),(0,r.kt)("p",null,"Regex en Python."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Module ",(0,r.kt)("inlineCode",{parentName:"li"},"re"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"compile")," fonction qui g\xe9n\xe8re une version compil\xe9e d\u2019une regex."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"match")," ou ",(0,r.kt)("inlineCode",{parentName:"li"},"search")," fait le matching entre une regex et une cha\xeene."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"sub")," remplace la premi\xe8re occurrence d\u2019un patron par une cha\xeene. ")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import re\n\nexample_string = "this is a test"\np = re.compile(r"\\w+")\n\nm = p.search(example_string) print("Start index:", m.start())  # Start index: 0\nprint(" End index:", m.end())  # End index: 4\nprint(m.group())  # this\nprint(p.findall(example_string))  # [\u2018this\', \'is\', \'a\', \'test\']\n\np = re.compile("is")\nprint(p.match(example_string))  # None\nprint(re.sub(r"(this) (is) (.+)", "\\\\2 \\\\1 \\\\3", example_string))  # \'is this a test\'\n')),(0,r.kt)("p",null,"See also: "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://docs.python.org/3/library/re.html"},(0,r.kt)("inlineCode",{parentName:"a"},"re")," - Regular expression operations"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://regex101.com/"},"Online regular expression tester"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://regexr.com/"},"RegExr"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"http://www.regextester.com/"},"Regex Tester"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://alf.nu/RegexGolf?world=regex&level=r00"},"Regex Golf"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://cheatography.com/davechild/cheat-sheets/regular-expressions/"},"Regular Expressions cheat sheet"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://docs.python.org/3/howto/regex.html"},"Regular Expression HOWTO"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://developers.google.com/edu/python/regular-expressions"},"Python Regular Expressions"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://missing.csail.mit.edu/2020/data-wrangling/"},"Data Wrangling")," from CSAIL MIT.")),(0,r.kt)("h2",{id:"2-pr\xe9traitement-de-textes-et-distance-minimale-d\xe9dition"},"2. Pr\xe9traitement de textes et distance minimale d'\xe9dition"),(0,r.kt)("p",null,"Semaine du 12 septembre 2023 :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Lecture de Jurafski et Martin, 3e \xe9dition, chapitre 2, sections 2.2 \xe0 2.5"),(0,r.kt)("li",{parentName:"ul"},"La partie sur la distance minimale d'\xe9dition est pr\xe9sent\xe9e uniquement \xe0 titre informatif. Elle ne sera pas \xe9valu\xe9e \xe0 l'examen. ")),(0,r.kt)("h3",{id:"mots"},"Mots"),(0,r.kt)("p",null,"Mot = Plus petit \xe9l\xe9ment pouvant \xeatre prononc\xe9/\xe9crit en isolation avec un contenu s\xe9mantique."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Loi de Heaps")," : ",(0,r.kt)("span",{parentName:"p",className:"math math-inline"},(0,r.kt)("span",{parentName:"span",className:"katex"},(0,r.kt)("span",{parentName:"span",className:"katex-mathml"},(0,r.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,r.kt)("semantics",{parentName:"math"},(0,r.kt)("mrow",{parentName:"semantics"},(0,r.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"\u2223"),(0,r.kt)("mi",{parentName:"mrow"},"V"),(0,r.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"\u2223"),(0,r.kt)("mo",{parentName:"mrow"},"="),(0,r.kt)("mi",{parentName:"mrow"},"k"),(0,r.kt)("msup",{parentName:"mrow"},(0,r.kt)("mi",{parentName:"msup"},"N"),(0,r.kt)("mi",{parentName:"msup"},"\u03b2"))),(0,r.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"|V| = k N^\\beta")))),(0,r.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.kt)("span",{parentName:"span",className:"mord"},"\u2223"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.22222em"}},"V"),(0,r.kt)("span",{parentName:"span",className:"mord"},"\u2223"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,r.kt)("span",{parentName:"span",className:"mrel"},"="),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8491em"}}),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.03148em"}},"k"),(0,r.kt)("span",{parentName:"span",className:"mord"},(0,r.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.10903em"}},"N"),(0,r.kt)("span",{parentName:"span",className:"msupsub"},(0,r.kt)("span",{parentName:"span",className:"vlist-t"},(0,r.kt)("span",{parentName:"span",className:"vlist-r"},(0,r.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8491em"}},(0,r.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,r.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,r.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,r.kt)("span",{parentName:"span",className:"mord mathnormal mtight",style:{marginRight:"0.05278em"}},"\u03b2")))))))))))),". Nous avons ",(0,r.kt)("span",{parentName:"p",className:"math math-inline"},(0,r.kt)("span",{parentName:"span",className:"katex"},(0,r.kt)("span",{parentName:"span",className:"katex-mathml"},(0,r.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,r.kt)("semantics",{parentName:"math"},(0,r.kt)("mrow",{parentName:"semantics"},(0,r.kt)("mn",{parentName:"mrow"},"0.67"),(0,r.kt)("mo",{parentName:"mrow"},"<"),(0,r.kt)("mi",{parentName:"mrow"},"\u03b2"),(0,r.kt)("mo",{parentName:"mrow"},"<"),(0,r.kt)("mn",{parentName:"mrow"},"0.75")),(0,r.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"0.67 < \\beta < 0.75")))),(0,r.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6835em",verticalAlign:"-0.0391em"}}),(0,r.kt)("span",{parentName:"span",className:"mord"},"0.67"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,r.kt)("span",{parentName:"span",className:"mrel"},"<"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.05278em"}},"\u03b2"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,r.kt)("span",{parentName:"span",className:"mrel"},"<"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,r.kt)("span",{parentName:"span",className:"mord"},"0.75")))))," pour les corpus Shakespeare, Brown corpus, Swithboard telephone conversations,\nCOCA, Google N-grams."),(0,r.kt)("p",null,"Combien de mots existe-t-il en anglais? "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Oxford English : plus de 600 000 mots."),(0,r.kt)("li",{parentName:"ul"},"Petit Larousse/Petit Robert : environ 60 000 mots.")),(0,r.kt)("h3",{id:"tokenisation"},"Tokenisation"),(0,r.kt)("p",null,"D\xe9terminer quels sont les mots d'un texte? "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Utilisation de d\xe9limiteurs (ponctuation, espaces)"),(0,r.kt)("li",{parentName:"ul"},"Quelques difficult\xe9s (apostrophes, traits d'union, acronymes, mots compos\xe9s et noms propres, nombres et termes sp\xe9ciaux)")),(0,r.kt)("p",null,"Tokeniseurs : Split, Whitespace, WordPunct, Treebank, Tweet, Regexp avec NLTK."),(0,r.kt)("p",null,"Logiciels : Disponible dans toutes les librairies NLP."),(0,r.kt)("p",null,"Doit \xeatre efficace :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Utilisation d'espressions r\xe9guli\xe8res"),(0,r.kt)("li",{parentName:"ul"},'On peut faire une passe suppl\xe9mentaire, avec un dictionnaire, pour corriger les "erreurs".')),(0,r.kt)("h3",{id:"normalisation-de-mots"},"Normalisation de mots"),(0,r.kt)("p",null,"Pour quelques applications, il n'est pas n\xe9cessaires de conserver tous les termes (ex. pluriels)."),(0,r.kt)("p",null,"On veut d\xe9finir des classes d'\xe9quivalence."),(0,r.kt)("h4",{id:"analyse-morphologique"},"Analyse morphologique"),(0,r.kt)("p",null,"La morphologie est l'\xe9tude de la composition des mots. On peut diviser les morph\xe8nes en deux groupes :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Racines (stems) : les morph\xe8mes lexicaux"),(0,r.kt)("li",{parentName:"ul"},"Affixes : les morph\xe8mes grammaticaux adh\xe8rent aux racines pour changer leur signification et leurs fonctions lexicales.",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Pr\xe9fixe : avant le radical (au d\xe9but du mot)"),(0,r.kt)("li",{parentName:"ul"},"Suffixe : apr\xe8s le radical (\xe0 la fin du mot)"),(0,r.kt)("li",{parentName:"ul"},"Infixe : au milieu du radical ou de part et d'autre (rare!)"))),(0,r.kt)("li",{parentName:"ul"},"Deux grandes classes de morph\xe8nes grammaticaux - Affixes:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"D\xe9rivatifs (",(0,r.kt)("em",{parentName:"li"},"derivational"),"): ",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Change verbes ou adjectifs en noms."),(0,r.kt)("li",{parentName:"ul"},"Change noms ou verbes verbe ou un adjectif en un nom."),(0,r.kt)("li",{parentName:"ul"},'Ex. "-ment" change les adjectifs en adverbes'))),(0,r.kt)("li",{parentName:"ul"},"Flexionnels (",(0,r.kt)("em",{parentName:"li"},"inflexctional"),")",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Ex. Plusieur ou f\xe9minin")))))),(0,r.kt)("p",null,"L'analyse morphologique ne serait pas souvent utilis\xe9e en NLP."),(0,r.kt)("h4",{id:"lemmatisation"},"Lemmatisation"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Alternative \xe0 l'analyse morphologique."),(0,r.kt)("li",{parentName:"ul"},"R\xe9duire les formes de surface \xe0 une seule forme de base",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"est, suis, somme > \xeatre"),(0,r.kt)("li",{parentName:"ul"},"l', le, la, les > le"),(0,r.kt)("li",{parentName:"ul"},"beau, bel, belle > beau"))),(0,r.kt)("li",{parentName:"ul"},"Approches de lemmatisation \xe0 l'aide de r\xe8gles et d'un lexique",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Par ex. la fonction ",(0,r.kt)("inlineCode",{parentName:"li"},"morphy")," de ",(0,r.kt)("a",{parentName:"li",href:"https://www.nltk.org/howto/wordnet.html"},"WordNet"),"."),(0,r.kt)("li",{parentName:"ul"},"Utilise des suffixes pour transformer le mot."),(0,r.kt)("li",{parentName:"ul"},"Tente de le trouver dans le lexique."),(0,r.kt)("li",{parentName:"ul"},"Exemple ",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"abilitie",(0,r.kt)("strong",{parentName:"li"},"s")," > abilitie: No"),(0,r.kt)("li",{parentName:"ul"},"abiliti",(0,r.kt)("strong",{parentName:"li"},"es")," > abilitie: No"),(0,r.kt)("li",{parentName:"ul"},"abilit",(0,r.kt)("strong",{parentName:"li"},"ies")," > ability: Yes"))))),(0,r.kt)("li",{parentName:"ul"},"Les approches les plus efficaces utilisent des approches probabilistes",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Par ex. les Hidden Markov Model (HMM)  ")))),(0,r.kt)("h4",{id:"stemming"},"Stemming"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Pour certaines t\xe2ches langagi\xe8res, il n'est pas n\xe9cessaire de faire une analyse complexe."),(0,r.kt)("li",{parentName:"ul"},"Stemming (racinisation)",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Une approche plus simple que la lemmatisation et l'analyse morphologique"),(0,r.kt)("li",{parentName:"ul"},"Ne n\xe9cessite pas de connaissance lexicale."),(0,r.kt)("li",{parentName:"ul"},"Vise seulement \xe0 trouver une racine (stem) pour le mot."))),(0,r.kt)("li",{parentName:"ul"},"Approche ",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Tronquer la fin d'un mot \xe0 l'aide de r\xe8gles de r\xe9\xe9criture."),(0,r.kt)("li",{parentName:"ul"},"Aucun lexique."),(0,r.kt)("li",{parentName:"ul"},"D\xe9pend de la langue.",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Pour l'anglais : Lovins, Porter, Snowball"),(0,r.kt)("li",{parentName:"ul"},"Pour le fran\xe7ais : Snowball"))),(0,r.kt)("li",{parentName:"ul"},"Exemples",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"EN: automate, automatic, automation > automat"),(0,r.kt)("li",{parentName:"ul"},"FR: continuit\xe9, continuait, continuation > continue")))))),(0,r.kt)("p",null,"Voir ",(0,r.kt)("a",{parentName:"p",href:"http://text-processing.com/demo/stem"},"Python NLTK Demos for Natural Language Text Processing"),"."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"http://tartarus.org/~martin/PorterStemmer/index.html"},"Porter stemmer"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"L'algorithme le plus courant"),(0,r.kt)("li",{parentName:"ul"},"Cascade de r\xe8gles simples pour convertir la terminaison du mot."),(0,r.kt)("li",{parentName:"ul"},"Ex. organizers > organizer > organize > organ"),(0,r.kt)("li",{parentName:"ul"},"Ce traitement peut faire des erreurs.")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import nltk\nfrom nltk.stem import PorterStemmer\n\nps = PorterStemmer()\n\nprint(ps.stem('code'))\nprint(ps.stem('coding'))\nprint(ps.stem('coder'))\nprint(ps.stem('coded'))\n")),(0,r.kt)("p",null,"Voir ",(0,r.kt)("a",{parentName:"p",href:"https://www.nltk.org/howto/stem.html"},"Sample usage for stem"),"."),(0,r.kt)("h3",{id:"segmentation-de-phrases"},"Segmentation de phrases"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"D\xe9couper un texte en phrases."),(0,r.kt)("li",{parentName:"ul"},"D\xe9limit\xe9es par un symbole de ponctuation.",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"!")," et ",(0,r.kt)("inlineCode",{parentName:"li"},"?")," : assez fiable, sauf que..."),(0,r.kt)("li",{parentName:"ul"},"Point ",(0,r.kt)("inlineCode",{parentName:"li"},".")," : quelques ambigu\xeft\xe9s (ex. ing., Ph.D., 3.141592)"),(0,r.kt)("li",{parentName:"ul"},"Point de suspension ... Interruption de phrase ou h\xe9sitation?"))),(0,r.kt)("li",{parentName:"ul"},"On peut approximer \xe0 l'aide de r\xe8gles."),(0,r.kt)("li",{parentName:"ul"},"Quelle information devrait-on utiliser?",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Le mot apr\xe8s d\xe9bute par une majuscule"),(0,r.kt)("li",{parentName:"ul"},"Le mot avant est tout en majuscule"),(0,r.kt)("li",{parentName:"ul"},"Pr\xe9c\xe9d\xe9 d'une abr\xe9viation"),(0,r.kt)("li",{parentName:"ul"},"Pr\xe9c\xe9d\xe9 et suivi de caract\xe8res sans espace"),(0,r.kt)("li",{parentName:"ul"},"Suivi de plusieurs espaces"),(0,r.kt)("li",{parentName:"ul"},"Pr\xe9c\xe9d\xe9/suivi de signes de ponctuation"),(0,r.kt)("li",{parentName:"ul"},"Suivi de guillemets ",(0,r.kt)("inlineCode",{parentName:"li"},'"')))),(0,r.kt)("li",{parentName:"ul"},"Approches",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"D\xe9cision prise pour chaque signe de ponctuation."),(0,r.kt)("li",{parentName:"ul"},"D\xe9cision prise selon le contexte."),(0,r.kt)("li",{parentName:"ul"},"Les approches les plus efficaces utilisent des techniques d'apprentissage automatique (classification binaire).")))),(0,r.kt)("h3",{id:"logiciels-et-ressources"},"Logiciels et ressources"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Tokenisation, segmentation et lemmatisation avec ",(0,r.kt)("a",{parentName:"li",href:"https://spacy.io/api/lemmatizer"},"Spacy"),"."),(0,r.kt)("li",{parentName:"ul"},"Tokenisation avec ",(0,r.kt)("a",{parentName:"li",href:"https://www.nltk.org/api/nltk.tokenize.html"},"NLTK"),"."),(0,r.kt)("li",{parentName:"ul"},"Tokeniseur, segmenteur de phrase et lemmatiseur de ",(0,r.kt)("a",{parentName:"li",href:"http://nlp.stanford.edu/software/corenlp.shtml"},"Stanford NLP")," (populaire au d\xe9but des ann\xe9es 2000)."),(0,r.kt)("li",{parentName:"ul"},"Des impl\xe9mentations de ",(0,r.kt)("em",{parentName:"li"},"stemmers")," : ",(0,r.kt)("a",{parentName:"li",href:"http://tartarus.org/~martin/PorterStemmer/index.html"},"Porter"),", ",(0,r.kt)("a",{parentName:"li",href:"http://www.cs.waikato.ac.nz/~eibe/stemmers/index.html"},"Lovins"),", ",(0,r.kt)("a",{parentName:"li",href:"https://www.nltk.org/_modules/nltk/stem/lancaster.html"},"Lancaster"),", ",(0,r.kt)("a",{parentName:"li",href:"http://snowball.tartarus.org/"},"SnowBall"),"."),(0,r.kt)("li",{parentName:"ul"},"Des sites en ligne pour la distance d'\xe9dition",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"http://www.let.rug.nl/~kleiweg/lev/"},"http://www.let.rug.nl/~kleiweg/lev/")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://phiresky.github.io/levenshtein-demo/"},"https://phiresky.github.io/levenshtein-demo/"))))),(0,r.kt)("h2",{id:"3-mod\xe8les-de-langue-n-grammes"},"3. Mod\xe8les de langue N-grammes"),(0,r.kt)("h2",{id:"4-classification-de-textes"},"4. Classification de textes"),(0,r.kt)("h2",{id:"5-s\xe9mantique-vectorielle-repr\xe9sentation-des-mots"},"5. S\xe9mantique vectorielle (repr\xe9sentation des mots)"),(0,r.kt)("h2",{id:"6-deep-nlp-plongements-de-mots-word-embeddings--intro-aux-r\xe9seaux-de-neurones"},"6. Deep NLP: Plongements de mots (word embeddings) + intro aux r\xe9seaux de neurones"),(0,r.kt)("h2",{id:"7-\xe9tiquetage-de-s\xe9quences---analyse-grammaticale-part-of-speech-tagging-et-reconnaissance-dentit\xe9s-nomm\xe9es"},"7. \xc9tiquetage de s\xe9quences - analyse grammaticale (Part of speech tagging) et reconnaissance d'entit\xe9s nomm\xe9es"),(0,r.kt)("h2",{id:"8-deep-nlp---r\xe9seaux-r\xe9currents-pour-le-traitement-de-s\xe9quences-rnn-gru-lstm"},"8. Deep NLP - R\xe9seaux r\xe9currents pour le traitement de s\xe9quences (RNN, GRU, LSTM)"),(0,r.kt)("h2",{id:"9-deep-nlp---introduction-aux-mod\xe8les-transformers"},"9. Deep NLP - Introduction aux mod\xe8les Transformers"),(0,r.kt)("h2",{id:"10-deep-nlp---traduction-automatique-et-mod\xe8le-encodeur-d\xe9codeur"},"10. Deep NLP - Traduction automatique et mod\xe8le encodeur-d\xe9codeur"),(0,r.kt)("h2",{id:"11-deep-nlp---plongements-contextuels-et-mod\xe8les-de-langue-pr\xe9entra\xeen\xe9s-bert-et-al"},"11. Deep NLP - Plongements contextuels et mod\xe8les de langue pr\xe9entra\xeen\xe9s (Bert et al.)"),(0,r.kt)("h2",{id:"12-deep-nlp---prompting-et-instruct-tuning"},"12. Deep NLP - Prompting et instruct tuning"),(0,r.kt)("h2",{id:"13-deep-nlp---syst\xe8mes-question-r\xe9ponse-qa"},"13. Deep NLP - Syst\xe8mes question-r\xe9ponse (QA)"),(0,r.kt)("h2",{id:"annexe-a-logiciels-pour-le-traitement-automatique-de-la-langue-naturelle"},"Annexe A. Logiciels pour le traitement automatique de la langue naturelle"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.nltk.org/"},"NLTK")," et ",(0,r.kt)("a",{parentName:"li",href:"https://www.nltk.org/book/"},"Livre en ligne"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://spacy.io/"},"Spacy")," et ",(0,r.kt)("a",{parentName:"li",href:"https://spacy.io/usage/spacy-101"},"Documentation"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://huggingface.co/"},"Hugging Face"),"."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://scikit-learn.org/stable/"},"Scikit-learn"),".",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Pr\xe9traitement de textes avec les classes ",(0,r.kt)("a",{parentName:"li",href:"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"},"CountVectorizer"),"\net ",(0,r.kt)("a",{parentName:"li",href:"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"},"TfidfVectorizer")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pytorch.org/"},"PyTorch"),".",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Quelques extensions pour l'analyse de textes dont ",(0,r.kt)("a",{parentName:"li",href:"https://pytorchnlp.readthedocs.io/en/latest/"},"PyTorch-NLP")," et ",(0,r.kt)("a",{parentName:"li",href:"https://torchtext.readthedocs.io/en/latest/"},"TorchText"),".")))),(0,r.kt)("h2",{id:"annexe-b-travaux-pratiques-pour-lautomne-2022"},"Annexe B. Travaux pratiques pour l'automne 2022"),(0,r.kt)("h3",{id:"travail-pratique-1"},"Travail pratique 1"),(0,r.kt)("h2",{id:"annexe-c-correction-dorthographe-\xe0-titre-informatif-seulement"},"Annexe C. Correction d'orthographe (\xe0 titre informatif seulement)"),(0,r.kt)("h2",{id:"annexe-d-mod\xe8les-de-traduction-statistique-\xe0-titre-informatif-seulement"},"Annexe D. Mod\xe8les de traduction statistique (\xe0 titre informatif seulement)"),(0,r.kt)("h2",{id:"annexe-e-analyse-syntaxique-\xe0-titre-informatif-seulement"},"Annexe E. Analyse syntaxique (\xe0 titre informatif seulement)"),(0,r.kt)("h2",{id:"annexe-f---syst\xe8mes-question-r\xe9ponse-qa---ancienne-version"},"Annexe F - Syst\xe8mes question-r\xe9ponse (QA) - Ancienne version"),(0,r.kt)("h2",{id:"annexe-g-extraction-dinformation-\xe0-titre-informatif-seulement"},"Annexe G. Extraction d'information (\xe0 titre informatif seulement)"))}d.isMDXComponent=!0}}]);
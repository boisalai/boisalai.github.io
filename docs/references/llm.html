<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-references/llm">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Large Language Models (LLMs) | Alain Boisvert</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://boisalai.github.io/docs/references/llm"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Large Language Models (LLMs) | Alain Boisvert"><meta data-rh="true" name="description" content="ChatBot"><meta data-rh="true" property="og:description" content="ChatBot"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://boisalai.github.io/docs/references/llm"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/references/llm" hreflang="en"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/references/llm" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.077224b7.css">
<link rel="preload" href="/assets/js/runtime~main.7bdf4c35.js" as="script">
<link rel="preload" href="/assets/js/main.4ee3156d.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Alain Boisvert</b></a><a class="navbar__item navbar__link" href="/docs/cv">Curriculum vitæ</a><a href="https://github.com/boisalai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link"> </a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Alain Boisvert</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/cv">Curriculum vitæ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/learning">Learning path</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/certificates">Certificates</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/courses">Courses</a><button aria-label="Toggle the collapsible sidebar category &#x27;Courses&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/code-snippets">Code Snippets</a><button aria-label="Toggle the collapsible sidebar category &#x27;Code Snippets&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/references">References</a><button aria-label="Toggle the collapsible sidebar category &#x27;References&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/references/command-line">Command Line</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/references/llm">Large Language Models (LLMs)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/references/sas">SAS</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/references"><span itemprop="name">References</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Large Language Models (LLMs)</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Large Language Models (LLMs)</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="chatbot">ChatBot<a href="#chatbot" class="hash-link" aria-label="Direct link to ChatBot" title="Direct link to ChatBot">​</a></h2><ul><li><a href="https://chat.openai.com/" target="_blank" rel="noopener noreferrer">ChatGPT</a> from OpenAI.</li><li><a href="https://www.bing.com/" target="_blank" rel="noopener noreferrer">Bing</a> from Microsoft.</li><li><a href="https://www.perplexity.ai/" target="_blank" rel="noopener noreferrer">Perplexity.ai</a>, a new chatbot based on OpenAI&#x27;s ChatGPT.</li><li><a href="https://bard.google.com/" target="_blank" rel="noopener noreferrer">Bard</a> from Google, not currently supported in Canada.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="models">Models<a href="#models" class="hash-link" aria-label="Direct link to Models" title="Direct link to Models">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="openai-gpt">OpenAI GPT<a href="#openai-gpt" class="hash-link" aria-label="Direct link to OpenAI GPT" title="Direct link to OpenAI GPT">​</a></h3><ul><li><a href="https://platform.openai.com/overview" target="_blank" rel="noopener noreferrer">OpenAI platform</a>.</li><li><a href="https://platform.openai.com/docs/models/gpt-4" target="_blank" rel="noopener noreferrer">GPT-4</a>.</li><li><a href="https://platform.openai.com/docs/models/gpt-3-5" target="_blank" rel="noopener noreferrer">GPT-3.5</a>.</li><li><code>gpt-3.5-turbo</code> has been optimized for chat using the <a href="https://platform.openai.com/docs/api-reference/chat" target="_blank" rel="noopener noreferrer">Chat completions API</a>. </li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="llama">Llama<a href="#llama" class="hash-link" aria-label="Direct link to Llama" title="Direct link to Llama">​</a></h3><ul><li><a href="https://arxiv.org/abs/2302.13971" target="_blank" rel="noopener noreferrer">LLaMA: Open and Efficient Foundation Language Models</a>.</li><li><a href="https://ai.meta.com/llama/" target="_blank" rel="noopener noreferrer">Meta AI Introducing Llama 2</a>.</li><li><a href="https://huggingface.co/papers/2307.09288" target="_blank" rel="noopener noreferrer">Llama 2 Research Paper</a>.</li><li><a href="https://huggingface.co/meta-llama" target="_blank" rel="noopener noreferrer">Llama 2 on Hugging Face</a>.</li><li><a href="https://github.com/facebookresearch/llama-recipes/tree/main" target="_blank" rel="noopener noreferrer">Meta Examples and recipes for Llama model</a>.</li><li><a href="https://labs.perplexity.ai/?utm_content=first_codellama&amp;s=u&amp;utm_source=twitter&amp;utm_campaign=labs" target="_blank" rel="noopener noreferrer">LLaMa Chat</a> on Perplexity.<ul><li><a href="https://www.mosaicml.com/blog/llama2-inference" target="_blank" rel="noopener noreferrer">Introducing Llama2-70B-Chat with MosaicML Inference</a>.</li></ul></li><li>Code Llama<ul><li><a href="https://huggingface.co/codellama" target="_blank" rel="noopener noreferrer">Code Llama</a></li><li><a href="https://huggingface.co/blog/codellama" target="_blank" rel="noopener noreferrer">Llama 2 learns to code</a>.</li><li><a href="https://arxiv.org/pdf/2308.12950.pdf" target="_blank" rel="noopener noreferrer">Code Llama: Open Foundation Models for Code</a></li><li><a href="https://github.com/facebookresearch/codellama" target="_blank" rel="noopener noreferrer">Llama repository</a></li></ul></li><li>Reddit<ul><li><a href="https://www.reddit.com/r/LocalLLaMA/" target="_blank" rel="noopener noreferrer">r/LocalLLaMA/</a></li><li><a href="https://www.reddit.com/r/LocalLLaMA/wiki/models/" target="_blank" rel="noopener noreferrer">r/LocalLLaMA/wiki/models/</a></li></ul></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="falcon">Falcon<a href="#falcon" class="hash-link" aria-label="Direct link to Falcon" title="Direct link to Falcon">​</a></h3><ul><li><a href="https://huggingface.co/tiiuae/falcon-40b" target="_blank" rel="noopener noreferrer">Falcon-40B</a>.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="wizardlm">WizardLM<a href="#wizardlm" class="hash-link" aria-label="Direct link to WizardLM" title="Direct link to WizardLM">​</a></h3><ul><li><a href="https://github.com/nlpxucan/WizardLM" target="_blank" rel="noopener noreferrer">WizardLM repository</a>.</li><li><a href="https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0" target="_blank" rel="noopener noreferrer">WizardLM/WizardCoder-Python-34B-V1.0</a>.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="methods">Methods<a href="#methods" class="hash-link" aria-label="Direct link to Methods" title="Direct link to Methods">​</a></h2><ul><li>Fine-Tuning</li><li>Retrieval-Augmented Generation (RAG)</li><li>Chain of Thought<ul><li><a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html" target="_blank" rel="noopener noreferrer">Language Models Perform Reasoning via Chain of Thought</a>.
This method enables models to decompose multi-step problems into intermediate steps. </li><li><a href="https://arxiv.org/pdf/2201.11903.pdf" target="_blank" rel="noopener noreferrer">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>.</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tools">Tools<a href="#tools" class="hash-link" aria-label="Direct link to Tools" title="Direct link to Tools">​</a></h2><ul><li>Microsoft <a href="https://github.com/microsoft/DeepSpeed" target="_blank" rel="noopener noreferrer">DeepSpeed</a>: Optimization library. </li><li>OpenAI <a href="https://platform.openai.com/docs/api-reference" target="_blank" rel="noopener noreferrer">API Reference</a>.</li><li><a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a>: Port of Facebook&#x27;s LLaMA model in C/C++.</li><li><a href="https://python.langchain.com/docs/get_started/introduction.html" target="_blank" rel="noopener noreferrer">LangChain</a> is a framework
for developing applications powered by language models.<ul><li><a href="https://api.python.langchain.com/en/latest/api_reference.html" target="_blank" rel="noopener noreferrer">langchain API Reference</a>.</li><li><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer">LangChain Github</a>.</li><li><a href="https://blog.langchain.dev/" target="_blank" rel="noopener noreferrer">LangChain Blog</a>.</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation">Evaluation<a href="#evaluation" class="hash-link" aria-label="Direct link to Evaluation" title="Direct link to Evaluation">​</a></h2><ul><li><a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="noopener noreferrer">BLEU</a> (bilingual evaluation understudy) is an algorithm for evaluating the quality of
text which has been machine-translated from one natural language to another.
See also <a href="https://huggingface.co/spaces/evaluate-metric/bleu" target="_blank" rel="noopener noreferrer">here</a>.</li><li><a href="https://github.com/openai/evals" target="_blank" rel="noopener noreferrer">Evals</a> is a framework for evaluating LLMs and LLM systems,
and an open-source registry of benchmarks.</li><li><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" target="_blank" rel="noopener noreferrer">🤗 Open LLM Leaderboard</a>.<ul><li><a href="https://huggingface.co/blog/evaluating-mmlu-leaderboard" target="_blank" rel="noopener noreferrer">What&#x27;s going on with the Open LLM Leaderboard?</a>.</li></ul></li><li><a href="https://huggingface.co/spaces/bigcode/multilingual-code-evals" target="_blank" rel="noopener noreferrer">🤗 Multilingual Code Models Evaluation</a>.</li><li><a href="https://www.mosaicml.com/llm-evaluation" target="_blank" rel="noopener noreferrer">Mosaic LLM Evaluation Leaderboard</a>.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="instructions">Instructions<a href="#instructions" class="hash-link" aria-label="Direct link to Instructions" title="Direct link to Instructions">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-llama-2-on-mac-m1m2">Using Llama 2 on Mac M1/M2<a href="#using-llama-2-on-mac-m1m2" class="hash-link" aria-label="Direct link to Using Llama 2 on Mac M1/M2" title="Direct link to Using Llama 2 on Mac M1/M2">​</a></h3><blockquote><p>Created 2023-08-26. Last updated 2023-08-26.</p></blockquote><ol><li>Download the original version of Llama from <a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">https://github.com/facebookresearch/llama</a> and extract it to a <code>llama-main</code> folder.</li><li>Download the cpu version from <a href="https://github.com/krychu/llama" target="_blank" rel="noopener noreferrer">https://github.com/krychu/llama</a>, extract it and replace files in the <code>llama-main</code> folder.</li><li>Go to the <code>llama-main</code> folder.</li><li>Follow the instructions in the <a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">README</a> to run the <code>download.sh</code> script.
<a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/" target="_blank" rel="noopener noreferrer">Request a new download link</a>.
Then run the <code>download.sh</code> script, passing the URL provided when prompted to start the download. </li><li>Create a virtual environment with <code>python3 -m venv env</code> and activate it with <code>source env/bin/activate</code>.</li><li>Install the cpu version of pytorch with <code>python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu</code>.</li><li>Install dependencies of llama with <code>python3 -m pip install -e .</code>.</li><li>Run <code>torchrun</code> like below.</li></ol><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/facebookresearch/llama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">mv</span><span class="token plain"> llama llama-main</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/krychu/llama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">cp</span><span class="token plain"> -r llama/ llama-main/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token builtin class-name">cd</span><span class="token plain"> llama-main </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> u+x download.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ ./download.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Enter the URL from email: https://download.llamameta.net/*?Policy</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">eyJTdGF0Z</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 -m venv </span><span class="token function" style="color:#d73a49">env</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token builtin class-name">source</span><span class="token plain"> env/bin/activate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 -m pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> torch torchvision torchaudio </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --index-url https://download.pytorch.org/whl/cpu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 -m pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> -e </span><span class="token builtin class-name">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ torchrun --nproc_per_node </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  example_text_completion.py </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --ckpt_dir llama-2-7b/ </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --tokenizer_path tokenizer.model </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --max_seq_len </span><span class="token number" style="color:#36acaa">128</span><span class="token plain"> --max_batch_size </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic">#(instead of 4)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>I get a failure with this message: <code>RuntimeError: Distributed package doesn&#x27;t have NCCL built in</code></p><p>Instead, people are using <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">https://github.com/ggerganov/llama.cpp</a>, which is a Port of Facebook&#x27;s LLaMA model in C/C++.</p><p>Found this link <a href="https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0" target="_blank" rel="noopener noreferrer">https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0</a>. Will try this.</p><p>Reference:</p><ul><li><a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">https://github.com/facebookresearch/llama</a></li><li><a href="https://github.com/facebookresearch/llama/issues/433#issuecomment-1650002750" target="_blank" rel="noopener noreferrer">https://github.com/facebookresearch/llama/issues/433#issuecomment-1650002750</a></li><li><a href="https://github.com/krychu/llama" target="_blank" rel="noopener noreferrer">https://github.com/krychu/llama</a></li><li><a href="https://github.com/aggiee/llama-v2-mps" target="_blank" rel="noopener noreferrer">https://github.com/aggiee/llama-v2-mps</a></li><li><a href="https://ryandam.net/blog/2023/8/2/using-llama2/index.html" target="_blank" rel="noopener noreferrer">https://ryandam.net/blog/2023/8/2/using-llama2/index.html</a></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="courses">Courses<a href="#courses" class="hash-link" aria-label="Direct link to Courses" title="Direct link to Courses">​</a></h2><ul><li>Standford <a href="https://stanford-cs324.github.io/winter2022/" target="_blank" rel="noopener noreferrer">CS324 - Large Language Models</a>.</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/gpt">GPT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/llama">Llama</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/references/command-line"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Command Line</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/references/sas"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">SAS</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#chatbot" class="table-of-contents__link toc-highlight">ChatBot</a></li><li><a href="#models" class="table-of-contents__link toc-highlight">Models</a><ul><li><a href="#openai-gpt" class="table-of-contents__link toc-highlight">OpenAI GPT</a></li><li><a href="#llama" class="table-of-contents__link toc-highlight">Llama</a></li><li><a href="#falcon" class="table-of-contents__link toc-highlight">Falcon</a></li><li><a href="#wizardlm" class="table-of-contents__link toc-highlight">WizardLM</a></li></ul></li><li><a href="#methods" class="table-of-contents__link toc-highlight">Methods</a></li><li><a href="#tools" class="table-of-contents__link toc-highlight">Tools</a></li><li><a href="#evaluation" class="table-of-contents__link toc-highlight">Evaluation</a></li><li><a href="#instructions" class="table-of-contents__link toc-highlight">Instructions</a><ul><li><a href="#using-llama-2-on-mac-m1m2" class="table-of-contents__link toc-highlight">Using Llama 2 on Mac M1/M2</a></li></ul></li><li><a href="#courses" class="table-of-contents__link toc-highlight">Courses</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Alain Boisvert. Construit avec Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.7bdf4c35.js"></script>
<script src="/assets/js/main.4ee3156d.js"></script>
</body>
</html>
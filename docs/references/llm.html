<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-references/llm">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Large Language Models (LLMs) | Alain Boisvert</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://boisalai.github.io/docs/references/llm"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Large Language Models (LLMs) | Alain Boisvert"><meta data-rh="true" name="description" content="&quot;The limits of my language mean the limits of my world.&quot; &amp;#x2014; Ludwig Wittgenstein"><meta data-rh="true" property="og:description" content="&quot;The limits of my language mean the limits of my world.&quot; &amp;#x2014; Ludwig Wittgenstein"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://boisalai.github.io/docs/references/llm"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/references/llm" hreflang="en"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/references/llm" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.fabb9ed5.css">
<link rel="preload" href="/assets/js/runtime~main.24a853f4.js" as="script">
<link rel="preload" href="/assets/js/main.1bf6aa8e.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Alain Boisvert</b></a><a class="navbar__item navbar__link" href="/docs/cv">Curriculum vitæ</a><a href="https://github.com/boisalai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><a href="https://www.linkedin.com/in/alain-boisvert-98b058156/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Alain Boisvert</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/cv">Curriculum vitæ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/learning">Learning path</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/certificates">Certificates</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/courses">Courses</a><button aria-label="Toggle the collapsible sidebar category &#x27;Courses&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/references">References</a><button aria-label="Toggle the collapsible sidebar category &#x27;References&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/references/links">Curated Links</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/references/command-line">Command Line</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/references/sas">SAS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/references/llm">Large Language Models (LLMs)</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/code-snippets">Code Snippets</a><button aria-label="Toggle the collapsible sidebar category &#x27;Code Snippets&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/references"><span itemprop="name">References</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Large Language Models (LLMs)</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Large Language Models (LLMs)</h1><p><em>&quot;The limits of my language mean the limits of my world.&quot;</em> <!-- -->—<!-- --> Ludwig Wittgenstein</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="models">Models<a href="#models" class="hash-link" aria-label="Direct link to Models" title="Direct link to Models">​</a></h2><p>Large language models (LLMs) refer to Transformer language models that contain hundreds of billions (or
more) of parameters, which are trained on massive text data.</p><p>See also <a href="https://crfm.stanford.edu/ecosystem-graphs/index.html" target="_blank" rel="noopener noreferrer">Table of LLMs</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="open-source">Open Source<a href="#open-source" class="hash-link" aria-label="Direct link to Open Source" title="Direct link to Open Source">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="stanford-alpaca">Stanford Alpaca<a href="#stanford-alpaca" class="hash-link" aria-label="Direct link to Stanford Alpaca" title="Direct link to Stanford Alpaca">​</a></h4><ul><li><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" target="_blank" rel="noopener noreferrer">https://crfm.stanford.edu/2023/03/13/alpaca.html</a></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="databricks-dolly">Databricks Dolly<a href="#databricks-dolly" class="hash-link" aria-label="Direct link to Databricks Dolly" title="Direct link to Databricks Dolly">​</a></h4><ul><li><a href="https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html" target="_blank" rel="noopener noreferrer">Dolly v1</a>.</li><li><a href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm" target="_blank" rel="noopener noreferrer">Dolly v2</a>.</li><li><a href="https://huggingface.co/datasets/databricks/databricks-dolly-15k" target="_blank" rel="noopener noreferrer">databricks/databricks-dolly-15k</a>.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="eleutherai-pythia">EleutherAI Pythia<a href="#eleutherai-pythia" class="hash-link" aria-label="Direct link to EleutherAI Pythia" title="Direct link to EleutherAI Pythia">​</a></h4><ul><li><a href="https://huggingface.co/EleutherAI/pythia-12b" target="_blank" rel="noopener noreferrer">EleutherAI/pythia-12b</a>.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="facebook-llama">Facebook Llama<a href="#facebook-llama" class="hash-link" aria-label="Direct link to Facebook Llama" title="Direct link to Facebook Llama">​</a></h4><ul><li><a href="https://arxiv.org/abs/2302.13971" target="_blank" rel="noopener noreferrer">LLaMA: Open and Efficient Foundation Language Models</a>.</li><li><a href="https://ai.meta.com/llama/" target="_blank" rel="noopener noreferrer">Meta AI Introducing Llama 2</a>.</li><li><a href="https://huggingface.co/papers/2307.09288" target="_blank" rel="noopener noreferrer">Llama 2 Research Paper</a>.</li><li><a href="https://huggingface.co/meta-llama" target="_blank" rel="noopener noreferrer">Llama 2 on Hugging Face</a>.</li><li><a href="https://github.com/facebookresearch/llama-recipes/tree/main" target="_blank" rel="noopener noreferrer">Meta Examples and recipes for Llama model</a>.</li><li><a href="https://labs.perplexity.ai/?utm_content=first_codellama&amp;s=u&amp;utm_source=twitter&amp;utm_campaign=labs" target="_blank" rel="noopener noreferrer">LLaMa Chat</a> on Perplexity.<ul><li><a href="https://www.mosaicml.com/blog/llama2-inference" target="_blank" rel="noopener noreferrer">Introducing Llama2-70B-Chat with MosaicML Inference</a>.</li></ul></li><li>Code Llama<ul><li><a href="https://huggingface.co/codellama" target="_blank" rel="noopener noreferrer">Code Llama</a>.</li><li><a href="https://huggingface.co/blog/codellama" target="_blank" rel="noopener noreferrer">Llama 2 learns to code</a>.</li><li><a href="https://arxiv.org/pdf/2308.12950.pdf" target="_blank" rel="noopener noreferrer">Code Llama: Open Foundation Models for Code</a></li><li><a href="https://github.com/facebookresearch/codellama" target="_blank" rel="noopener noreferrer">Llama repository</a></li></ul></li><li>Reddit<ul><li><a href="https://www.reddit.com/r/LocalLLaMA/" target="_blank" rel="noopener noreferrer">r/LocalLLaMA/</a></li><li><a href="https://www.reddit.com/r/LocalLLaMA/wiki/models/" target="_blank" rel="noopener noreferrer">r/LocalLLaMA/wiki/models/</a></li></ul></li><li><a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/" target="_blank" rel="noopener noreferrer">Request access</a> to the next version of Llama.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="tii-falcon">TII Falcon<a href="#tii-falcon" class="hash-link" aria-label="Direct link to TII Falcon" title="Direct link to TII Falcon">​</a></h4><ul><li><a href="https://huggingface.co/tiiuae/falcon-40b" target="_blank" rel="noopener noreferrer">Falcon-40B</a>.</li><li><a href="https://huggingface.co/blog/falcon-180b" target="_blank" rel="noopener noreferrer">Spread Your Wings: Falcon 180B is here</a>.
** Falcon 180b can be commercially used but under very restrictive conditions, excluding any &quot;hosting use&quot;.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="mosaic-mpt">Mosaic MPT<a href="#mosaic-mpt" class="hash-link" aria-label="Direct link to Mosaic MPT" title="Direct link to Mosaic MPT">​</a></h4><ul><li><a href="https://www.mosaicml.com/" target="_blank" rel="noopener noreferrer">https://www.mosaicml.com/</a></li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="stablelm">StableLM<a href="#stablelm" class="hash-link" aria-label="Direct link to StableLM" title="Direct link to StableLM">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="vicuna">Vicuna<a href="#vicuna" class="hash-link" aria-label="Direct link to Vicuna" title="Direct link to Vicuna">​</a></h4><h4 class="anchor anchorWithStickyNavbar_LWe7" id="wizardlm">WizardLM<a href="#wizardlm" class="hash-link" aria-label="Direct link to WizardLM" title="Direct link to WizardLM">​</a></h4><ul><li><a href="https://github.com/nlpxucan/WizardLM" target="_blank" rel="noopener noreferrer">WizardLM repository</a>.</li><li><a href="https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0" target="_blank" rel="noopener noreferrer">WizardLM/WizardCoder-Python-34B-V1.0</a>.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="proprietary">Proprietary<a href="#proprietary" class="hash-link" aria-label="Direct link to Proprietary" title="Direct link to Proprietary">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpt">GPT<a href="#gpt" class="hash-link" aria-label="Direct link to GPT" title="Direct link to GPT">​</a></h4><ul><li><a href="https://platform.openai.com/overview" target="_blank" rel="noopener noreferrer">OpenAI platform</a>.</li><li><a href="https://platform.openai.com/docs/models/gpt-4" target="_blank" rel="noopener noreferrer">GPT-4</a>.</li><li><a href="https://platform.openai.com/docs/models/gpt-3-5" target="_blank" rel="noopener noreferrer">GPT-3.5</a>.</li><li><code>gpt-3.5-turbo</code> has been optimized for chat using the <a href="https://platform.openai.com/docs/api-reference/chat" target="_blank" rel="noopener noreferrer">Chat completions API</a>. </li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="chatbot">ChatBot<a href="#chatbot" class="hash-link" aria-label="Direct link to ChatBot" title="Direct link to ChatBot">​</a></h2><ul><li><a href="https://platform.openai.com/playground" target="_blank" rel="noopener noreferrer">OpenAI Playground</a>.</li><li><a href="https://chat.openai.com/" target="_blank" rel="noopener noreferrer">ChatGPT</a> from OpenAI.</li><li><a href="https://www.bing.com/" target="_blank" rel="noopener noreferrer">Bing</a> from Microsoft.</li><li><a href="https://www.perplexity.ai/" target="_blank" rel="noopener noreferrer">Perplexity</a>, a new chatbot based on OpenAI&#x27;s ChatGPT.</li><li><a href="https://bard.google.com/" target="_blank" rel="noopener noreferrer">Google Bard</a> from Google, currently not available in Canada.</li><li><a href="https://claude.ai/" target="_blank" rel="noopener noreferrer">Claude.ai</a> Claude.ai is only available in the US and UK. </li><li><a href="https://www.phind.com/" target="_blank" rel="noopener noreferrer">phind</a>.</li><li><a href="https://github.com/KillianLucas/open-interpreter/" target="_blank" rel="noopener noreferrer">Open Interpreter</a>.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="code-llms">Code LLMs<a href="#code-llms" class="hash-link" aria-label="Direct link to Code LLMs" title="Direct link to Code LLMs">​</a></h2><ul><li><a href="https://www.cursor.so/" target="_blank" rel="noopener noreferrer">cursor.so</a>.</li><li><a href="https://github.com/features/copilot" target="_blank" rel="noopener noreferrer">GitHub Copilot</a>.</li><li><a href="https://github.com/bigcode-project/starcoder" target="_blank" rel="noopener noreferrer">StarCoder</a> and <a href="https://huggingface.co/blog/starcoder" target="_blank" rel="noopener noreferrer">here</a>.</li><li><a href="https://alphacode.deepmind.com/" target="_blank" rel="noopener noreferrer">DeepMind AlphaCode</a>.</li><li><a href="https://aws.amazon.com/codewhisperer/" target="_blank" rel="noopener noreferrer">Amazon CodeWhisperer</a>.</li><li><a href="https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder" target="_blank" rel="noopener noreferrer">WizardCoder</a>.</li><li><a href="https://github.com/facebookresearch/codellama" target="_blank" rel="noopener noreferrer">Code Llama</a>.</li><li><a href="https://huggingface.co/collections/lmstudio-ai/metaais-codellama-coding-assistant-llm-64fb1d4ab60e2c9ddd07f8e6" target="_blank" rel="noopener noreferrer">MetaAI&#x27;s CodeLlama - Coding Assistant LLM</a>: Fast, small, and capable coding model you can run locally,</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="leaderboard">Leaderboard<a href="#leaderboard" class="hash-link" aria-label="Direct link to Leaderboard" title="Direct link to Leaderboard">​</a></h2><ul><li><a href="https://huggingface.co/collections/open-llm-leaderboard/the-big-benchmarks-collection-64faca6335a7fc7d4ffe974a" target="_blank" rel="noopener noreferrer">The Big Benchmarks Collection</a>.</li><li><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" target="_blank" rel="noopener noreferrer">🤗 Open LLM Leaderboard</a>.</li><li><a href="https://huggingface.co/spaces/optimum/llm-perf-leaderboard" target="_blank" rel="noopener noreferrer">🤗 Open LLM-Perf Leaderboard 🏋️</a>.</li><li><a href="https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard" target="_blank" rel="noopener noreferrer">⭐ Big Code Models Leaderboard</a>.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="common-nlp-tasks">Common NLP tasks<a href="#common-nlp-tasks" class="hash-link" aria-label="Direct link to Common NLP tasks" title="Direct link to Common NLP tasks">​</a></h2><ul><li>Summarization</li><li>Sentiment analysis</li><li>Translation</li><li><a href="https://huggingface.co/tasks/zero-shot-classification" target="_blank" rel="noopener noreferrer">Zero-shot classification</a>: A model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes.</li><li>Few-shot learning</li><li>Conversation / chat</li><li>Question-answering</li><li>Text classification</li><li>Text generation</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="choose-the-right-llm">Choose the right LLM<a href="#choose-the-right-llm" class="hash-link" aria-label="Direct link to Choose the right LLM" title="Direct link to Choose the right LLM">​</a></h2><p>There is no “perfect” model. Trade-offs are required. </p><p>Decision criteria</p><ul><li>Privacy</li><li>Quality </li><li>Cost</li><li>Latency</li><li>Customizability</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="training-llms">Training LLMs<a href="#training-llms" class="hash-link" aria-label="Direct link to Training LLMs" title="Direct link to Training LLMs">​</a></h2><p>There&#x27;s essentially three (3) approaches to training LLMs: pre-training, fine-tuning, and LoRA.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="techniques">Techniques<a href="#techniques" class="hash-link" aria-label="Direct link to Techniques" title="Direct link to Techniques">​</a></h2><ul><li>Tokenization: Transforming text into word-pieces.</li><li>Word Embeddings: Represent words with vectors.</li><li>Parameter-efficient fine-tuning (PEFT).<ul><li><a href="https://huggingface.co/blog/peft" target="_blank" rel="noopener noreferrer">🤗 PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware</a>.</li><li>Additive: Keep the foundation model weights frozen and update only the new layer weights. <ul><li>Soft Prompt tuning: Concatenates trainable parameters with the input embeddings.</li><li>Prefix tuning: Adding tunable layer to each transformer block, rather than just the input layer.</li></ul></li><li>Selective.<ul><li><a href="https://arxiv.org/abs/2106.10199" target="_blank" rel="noopener noreferrer">BitFit</a>: Only updates bias parameters.</li><li><a href="https://aclanthology.org/2021.acl-long.378/" target="_blank" rel="noopener noreferrer">Diff Pruning</a>: Create task-specific &quot;diff&quot; vectors and only updates them</li></ul></li><li>Re-parametrization: Decompose weight matrix updates into smaller-rank matrices.<ul><li><a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">Low-Rank Adaptation (LoRA)</a>, aim to refine a relatively small subset of
parameters, thereby minimizing resource utilization and accelerating the training cycle.</li><li>LoRA with ZeRO-3</li><li><a href="https://arxiv.org/abs/2205.05638" target="_blank" rel="noopener noreferrer">(IA)<sup>3</sup></a>.</li></ul></li><li><a href="https://github.com/Lightning-AI/lit-gpt/blob/main/tutorials/finetune_adapter.md" target="_blank" rel="noopener noreferrer">Finetune with Adapters</a>.</li></ul></li><li>Faster calculations<ul><li><a href="https://arxiv.org/abs/2205.14135" target="_blank" rel="noopener noreferrer">Flash Attention!</a>: Calculating attention in a flash.</li></ul></li><li>Improving Model Footprint<ul><li>Quantization <ul><li><a href="https://github.com/timdettmers/bitsandbytes" target="_blank" rel="noopener noreferrer">bitsandbytes</a> (4-bit quantization).</li><li>Quantized Low-Rank Adaptation (QLoRA)</li></ul></li><li><a href="https://github.com/ggerganov/ggml" target="_blank" rel="noopener noreferrer">GGML</a>.</li><li><strong>GGUF</strong> is a new format introduced by the llama.cpp team on August 21st 2023. It is a replacement for GGML,
which is no longer supported by llama.cpp.</li><li><a href="https://arxiv.org/abs/2210.17323" target="_blank" rel="noopener noreferrer">GPTQ</a> is a post-training quantziation method to compress LLMs.<ul><li>GPTQ compresses GPT models by reducing the number of bits needed to store each weight in the model, from 32 bits down to just 3-4 bits. </li><li>GPTQ analyzes each layer of the model separately and approximating the weights in a way that preserves the overall accuracy.</li><li>See <a href="https://www.philschmid.de/gptq-llama" target="_blank" rel="noopener noreferrer">Optimize open LLMs using GPTQ and Hugging Face Optimum</a>.</li><li><a href="https://huggingface.co/blog/gptq-integration" target="_blank" rel="noopener noreferrer">AutoGPTQ</a>.</li></ul></li></ul></li><li>Multi-LLM Inferencing<ul><li>Mixture-of-Experts (MoE) and <a href="https://arxiv.org/abs/2101.03961" target="_blank" rel="noopener noreferrer">Switch Transformer</a>.</li><li>LLM Cascades and <a href="https://arxiv.org/abs/2305.05176" target="_blank" rel="noopener noreferrer">FrugalGPT</a>.</li></ul></li><li>Multi-modal Language Models (MLLMs)<ul><li>Chain-of-Thought MLLMs</li><li><a href="https://arxiv.org/pdf/2201.11903.pdf" target="_blank" rel="noopener noreferrer">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>.</li><li><a href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html" target="_blank" rel="noopener noreferrer">Language Models Perform Reasoning via Chain of Thought</a>.</li></ul></li><li><a href="https://rentry.org/llm-training" target="_blank" rel="noopener noreferrer">The Novice&#x27;s LLM Training Guide</a>.  </li><li>Reinforcement learning with human feedback (RLHF)</li><li>Retrieval Augmented Generation (RAG)</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tools">Tools<a href="#tools" class="hash-link" aria-label="Direct link to Tools" title="Direct link to Tools">​</a></h2><ul><li><a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">🤗 Hugging Face</a>: The GitHub of Large Language Models<ul><li><a href="https://huggingface.co/datasets" target="_blank" rel="noopener noreferrer">Datasets</a>, pipelines, tokenizers, and <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">models</a>.</li><li><a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">🤗 Hugging Face Transformers</a>.</li><li><a href="https://huggingface.co/docs/transformers/transformers_agents" target="_blank" rel="noopener noreferrer">Transformers Agent</a>.</li></ul></li><li><a href="https://www.nltk.org/" target="_blank" rel="noopener noreferrer">NLTK</a>.</li><li><a href="https://spacy.io/" target="_blank" rel="noopener noreferrer">SpaCy</a>.</li><li><a href="https://radimrehurek.com/gensim/" target="_blank" rel="noopener noreferrer">Gensim</a>.</li><li><a href="https://pypi.org/project/openai/" target="_blank" rel="noopener noreferrer">OpenAI</a>.<ul><li>OpenAI <a href="https://platform.openai.com/docs/api-reference" target="_blank" rel="noopener noreferrer">API Reference</a>.</li></ul></li><li><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer">🦜️🔗 LangChain</a>.</li><li>Microsoft <a href="https://github.com/microsoft/DeepSpeed" target="_blank" rel="noopener noreferrer">DeepSpeed</a>: Optimization library. </li><li><a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a>: Port of Facebook&#x27;s LLaMA model in C/C++.</li><li><a href="https://ollama.ai/" target="_blank" rel="noopener noreferrer">Ollama</a>.</li><li>Vector stores (databases, libraries, plugins).<ul><li><a href="https://www.trychroma.com/" target="_blank" rel="noopener noreferrer">Chroma</a>.</li><li><a href="https://www.pinecone.io/" target="_blank" rel="noopener noreferrer">Pinecone</a>.</li><li><a href="https://github.com/pgvector/pgvector" target="_blank" rel="noopener noreferrer">PGVector</a>.</li></ul></li><li><a href="https://python.langchain.com/docs/guides/langsmith/" target="_blank" rel="noopener noreferrer">LangSmith</a>.</li><li><a href="https://github.com/explodinggradients/ragas" target="_blank" rel="noopener noreferrer">Ragas</a>: Evaluation framework for Retrieval Augmented Generation (RAG) pipelines. </li><li><a href="https://github.com/bigscience-workshop/petals" target="_blank" rel="noopener noreferrer">Petals</a> a system for inference and fine-tuning of large models
collaboratively by joining the resources of multiple parties [<a href="https://arxiv.org/pdf/2209.01188.pdf" target="_blank" rel="noopener noreferrer">Paper</a>].</li><li><a href="https://www.mendable.ai/" target="_blank" rel="noopener noreferrer">Mendable.ai</a></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="️-langchain">🦜️🔗 LangChain<a href="#️-langchain" class="hash-link" aria-label="Direct link to 🦜️🔗 LangChain" title="Direct link to 🦜️🔗 LangChain">​</a></h3><p><a href="https://python.langchain.com/docs/get_started/introduction.html" target="_blank" rel="noopener noreferrer">🦜️🔗 LangChain</a> is a framework
for developing applications powered by language models.</p><p>Released in late 2022. Useful for multi-stage reasoning, LLM-based workflows</p><p>The core idea of the library is that we can “chain” together different components to create more advanced use cases around LLMs. Chains may consist of multiple components from several modules:</p><ul><li><strong>Prompt templates</strong>: Prompt templates are templates for different types of prompts. Like “chatbot” style templates, ELI5 question-answering, etc</li><li><strong>LLMs</strong>: Large language models like GPT-3, BLOOM, etc</li><li><strong>Agents</strong>: Agents use LLMs to decide what actions should be taken. Tools like web search or calculators can be used, and all are packaged into a logical loop of operations.</li><li><strong>Memory</strong>: Short-term memory, long-term memory.</li></ul><p>See also:</p><ul><li><a href="https://api.python.langchain.com/en/latest/api_reference.html" target="_blank" rel="noopener noreferrer">API Reference</a>.</li><li><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer">Github</a>.</li><li><a href="https://blog.langchain.dev/" target="_blank" rel="noopener noreferrer">Blog</a>.</li><li><a href="https://www.pinecone.io/learn/series/langchain/" target="_blank" rel="noopener noreferrer">LangChain AI Handbook</a>.</li><li><a href="https://github.com/logspace-ai/langflow" target="_blank" rel="noopener noreferrer">⛓️ Langflow</a>.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="llamaindex">LlamaIndex<a href="#llamaindex" class="hash-link" aria-label="Direct link to LlamaIndex" title="Direct link to LlamaIndex">​</a></h3><p><a href="https://gpt-index.readthedocs.io/" target="_blank" rel="noopener noreferrer">LlamaIndex</a> is a toolkit for building LLM-powered applications over custom data. It consists of two stages: the indexing stage, where the knowledge base is prepared using data connectors and indexes, and the querying stage, where relevant context is retrieved from the knowledge base to assist the LLM in responding to a question. LlamaIndex provides building blocks such as retrievers, node postprocessors, and response synthesizers, as well as pipelines like query engines, chat engines, and agents.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="vector-stores">Vector Stores<a href="#vector-stores" class="hash-link" aria-label="Direct link to Vector Stores" title="Direct link to Vector Stores">​</a></h3><p>Using a vector store requires setting up an indexing pipeline to load data from sources (a website, a file, etc.),
transform the data into documents, embed those documents, and insert the embeddings and documents into the vector store.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation">Evaluation<a href="#evaluation" class="hash-link" aria-label="Direct link to Evaluation" title="Direct link to Evaluation">​</a></h2><p>A good language will model will have high accuracy and low perplexity.
Accuracy = next word is right or wrong. Perplexity = how confident was that choice. </p><ul><li><a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="noopener noreferrer">BLEU</a> (bilingual evaluation understudy) is an algorithm for evaluating the quality of
text which has been machine-translated from one natural language to another.</li><li><a href="https://aclanthology.org/W04-1013.pdf" target="_blank" rel="noopener noreferrer">ROUGE</a> for summarization.
See also <a href="https://huggingface.co/spaces/evaluate-metric/bleu" target="_blank" rel="noopener noreferrer">here</a>.</li><li>sacreBLEU, TER, ChrF, ChrF++, BERTScore, METEOR, and Semantic Similarity</li><li><a href="https://github.com/openai/evals" target="_blank" rel="noopener noreferrer">Evals</a> is a framework for evaluating LLMs and LLM systems,
and an open-source registry of benchmarks.</li><li><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" target="_blank" rel="noopener noreferrer">🤗 Open LLM Leaderboard</a>.<ul><li><a href="https://huggingface.co/blog/evaluating-mmlu-leaderboard" target="_blank" rel="noopener noreferrer">What&#x27;s going on with the Open LLM Leaderboard?</a>.</li></ul></li><li><a href="https://huggingface.co/spaces/bigcode/multilingual-code-evals" target="_blank" rel="noopener noreferrer">🤗 Multilingual Code Models Evaluation</a>.</li><li><a href="https://www.mosaicml.com/llm-evaluation" target="_blank" rel="noopener noreferrer">Mosaic LLM Evaluation Leaderboard</a>.</li></ul><p>See also <a href="https://github.com/Troyanovsky/Local-LLM-Comparison-Colab-UI" target="_blank" rel="noopener noreferrer">Local LLM Comparison &amp; Colab Links</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="papers">Papers<a href="#papers" class="hash-link" aria-label="Direct link to Papers" title="Direct link to Papers">​</a></h2><ul><li><strong>Attention is all you need</strong>, NIPS 2017. [<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer">Paper</a>].</li><li><strong>A Survey of Large Language Models</strong>, arXiv 2023. [<a href="https://arxiv.org/abs/2303.18223" target="_blank" rel="noopener noreferrer">Paper</a>, <a href="https://github.com/RUCAIBox/LLMSurvey" target="_blank" rel="noopener noreferrer">GitHub</a>].</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="instructions">Instructions<a href="#instructions" class="hash-link" aria-label="Direct link to Instructions" title="Direct link to Instructions">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-llama-2-on-mac-m1m2">Using Llama 2 on Mac M1/M2<a href="#using-llama-2-on-mac-m1m2" class="hash-link" aria-label="Direct link to Using Llama 2 on Mac M1/M2" title="Direct link to Using Llama 2 on Mac M1/M2">​</a></h3><blockquote><p>Created 2023-08-26. Last updated 2023-08-26.</p></blockquote><ol><li>Download the original version of Llama from <a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">https://github.com/facebookresearch/llama</a> and extract it to a <code>llama-main</code> folder.</li><li>Download the cpu version from <a href="https://github.com/krychu/llama" target="_blank" rel="noopener noreferrer">https://github.com/krychu/llama</a>, extract it and replace files in the <code>llama-main</code> folder.</li><li>Go to the <code>llama-main</code> folder.</li><li>Follow the instructions in the <a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">README</a> to run the <code>download.sh</code> script.
<a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/" target="_blank" rel="noopener noreferrer">Request a new download link</a>.
Then run the <code>download.sh</code> script, passing the URL provided when prompted to start the download. </li><li>Create a virtual environment with <code>python3 -m venv env</code> and activate it with <code>source env/bin/activate</code>.</li><li>Install the cpu version of pytorch with <code>python3 -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu</code>.</li><li>Install dependencies of llama with <code>python3 -m pip install -e .</code>.</li><li>Run <code>torchrun</code> like below.</li></ol><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/facebookresearch/llama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">mv</span><span class="token plain"> llama llama-main</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/krychu/llama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">cp</span><span class="token plain"> -r llama/ llama-main/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token builtin class-name">cd</span><span class="token plain"> llama-main </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> u+x download.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ ./download.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Enter the URL from email: https://download.llamameta.net/*?Policy</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">eyJTdGF0Z</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 -m venv </span><span class="token function" style="color:#d73a49">env</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ </span><span class="token builtin class-name">source</span><span class="token plain"> env/bin/activate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 -m pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> torch torchvision torchaudio </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --index-url https://download.pytorch.org/whl/cpu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ python3 -m pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> -e </span><span class="token builtin class-name">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ torchrun --nproc_per_node </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  example_text_completion.py </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --ckpt_dir llama-2-7b/ </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --tokenizer_path tokenizer.model </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --max_seq_len </span><span class="token number" style="color:#36acaa">128</span><span class="token plain"> --max_batch_size </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic">#(instead of 4)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>I get a failure with this message: <code>RuntimeError: Distributed package doesn&#x27;t have NCCL built in</code></p><p>Instead, people are using <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">https://github.com/ggerganov/llama.cpp</a>, which is a Port of Facebook&#x27;s LLaMA model in C/C++.</p><p>Found this link <a href="https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0" target="_blank" rel="noopener noreferrer">https://gist.github.com/cedrickchee/e8d4cb0c4b1df6cc47ce8b18457ebde0</a>. Will try this.</p><p>Reference:</p><ul><li><a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">https://github.com/facebookresearch/llama</a></li><li><a href="https://github.com/facebookresearch/llama/issues/433#issuecomment-1650002750" target="_blank" rel="noopener noreferrer">https://github.com/facebookresearch/llama/issues/433#issuecomment-1650002750</a></li><li><a href="https://github.com/krychu/llama" target="_blank" rel="noopener noreferrer">https://github.com/krychu/llama</a></li><li><a href="https://github.com/aggiee/llama-v2-mps" target="_blank" rel="noopener noreferrer">https://github.com/aggiee/llama-v2-mps</a></li><li><a href="https://ryandam.net/blog/2023/8/2/using-llama2/index.html" target="_blank" rel="noopener noreferrer">https://ryandam.net/blog/2023/8/2/using-llama2/index.html</a></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="courses">Courses<a href="#courses" class="hash-link" aria-label="Direct link to Courses" title="Direct link to Courses">​</a></h2><ul><li>Standford <a href="https://stanford-cs324.github.io/winter2022/" target="_blank" rel="noopener noreferrer">CS324 - Large Language Models</a>.</li></ul><ul><li><a href="https://learnprompting.org/" target="_blank" rel="noopener noreferrer">Learn Prompting</a>.</li><li><a href="https://t.co/uqjYkxBnWO" target="_blank" rel="noopener noreferrer">ChatGPT Prompt Engineering for Developers</a>.</li><li></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm-blogs">LLM Blogs<a href="#llm-blogs" class="hash-link" aria-label="Direct link to LLM Blogs" title="Direct link to LLM Blogs">​</a></h2><ul><li><a href="https://eugeneyan.com/" target="_blank" rel="noopener noreferrer">Eugene Yan</a>.</li><li><a href="https://huyenchip.com/" target="_blank" rel="noopener noreferrer">Chip Huyen</a>.</li><li><a href="https://medium.com/@iamleonie" target="_blank" rel="noopener noreferrer">Leonie Monigatti</a>.</li><li><a href="https://lilianweng.github.io/" target="_blank" rel="noopener noreferrer">Lilian Weng</a>.</li><li><a href="https://logankilpatrick.medium.com/" target="_blank" rel="noopener noreferrer">Logan Kilpatrick</a>.</li><li><a href="https://magazine.sebastianraschka.com/" target="_blank" rel="noopener noreferrer">Sebastian Raschka</a>.</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/gpt">GPT</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/llama">Llama</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/references/sas"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">SAS</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/category/code-snippets"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Code Snippets</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#models" class="table-of-contents__link toc-highlight">Models</a><ul><li><a href="#open-source" class="table-of-contents__link toc-highlight">Open Source</a></li><li><a href="#proprietary" class="table-of-contents__link toc-highlight">Proprietary</a></li></ul></li><li><a href="#chatbot" class="table-of-contents__link toc-highlight">ChatBot</a></li><li><a href="#code-llms" class="table-of-contents__link toc-highlight">Code LLMs</a></li><li><a href="#leaderboard" class="table-of-contents__link toc-highlight">Leaderboard</a></li><li><a href="#common-nlp-tasks" class="table-of-contents__link toc-highlight">Common NLP tasks</a></li><li><a href="#choose-the-right-llm" class="table-of-contents__link toc-highlight">Choose the right LLM</a></li><li><a href="#training-llms" class="table-of-contents__link toc-highlight">Training LLMs</a></li><li><a href="#techniques" class="table-of-contents__link toc-highlight">Techniques</a></li><li><a href="#tools" class="table-of-contents__link toc-highlight">Tools</a><ul><li><a href="#️-langchain" class="table-of-contents__link toc-highlight">🦜️🔗 LangChain</a></li><li><a href="#llamaindex" class="table-of-contents__link toc-highlight">LlamaIndex</a></li><li><a href="#vector-stores" class="table-of-contents__link toc-highlight">Vector Stores</a></li></ul></li><li><a href="#evaluation" class="table-of-contents__link toc-highlight">Evaluation</a></li><li><a href="#papers" class="table-of-contents__link toc-highlight">Papers</a></li><li><a href="#instructions" class="table-of-contents__link toc-highlight">Instructions</a><ul><li><a href="#using-llama-2-on-mac-m1m2" class="table-of-contents__link toc-highlight">Using Llama 2 on Mac M1/M2</a></li></ul></li><li><a href="#courses" class="table-of-contents__link toc-highlight">Courses</a></li><li><a href="#llm-blogs" class="table-of-contents__link toc-highlight">LLM Blogs</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Alain Boisvert. Construit avec Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.24a853f4.js"></script>
<script src="/assets/js/main.1bf6aa8e.js"></script>
</body>
</html>
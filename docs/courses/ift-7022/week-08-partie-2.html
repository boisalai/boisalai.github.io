<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-courses/ift-7022/week-08-partie-2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">Notions de base pour les RNN, GRU et LSTM | Alain Boisvert</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://boisalai.github.io/docs/courses/ift-7022/week-08-partie-2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Notions de base pour les RNN, GRU et LSTM | Alain Boisvert"><meta data-rh="true" name="description" content="On présente dans ce notebook quelques exemples simples afin d&#x27;illustrer des notions utiles pour la programmation de réseaux récurrents avec PyTorch :"><meta data-rh="true" property="og:description" content="On présente dans ce notebook quelques exemples simples afin d&#x27;illustrer des notions utiles pour la programmation de réseaux récurrents avec PyTorch :"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://boisalai.github.io/docs/courses/ift-7022/week-08-partie-2"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/ift-7022/week-08-partie-2" hreflang="en"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/ift-7022/week-08-partie-2" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Alain Boisvert RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Alain Boisvert Atom Feed">



<link rel="stylesheet" href="/fonts/font-awesome/fontawesome.css">
<link rel="stylesheet" href="/fonts/font-awesome/solid.css">
<link rel="stylesheet" href="/fonts/font-awesome/regular.css">
<link rel="stylesheet" href="/fonts/font-awesome/brands.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.b5c999da.css">
<script src="/assets/js/runtime~main.e6737288.js" defer="defer"></script>
<script src="/assets/js/main.a09b2bce.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Alain Boisvert</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" target="" href="/docs/courses/ift-7022">IFT-7022</a><a class="navbar__item navbar__link" target="" href="/docs/courses/gif-7005">GIF-7005</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/boisalai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-github"> </a><a href="https://www.linkedin.com/in/alain-boisvert-98b058156/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-linkedin-in"> </a><a href="mailto:ay.boisvert@gmail.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-solid fa-envelope"> </a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Alain Boisvert</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/cv">Curriculum vitæ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/learning">Learning path</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/certificates">Certificates</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/courses">Courses</a><button aria-label="Collapse sidebar category &#x27;Courses&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/courses/gif-7005">GIF-7005 Introduction à l&#x27;apprentissage automatique</a><button aria-label="Expand sidebar category &#x27;GIF-7005 Introduction à l&#x27;apprentissage automatique&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/courses/ift-7022">IFT-7022 Traitement automatique de la langue naturelle</a><button aria-label="Collapse sidebar category &#x27;IFT-7022 Traitement automatique de la langue naturelle&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-01">1 Expressions régulières</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-02">2 Prétraitement de textes et distance minimale d&#x27;édition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-03">3 Modèles de langue N-grammes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-04">4 Classification de textes</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-05">5 Sémantique vectorielle (représentation des mots)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-06">6 Deep NLP + Plongements de mots (word embeddings) + intro aux réseaux de neurones</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-07">7 Étiquetage de séquences - analyse grammaticale (Part of speech tagging) et reconnaissance d&#x27;entités nommées</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-08-partie-1">8 Deep NLP - Réseaux récurrents pour le traitement de séquences (RNN, GRU, LSTM)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/courses/ift-7022/week-08-partie-2">8 Notions de base pour les RNN, GRU et LSTM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-09">9 Deep NLP - Introduction aux modèles Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-10">10 Deep NLP - Plongements contextuels et modèles encodeurs pré-entraînés</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-11">11 Deep NLP - Traduction automatique et modèle encodeur-décodeur</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/week-12">12 Deep NLP - Systèmes question-réponse (QA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/travail-1">Travail pratique 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/travail-2">Travail pratique 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/travail-3">Travail pratique 3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/exam-intra">Examen de mi-session</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/ift-7022/exam-final">Examen final</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chatgpt-building-systems">Building Systems with the ChatGPT API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chatgpt-prompt-engineering">ChatGPT Prompt Engineering for Developers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/fine-tuning-llms">Training and fine-tuning LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/langchain-1">LangChain for LLM Application Development</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/pair-prog-with-llm">Pair Programming with a Large Language Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chat-with-your-data">LangChain Chat with Your Data</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/references">References</a><button aria-label="Expand sidebar category &#x27;References&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/code-snippets">Code Snippets</a><button aria-label="Expand sidebar category &#x27;Code Snippets&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/courses"><span itemprop="name">Courses</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/courses/ift-7022"><span itemprop="name">IFT-7022 Traitement automatique de la langue naturelle</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">8 Notions de base pour les RNN, GRU et LSTM</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Notions de base pour les RNN, GRU et LSTM</h1>
<p>On présente dans ce notebook quelques exemples simples afin d&#x27;illustrer des notions utiles pour la programmation de réseaux récurrents avec PyTorch :</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-création-dune-couche-rnn-ou-gru">1. Création d&#x27;une couche RNN ou GRU<a href="#1-création-dune-couche-rnn-ou-gru" class="hash-link" aria-label="Direct link to 1. Création d&#x27;une couche RNN ou GRU" title="Direct link to 1. Création d&#x27;une couche RNN ou GRU">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="11-couche-récurrente-rnn">1.1. Couche récurrente RNN<a href="#11-couche-récurrente-rnn" class="hash-link" aria-label="Direct link to 1.1. Couche récurrente RNN" title="Direct link to 1.1. Couche récurrente RNN">​</a></h3>
<p>On illustre ici la création d&#x27;une couche RNN avec PyTorch en utilisant la classe <code>nn.RNN</code>.</p>
<p>Les principaux arguments pour la création d&#x27;une couche récurrrente (<code>rnn_layer</code>) sont la dimension
de la couches d&#x27;entrée (<code>input_size</code>), la dimension de la couche cachée (<code>hidden_size</code>). On limite
notre problème jouet à une couche d&#x27;entrée de dimension 4 et une couche cachée contenant 3 neurones.</p>
<p>Dans cet exemple-ci, la matrice <strong>W</strong> qui relie un input à la couche cachée a une dimension 4X3
tandis que la matrice <strong>U</strong> qui relie la couche cachée précédente à la couche cachée actuelle est de 3X3.
Nous n&#x27;avons pas dans cette exemple de matrice <strong>V</strong> qui relierait la couche cachée à un couche de sortie
additionnelle qui ferait une prédiction (par exemple un classification du texte ou un étiquetage de mot).</p>
<p>Les poids du réseau récurrent (les matrices <strong>W</strong> et <strong>U</strong>) sont initialisée aléatoirement lors de
la création de la couche RNN.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch import nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_dimension = 4</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden_dimension = 3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">rnn_layer = nn.RNN(input_size=input_dimension, hidden_size=hidden_dimension, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">rnn_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># RNN(4, 3, batch_first=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On retrouve l&#x27;argument optionnel <code>batch_first</code> qui indique la forme des tenseurs données en inputs
durant l&#x27;entraînement (les <em>minibatchs</em>). Lorsque <code>batch_first</code> est <code>True</code>, la 1ere dimension du tenseur
de minibatch correspond au nombre d&#x27;exemples dans la minibatch. Si sa valeur est <code>False</code>, la première
dimension correspond à la longueur des séquences.</p>
<p>Pour illustrer l&#x27;utilisation de la couche RNN <code>rnn_layer</code>, on lui soumet une seule séquence afin d&#x27;observer
l&#x27;output qui est retournée par la couche. La séquence contient 2 éléments, ce qui pourrait correspondre à la
représentation d&#x27;un court texte qui contient 2 <em>embeddings</em> de mots. Comme on a défini la dimension des
embeddings à 4, l&#x27;input au RNN correspond à une matrice 1 X 2 X 4 (c.-à-d. une seule séquence qui contient
2 mots représentés par des <em>embeddings</em> de dimension 4).</p>
<p>Pour traiter la séquence, le RNN a besoin d&#x27;un état caché initiale <em>h0</em> (<code>hidden0</code> dans le code). On y va ici
avec un vecteur de 0, indiquant que nous n&#x27;avons aucune information à prendre en compte avant de traiter cette
séquence. Une autre option qu&#x27;on voit parfois est la génération d&#x27;un état caché initial contenant des valeurs aléatoires.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">emb1 = [0.9, 0.8, 0.7 , 0.6]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">emb2 = [0.1, 0.2, 0.3 , 0.4]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">sequence = [[emb1, emb2]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">inputs = torch.FloatTensor(sequence)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Inputs du RNN:\n&quot;, inputs)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden0 = torch.zeros(1, 1, 3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nÉtat caché initial du RNN:\n&quot;, hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output, hidden = rnn_layer(inputs, hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Inputs du RNN:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[0.9000, 0.8000, 0.7000, 0.6000],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [0.1000, 0.2000, 0.3000, 0.4000]]])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># État caché initial du RNN:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[0., 0., 0.]]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On inspecte les résultats produits par la couche RNN. Le premier résultat <code>output</code> contient la liste des états cachés
par le réseau dans le traitement de la séquence en input. On retrouvera donc 2 vecteurs d&#x27;état caché qui ont été
générés pour les inputs <code>emb1</code> et <code>emb2</code>. Le deuxième résultat hidden correspond au dernier état caché généré
par le réseau (c.-à-d. l&#x27;état caché associé au dernier mot de la séquence - dans notre cas <code>emb2</code>).</p>
<p>À noter dans ces exemples l&#x27;utilisation de la fonction <code>squeeze()</code> qui élimine les dimensions d&#x27;un tenseur égales à 1.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.set_printoptions(precision=4)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Output:&quot;, output)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Hidden:&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Output: tensor([[[-0.4870,  0.5099, -0.4016],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.4997, -0.2191, -0.3646]]], grad_fn=&lt;TransposeBackward1&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Hidden: tensor([[[-0.4997, -0.2191, -0.3646]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden1 = output[:, 0, :].squeeze().tolist()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;État caché hidden1 qui correspond au 1er input: &quot;, hidden1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># État caché hidden1 qui correspond au 1er input:  [-0.48698967695236206, 0.5099459290504456,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># -0.4015676975250244]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden2 = output[:, 1, :].squeeze().tolist()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;État caché hidden2 qui correspond au 2e input:&quot;, hidden2)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># État caché hidden2 qui correspond au 2e input: [-0.49973031878471375, -0.2191120833158493,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># -0.3646095395088196]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Dernier état caché du RNN:&quot;, hidden.squeeze().tolist())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Dernier état caché du RNN: [-0.49973031878471375, -0.2191120833158493, -0.3646095395088196]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="12-couche-récurrente-gru">1.2 Couche récurrente GRU<a href="#12-couche-récurrente-gru" class="hash-link" aria-label="Direct link to 1.2 Couche récurrente GRU" title="Direct link to 1.2 Couche récurrente GRU">​</a></h3>
<p>On refait le même exercice avec un GRU. Comme le nombre d&#x27;input et d&#x27;output d&#x27;un GRU est le même que ceux d&#x27;un RNN,
la seule modification à faire est d&#x27;utiliser la classe <code>nn.GRU</code> pour créer la couche récurrente. Tout le reste est
identique et on réutilise l&#x27;input et l&#x27;état caché initial (<code>hidden0</code>) de la partie 1.1 de ce notebook.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">gru_layer = nn.GRU(input_size=input_dimension, hidden_size=hidden_dimension, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output, hidden = gru_layer(inputs, hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">gru_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># GRU(4, 3, batch_first=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">output</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[[ 0.0524, -0.2793, -0.1730],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0454, -0.1000, -0.1087]]], grad_fn=&lt;TransposeBackward1&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[[ 0.0454, -0.1000, -0.1087]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="13-stacked-rnn">1.3 Stacked RNN<a href="#13-stacked-rnn" class="hash-link" aria-label="Direct link to 1.3 Stacked RNN" title="Direct link to 1.3 Stacked RNN">​</a></h3>
<p>Un réseau récurrent peut avoir plusieurs couches superposées (<em>stacked RNNs</em>, voir section 9.5.1 de Jurafsky et Martin).
Le nombre de couches est déterminé par le paramètre <code>num_layers</code>. Par défaut, les RNNs n&#x27;ont qu&#x27;une seule couche (<code>num_layers=1</code>).</p>
<p>Voici un exemple à 3 couches. Nous avons toujours des inputs de dimensions 3.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">stacked_rnn_layer = nn.RNN(input_size=input_dimension, hidden_size=hidden_dimension, batch_first=True, num_layers=3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">stacked_rnn_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># RNN(4, 3, num_layers=3, batch_first=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 3 couches dans le RNN, 1 seul exemple à traiter, hidden_dimension = 3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">stacked_hidden0 = torch.zeros(3, 1, 3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output, hidden = stacked_rnn_layer(inputs, stacked_hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nÉtat caché initial du stacked RNN - 1 vecteur par couche:\n&quot;, stacked_hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># État caché initial du stacked RNN - 1 vecteur par couche:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[0., 0., 0.]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [[0., 0., 0.]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [[0., 0., 0.]]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.set_printoptions(precision=4)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Les outputs produits en sortie de la dernière couche du stacked RNN pour chacun des 2 mots de la séquence (output):\n&quot;, output)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nLes vecteurs de chacune des 3 couches cachées pour le dernier mot de la séquence (hidden):\n&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Les outputs produits en sortie de la dernière couche du stacked RNN pour chacun des 2 mots de la séquence (output):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"> tensor([[[-0.4371, -0.6443, -0.3190],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">         [-0.6356, -0.3190, -0.2104]]], grad_fn=&lt;TransposeBackward1&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Les vecteurs de chacune des 3 couches cachées pour le dernier mot de la séquence (hidden):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"> tensor([[[-0.6729, -0.4056, -0.7022]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        [[ 0.1081,  0.8286,  0.5611]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        [[-0.6356, -0.3190, -0.2104]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="14-rnn-bidirectionnel">1.4 RNN bidirectionnel<a href="#14-rnn-bidirectionnel" class="hash-link" aria-label="Direct link to 1.4 RNN bidirectionnel" title="Direct link to 1.4 RNN bidirectionnel">​</a></h3>
<p>On peut créer un RNN bidirectionnel en activant l&#x27;argument <code>bidirectional</code>. On obtient alors 2 RNNs qui traitent les inputs
dans des directions opposées - a) de gauche à droite et b) de droite à gauche (voir section 9.5.2 de Jurafsky et Martin).
Vous noterez dans cet exemple que les états cachés produits par le RNN bidirectionnel (output) sont la concaténation des
états cachés de chacun des RNNs directionnels (c.-à-d. les 2 états associés au même jeton sont mis bout à bout).</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">bidirectional_rnn_layer = nn.RNN(input_size=input_dimension, hidden_size=hidden_dimension,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                 batch_first=True, bidirectional=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">bidirectional_rnn_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># RNN(4, 3, batch_first=True, bidirectional=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 2 couches bidirectionnelles, 1 exemple, taille des états cachés = 3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">bi_hidden0 = torch.zeros(2, 1, 3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output, hidden = bidirectional_rnn_layer(inputs, bi_hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nÉtat caché initial du biRNN - 1 vecteur pour initialiser chaque direction:\n&quot;, bi_hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># État caché initial du biRNN - 1 vecteur pour initialiser chaque direction:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[0., 0., 0.]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [[0., 0., 0.]]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.set_printoptions(precision=4)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Les états cachés du biRNN pour chaque mots - concaténation des états cachés de chacun des RNNs directionnels (output):\n&quot;, output)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nLes vecteurs en sortie de chacun de 2 RNNs directionnels (hidden):\n&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Les états cachés du biRNN pour chaque mots - concaténation des états cachés de chacun des RNNs directionnels (output):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[ 0.8223,  0.0209, -0.7598, -0.4576,  0.9166, -0.2191],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.5874, -0.4373, -0.5055, -0.3148,  0.5022,  0.4569]]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#        grad_fn=&lt;TransposeBackward1&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#Les vecteurs en sortie de chacun de 2 RNNs directionnels (hidden):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[[ 0.5874, -0.4373, -0.5055]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#        [[-0.4576,  0.9166, -0.2191]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="15-ajouter-une-couche-de-prédiction-à-la-sortie-dun-rnn">1.5 Ajouter une couche de prédiction à la sortie d&#x27;un RNN<a href="#15-ajouter-une-couche-de-prédiction-à-la-sortie-dun-rnn" class="hash-link" aria-label="Direct link to 1.5 Ajouter une couche de prédiction à la sortie d&#x27;un RNN" title="Direct link to 1.5 Ajouter une couche de prédiction à la sortie d&#x27;un RNN">​</a></h3>
<p>On a vu dans le cours qu&#x27;un réseau récurrent peut être défini par 3 matrices de poids :</p>
<ul>
<li><strong>W</strong> qui relie les inputs à la couche cachée</li>
<li><strong>U</strong> qui relie l&#x27;état caché précédent à l&#x27;état caché actuel</li>
<li><strong>V</strong> qui permet de faire une prédiction à partir du contenu de l&#x27;état caché (c.-à-d. une tête de prédiction).</li>
</ul>
<p>Les exemples précédents ne contenaient que les 2 premières matrices. Voici un exemple simplifié de réseau récurrent GRU
<code>SimpleGRUTagger</code> qui fait une prédiction binaire pour chaque mot d&#x27;un texte (un étiquetage). On applique une fonction
d&#x27;activation ReLU à la couche intermédiaire. On utilise les poids initiaux pour faire les prédictions (pas d&#x27;entraînement
du réseau dans cet exemple). À noter que lorsque l&#x27;état initial <em>h0</em> du réseau récurrent n&#x27;est pas spécifié,
des vecteurs de 0s sont utilisés.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">class SimpleGRUTagger(nn.Module):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, input_dim, hidden_dim, output_dim):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super(SimpleGRUTagger, self).__init__()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.hidden_dim = hidden_dim</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.gru_layer = nn.GRU(input_dim, hidden_dim, batch_first=True)  # Défini W et U</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.fc = nn.Linear(hidden_dim, output_dim)  # Correspond à V</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.relu = nn.ReLU()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def forward(self, x, h):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        out, h = self.gru_layer(x, h)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # V est appliqué à chacun des états cachés = étiquetage de tous les mots</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        out = self.fc(self.relu(out))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return out, h</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_dimension = 4</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden_dimension = 3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output_dimension = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">simple_tagger = SimpleGRUTagger(input_dimension, hidden_dimension, output_dimension)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">simple_tagger</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># SimpleGRUTagger(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#   (gru_layer): GRU(4, 3, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#   (fc): Linear(in_features=3, out_features=1, bias=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#   (relu): ReLU()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># )</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Input - 2 _embeddings_ donnés à l&#x27;étiqueteur GRU:\n&quot;, inputs)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Input - 2 _embeddings_ donnés à l&#x27;étiqueteur GRU:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[0.9000, 0.8000, 0.7000, 0.6000],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [0.1000, 0.2000, 0.3000, 0.4000]]])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">predictions, hidden = simple_tagger(inputs, hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Les prédictions pour ces 2 mots:\n&quot;, predictions)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Les prédictions pour ces 2 mots:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[-0.3666],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.3458]]], grad_fn=&lt;AddBackward0&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Le dernier état caché du réseau:\n&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Le dernier état caché du réseau:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[-0.1405,  0.3199,  0.0720]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Un exemple similaire pour un réseau <code>SimpleGRUClassifier</code> qui fait la classification binaire d&#x27;une séquence
complète. À noter que la seule différence est dans la fonction forward qui n&#x27;applique la tête de prédiction (la matrice <strong>V</strong>)
que sur l&#x27;état final du réseau récurrent.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">class SimpleGRUClassifier(nn.Module):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, input_dim, hidden_dim, output_dim):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super(SimpleGRUClassifier, self).__init__()  # Une différence mineure</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.hidden_dim = hidden_dim</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.gru_layer = nn.GRU(input_dim, hidden_dim, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.fc = nn.Linear(hidden_dim, output_dim)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.relu = nn.ReLU()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def forward(self, x, h):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        out, h = self.gru_layer(x, h)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # V est appliqué au dernier état caché = classification du texte</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        out = self.fc(self.relu(out[:,-1]))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return out, h</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output_dimension = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">simple_classifier = SimpleGRUClassifier(input_dimension, hidden_dimension, output_dimension)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">prediction, hidden = simple_classifier(inputs, hidden0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;La prédiction pour ce mini-texte:\n&quot;, prediction)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nLe dernier état caché du réseau:\n&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># La prédiction pour ce mini-texte:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[0.4064]], grad_fn=&lt;AddmmBackward&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Le dernier état caché du réseau:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[-0.0279,  0.3144,  0.2712]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-création-dun-lstm">2. Création d&#x27;un LSTM<a href="#2-création-dun-lstm" class="hash-link" aria-label="Direct link to 2. Création d&#x27;un LSTM" title="Direct link to 2. Création d&#x27;un LSTM">​</a></h2>
<p>D&#x27;un point de vue programmation, la seule différence entre un RNN et un LSTM est que le LSTM
manipule 2 vecteurs latents: 1 vecteur d&#x27;état caché (mémoire court-terme - <em>hidden</em>) et un vecteur de contexte (mémoire
long-terme - <em>context</em>). Pour initialiser le traitement d&#x27;une séquence, il faut donc créer 2 vecteurs d&#x27;initialisation
(<code>hidden0</code> et <code>context0</code>). Et en sortie, <code>hidden</code> contient les 2 vecteurs finaux, ceux de la couche cachée et du contexte long-terme.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">lstm_layer = nn.LSTM(input_size=input_dimension, hidden_size=hidden_dimension, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden0 = torch.zeros(1, 1, 3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">context0 = torch.zeros(1, 1, 3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output, (hidden, context) = lstm_layer(inputs, (hidden0, context0))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">lstm_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># LSTM(4, 3, batch_first=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">output</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">tensor([[[ 0.0474,  0.0503,  0.0086],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">         [ 0.1201,  0.1592, -0.0042]]], grad_fn=&lt;TransposeBackward0&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Ce sont les deux vecteurs d&#x27;état caché <code>h1</code> et <code>h2</code>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Dernier état caché:\n&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Dernier état caché:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[ 0.1201,  0.1592, -0.0042]]], grad_fn=&lt;StackBackward&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Dernier vecteur de contexte du réseau:\n&quot;, context)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Dernier vecteur de contexte du réseau:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[ 0.3921,  0.3844, -0.0104]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On voit ici que le vecteur <code>hidden</code> correspond au dernier état caché du LSTM (voir 2e vecteur de <code>output</code>) tandis que le
vecteur <code>context</code> correspond au contexte long-terme qui a été produit à la dernière récurrence.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-passer-des-embeddings-préentraînés-directement-comme-input-dun-réseau-récurrent">3. Passer des <em>embeddings</em> préentraînés directement comme input d&#x27;un réseau récurrent<a href="#3-passer-des-embeddings-préentraînés-directement-comme-input-dun-réseau-récurrent" class="hash-link" aria-label="Direct link to 3-passer-des-embeddings-préentraînés-directement-comme-input-dun-réseau-récurrent" title="Direct link to 3-passer-des-embeddings-préentraînés-directement-comme-input-dun-réseau-récurrent">​</a></h2>
<p>On illustre ici le passage direct de plongements préentraînés à une couche récurrente. On utilise les <em>embeddings</em> de Spacy.
Ce code pour obtenir les <em>embeddings</em> se retrouverait normalement dans une classe de Dataset.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import spacy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch import FloatTensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spacy_en = spacy.load(&#x27;en_core_web_md&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def get_spacy_embeddings(text, spacy_analyzer):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    doc = spacy_analyzer(text)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    _embeddings_ = [token.vector for token in doc]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return FloatTensor(embeddings)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Init Plugin</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Init Graph Optimizer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Init Kernel</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">example = &quot;This is an example&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embeddings = get_spacy_embeddings(example, spacy_en)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Dimensions des _embeddings_ de cet exemple:&quot;, embeddings.shape)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Dimensions des _embeddings_ de cet exemple: torch.Size([4, 300])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Les embeddings:&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embeddings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Les embeddings:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[-0.0876,  0.3550,  0.0639,  ...,  0.0345, -0.1503,  0.4067],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.0850,  0.5020,  0.0024,  ..., -0.2151, -0.2630, -0.0060],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.0117,  0.1948,  0.0889,  ..., -0.0547, -0.1934,  0.1400],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.2713,  0.2902, -0.2893,  ..., -0.0983,  0.0059,  0.2856]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># On ajoute une dimension=1 pour obtenir un tenseur de minibatch qui contient notre seul</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># exemple contenant les embeddings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_tensor = torch.unsqueeze(embeddings, dim=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Dimensions du tenseur en input du RNN =&quot;, input_tensor.shape)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\t= (nombre d&#x27;exemples, longueur des exemples, dimension des embeddings)&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_tensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Dimensions du tenseur en input du RNN = torch.Size([1, 4, 300])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  = (nombre d&#x27;exemples, longueur des exemples, dimension des embeddings)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[[-0.0876,  0.3550,  0.0639,  ...,  0.0345, -0.1503,  0.4067],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.0850,  0.5020,  0.0024,  ..., -0.2151, -0.2630, -0.0060],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.0117,  0.1948,  0.0889,  ..., -0.0547, -0.1934,  0.1400],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.2713,  0.2902, -0.2893,  ..., -0.0983,  0.0059,  0.2856]]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># La dimension des vecteurs d&#x27;embeddings de Spacy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spacy_embedding_dim = spacy_en.meta[&#x27;vectors&#x27;][&#x27;width&#x27;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_dimension = spacy_embedding_dim</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden_dimension = 4  # Couche cachée de faible dimension pour visualiser les résultats</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spacy_rnn_layer = nn.RNN(input_size=input_dimension, hidden_size=hidden_dimension, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">output, hidden = spacy_rnn_layer(input_tensor)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;On retrouve encore une fois les usuels output:\n&quot;, output)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\net hidden:\n&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># On retrouve encore une fois les usuels output:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[ 0.7739,  0.9987, -0.8505,  0.7156],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.7215,  0.9681, -0.0299, -0.7905],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.9722,  0.9991,  0.0179, -0.8747],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.9392,  0.9870, -0.7154,  0.3561]]], grad_fn=&lt;TransposeBackward1&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># et hidden:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[-0.9392,  0.9870, -0.7154,  0.3561]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-couche-dembeddings-pour-convertir-les-mots-en-plongements">4. Couche d&#x27;<em>embeddings</em> pour convertir les mots en plongements<a href="#4-couche-dembeddings-pour-convertir-les-mots-en-plongements" class="hash-link" aria-label="Direct link to 4-couche-dembeddings-pour-convertir-les-mots-en-plongements" title="Direct link to 4-couche-dembeddings-pour-convertir-les-mots-en-plongements">​</a></h2>
<p>PyTorch offre la classe <code>nn.Embedding</code> qui permet de construire une couche de réseau qui convertit des mots en vecteurs
de plongement (<em>embeddings</em>). On dénomme cette couche <em>embedding layer</em>. En gros, on peut voir cette classe comme une matrice
(ou une couche linéaire) qui contient les <em>embeddings</em> des mots d&#x27;un vocabulaire. Les mots sont associés à des identifiants
(des entiers de 0 à N-1 qui correspondent aux N mots de notre vocabulaire).</p>
<p>Pour traiter un texte avec un réseau récurrent contenant une couche d&#x27;<em>embeddings</em>, on remplace tout d&#x27;abord chaque mot
du texte par son identifiant et on passe cette liste d&#x27;entiers à la couche d&#x27;<em>embeddings</em> qui retourne les <em>embeddings</em>
associés aux identifiants de mots. On peut par la suite rendre ces plongements disponible aux couches suivantes du réseau.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-pour-aller-rapidement-à-lessentiel">4.1 Pour aller rapidement à l&#x27;essentiel<a href="#41-pour-aller-rapidement-à-lessentiel" class="hash-link" aria-label="Direct link to 4.1 Pour aller rapidement à l&#x27;essentiel" title="Direct link to 4.1 Pour aller rapidement à l&#x27;essentiel">​</a></h3>
<p>Un exemple jouet pour illustrer la mécanique de cette classe.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">num_words = 3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_dimension = 5</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer = nn.Embedding(num_words, embedding_dimension)  # valeurs initialisées aléatoirement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Embedding(3, 5)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>La couche d&#x27;<em>embeddings</em> est initialisée aléatoirement avec des valeurs suivant une loi normale (0, 1).</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_ids = [2]  # Notre texte contient 1 seul mot qui correspond à l&#x27;identifiant 2 (c.-à-d. 2e mot du vocabulaire)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word_id = torch.LongTensor(text_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer(word_id)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[-0.1250,  0.1272,  0.2590,  1.1000,  0.1559]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#        grad_fn=&lt;EmbeddingBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_ids = [0, 1, 2]  # Notre texte contient 3 mots dont les identifiants dont 0, 1 et 2.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word_ids = torch.LongTensor(text_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer(word_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[-0.4157, -0.2084, -0.8642,  0.8541,  0.3090],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.7784,  2.3099,  2.1679,  0.6308,  1.0504],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.1250,  0.1272,  0.2590,  1.1000,  0.1559]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#        grad_fn=&lt;EmbeddingBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-ajout-dun-jeton-de-padding-rembourrage-dans-la-couche-dembeddings">4.2 Ajout d&#x27;un jeton de <em>padding</em> (rembourrage) dans la couche d&#x27;<em>embeddings</em><a href="#42-ajout-dun-jeton-de-padding-rembourrage-dans-la-couche-dembeddings" class="hash-link" aria-label="Direct link to 42-ajout-dun-jeton-de-padding-rembourrage-dans-la-couche-dembeddings" title="Direct link to 42-ajout-dun-jeton-de-padding-rembourrage-dans-la-couche-dembeddings">​</a></h3>
<p>Le rembourrage (<em>padding</em>) est fréquemment utilisé dans les réseaux de neurones, surtout pour le traitement de
minibatch. Lorsqu&#x27;on veut traiter des séquences de longueurs fixes, le rembourrage consiste à ajouter des jetons
de padding afin d&#x27;obtenir la bonne longueur de séquence. Par exemple, pour une longueur désirée de 6 jetons,
la liste de jetons du texte &quot;<em>ceci est un exemple</em>&quot; deviendrait: [ceci, est, un, exemple, &amp;lt;PAD&gt;, &amp;lt;PAD&gt;]</p>
<p>Dans la couche d&#x27;<em>embeddings</em>, la convention est d&#x27;associer l&#x27;identifiant 0 au jeton de padding. Pour l&#x27;activer,
on choisit l&#x27;option <code>padding_idx=0</code>. Il est toutefois possible de choisir un autre numéro d&#x27;identifiant au besoin
(cela est seulement une convention).</p>
<p>Par défaut, on associe au jeton de padding un vecteur rempli de 0s.</p>
<p>Voici un exemple.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch import nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">num_words = 3</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_dimension = 5</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">padding_id = 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">padding_token = &#x27;&lt;PAD&gt;&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer = nn.Embedding(num_words, embedding_dimension, padding_idx=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Embedding(3, 5, padding_idx=0)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer(torch.LongTensor([0]))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[0., 0., 0., 0., 0.]], grad_fn=&lt;EmbeddingBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_ids = [2, 1, 0]  # Notre texte contient 3 mots ayant les identifiants 2, 1 et 0 (jeton de padding).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word_ids = torch.LongTensor(text_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_embeddings = embedding_layer(word_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_embeddings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[ 0.1385, -0.3528,  1.1324, -0.3810,  1.7321],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.6047, -0.8128,  0.7661, -1.5609, -1.5598],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#        grad_fn=&lt;EmbeddingBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="43-créer-une-embedding-layer-à-partir-de-plongements-existants">4.3 Créer une <em>embedding</em> layer à partir de plongements existants<a href="#43-créer-une-embedding-layer-à-partir-de-plongements-existants" class="hash-link" aria-label="Direct link to 43-créer-une-embedding-layer-à-partir-de-plongements-existants" title="Direct link to 43-créer-une-embedding-layer-à-partir-de-plongements-existants">​</a></h3>
<p>La fonction <code>from_pretrained</code> permet de construire une <em>embedding</em> layer à partir d&#x27;une matrice de poids correspondant à
des plongements de mots. Comme dans l&#x27;exemple précédent, on peut par la suite utiliser cette couche pour convertir un ou plusieurs mots en embeddings.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_w0 = [ 0.0,  0.0, 0.0, 0.0, 0.0]  # Padding</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_w1 = [ 0.3002,  0.0271, -0.7447, -0.1957, -0.3382]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_w2 = [-0.3433,  0.0522,  0.2301, -0.9601, -0.0239]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_w3 = [-0.1272, -0.6078, -0.7775,  2.8373, -0.4550]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embeddings_tensor = torch.FloatTensor([embedding_w0, embedding_w1, embedding_w2, embedding_w3])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer = nn.Embedding.from_pretrained(embeddings_tensor, padding_idx=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Embedding(4, 5, padding_idx=0)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_ids = [1]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_ids_tensor = torch.LongTensor(text_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer(text_ids_tensor)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[ 0.3002,  0.0271, -0.7447, -0.1957, -0.3382]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_ids = [1, 3, 0]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_ids_tensor = torch.LongTensor(text_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer(text_ids_tensor)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[ 0.3002,  0.0271, -0.7447, -0.1957, -0.3382],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.1272, -0.6078, -0.7775,  2.8373, -0.4550],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="44-exemple-avec-spacy">4.4 Exemple avec Spacy<a href="#44-exemple-avec-spacy" class="hash-link" aria-label="Direct link to 4.4 Exemple avec Spacy" title="Direct link to 4.4 Exemple avec Spacy">​</a></h3>
<p>On refait l&#x27;exemple précédent mais de manière plus concrète pour construire une couche d&#x27;<em>embeddings</em> à partir d&#x27;un corpus
de taille limitée et de plongements de mots préentraînés (ceux de Spacy). À noter ici qu&#x27;on travaille avec un vocabulaire
fermé, c.-à-d. qu&#x27;on suppose qu&#x27;on connait à l&#x27;avance tous les mots de notre vocabulaire. Autrement dit, on
suppose qu&#x27;il n&#x27;y a pas de mot inconnu.</p>
<p>À noter qu&#x27;on ajoute ici un jeton de padding au vocabulaire, ce qui sera utile pour la section 5 du notebook.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">padding_token = &#x27;&lt;PAD&gt;&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">padding_id = 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">small_corpus = [&quot;This is a test&quot;, &quot;To be or not to be&quot;, &quot;That is the question&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def get_vocabulary(corpus, padding=True):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;Une version simplifiée pour construire un vocabulaire à partir des textes d&#x27;un corpus.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    token_set = set()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for text in corpus:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        tokens = text.split()  # on utiliserait normalement un tokeniseur pour cette étape</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        for token in tokens:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            token_set.add(token)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    vocabulary = list(token_set)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if padding:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        vocabulary.insert(padding_id, padding_token)  # ou vocabulary = [padding_token] + vocabulary si id=0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return vocabulary</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">vocab = get_vocabulary(small_corpus, padding=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(vocab)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[&#x27;&lt;PAD&gt;&#x27;, &#x27;a&#x27;, &#x27;not&#x27;, &#x27;the&#x27;, &#x27;test&#x27;, &#x27;That&#x27;, &#x27;To&#x27;, &#x27;is&#x27;, &#x27;to&#x27;, &#x27;be&#x27;, &#x27;question&#x27;, &#x27;or&#x27;, &#x27;This&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On crée ici les structures de données qui nous permettent de convertir un mot en identifiant (et l&#x27;inverse).</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">index_to_word = {index: word for index, word in enumerate(vocab)}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word_to_index = {word: index for index, word in enumerate(vocab)}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;index_to_word:&quot;, index_to_word)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nword_to_index:&quot;, word_to_index)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># index_to_word: {0: &#x27;&lt;PAD&gt;&#x27;, 1: &#x27;a&#x27;, 2: &#x27;not&#x27;, 3: &#x27;the&#x27;, 4: &#x27;test&#x27;, 5: &#x27;That&#x27;, 6: &#x27;To&#x27;, 7: &#x27;is&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 8: &#x27;to&#x27;, 9: &#x27;be&#x27;, 10: &#x27;question&#x27;, 11: &#x27;or&#x27;, 12: &#x27;This&#x27;}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># word_to_index: {&#x27;&lt;PAD&gt;&#x27;: 0, &#x27;a&#x27;: 1, &#x27;not&#x27;: 2, &#x27;the&#x27;: 3, &#x27;test&#x27;: 4, &#x27;That&#x27;: 5, &#x27;To&#x27;: 6, &#x27;is&#x27;: 7,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># &#x27;to&#x27;: 8, &#x27;be&#x27;: 9, &#x27;question&#x27;: 10, &#x27;or&#x27;: 11, &#x27;This&#x27;: 12}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def convert_to_id(text):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    tokens = text.split()  # on utiliserait normalement un tokeniseur pour cette étape</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return [word_to_index[token] for token in tokens]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">convert_to_id(&quot;This is a question&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># [12, 7, 1, 10]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def get_embedding_tensor(vocab, spacy_analyzer, padding=True):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    pseudo_text = &quot; &quot;.join(vocab)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    doc = spacy_analyzer(pseudo_text)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    _embeddings_ = [token.vector for token in doc]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if padding:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        embedding_dim = len(embeddings[0])  # un petit truc pour connaître la longueur des _embeddings_</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        padding_emb = get_padding_embedding(embedding_dim)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # on suppose que le jeton de padding correspond à l&#x27;identifiant 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        embeddings.insert(0, padding_emb)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return FloatTensor(embeddings)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def get_padding_embedding(dimension):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return [0] * dimension  # un _embedding_ de padding = un vecteur de 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spacy_embeddings = get_embedding_tensor(vocab, spacy_en)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(spacy_embeddings.shape)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spacy_embeddings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># torch.Size([16, 300])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.6221,  0.2501, -0.0375,  ..., -0.0087, -0.5015,  0.1330],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 0.3235,  0.3555,  0.0294,  ...,  0.3456,  0.2777, -0.0781],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         ...,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.2226,  0.2236, -0.2385,  ...,  0.0078,  0.4053,  0.2960],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.2285,  0.1390, -0.3711,  ..., -0.4301,  0.3176,  0.1462],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.0876,  0.3550,  0.0639,  ...,  0.0345, -0.1503,  0.4067]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer = nn.Embedding.from_pretrained(spacy_embeddings)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Embedding(16, 300)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_text = &quot;That is not a question&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_ids = torch.LongTensor(convert_to_id(input_text))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_ids</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([ 5,  7,  2,  1, 10])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_embeddings = embedding_layer(input_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">text_embeddings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[-0.0498,  0.0270, -0.3879,  ..., -0.3036,  0.2707,  0.1805],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 0.0611,  0.2672,  0.2177,  ...,  0.1498,  0.4010, -0.0943],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 0.3235,  0.3555,  0.0294,  ...,  0.3456,  0.2777, -0.0781],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.6221,  0.2501, -0.0375,  ..., -0.0087, -0.5015,  0.1330],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [-0.0850,  0.5020,  0.0024,  ..., -0.2151, -0.2630, -0.0060]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On peut également faire cette conversion pour une minibatch.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_texts = [&quot;That is not question&quot;, &quot;To be a test&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">minibatch_ids = torch.LongTensor([convert_to_id(x) for x in input_texts])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Les IDs des 2 exemples:\n&quot;, minibatch_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">minibatch_embeddings = embedding_layer(minibatch_ids)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nLa minibatch qui en résulte:\n&quot;, minibatch_embeddings)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Les IDs des 2 exemples:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[ 5,  7,  2, 10],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 6,  9,  1,  4]])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># La minibatch qui en résulte:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[-0.0498,  0.0270, -0.3879,  ..., -0.3036,  0.2707,  0.1805],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0611,  0.2672,  0.2177,  ...,  0.1498,  0.4010, -0.0943],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.3235,  0.3555,  0.0294,  ...,  0.3456,  0.2777, -0.0781],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.0850,  0.5020,  0.0024,  ..., -0.2151, -0.2630, -0.0060]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [[ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.3192,  0.0632, -0.2786,  ...,  0.0827,  0.0978,  0.2504],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.6221,  0.2501, -0.0375,  ..., -0.0087, -0.5015,  0.1330],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0438,  0.0248, -0.2094,  ..., -0.3010, -0.1458,  0.2819]]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>À noter ici que les textes d&#x27;une minibatch doivent être de même longueur. On revient sur ce point dans la section 5 sur le padding.</p>
<p>On peut par la suite soumettre cette minibatch à une couche récurrente.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">output, hidden = spacy_rnn_layer(minibatch_embeddings)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Tous les états cachés des 2 exemples:\n&quot;, output)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;\nL&#x27;état caché du dernier mot de chacun des 2 exemples:\n&quot;, hidden)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Tous les états cachés des 2 exemples:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[ 0.9280,  0.9665, -0.4408, -0.9572],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.9912,  0.9825, -0.9495, -0.8383],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.9938, -0.0011, -0.9939,  0.9142],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.8921,  0.8652, -0.1503, -0.9503]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [[ 0.9163,  0.9763, -0.4424, -0.6474],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.9873,  0.9823,  0.3500,  0.6399],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.1647,  0.9123, -0.8965, -0.7907],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.2726,  0.9968, -0.5654, -0.8592]]], grad_fn=&lt;TransposeBackward1&gt;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># L&#x27;état caché du dernier mot de chacun des 2 exemples:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([[[ 0.8921,  0.8652, -0.1503, -0.9503],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.2726,  0.9968, -0.5654, -0.8592]]], grad_fn=&lt;StackBackward&gt;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="45-ajout-dun-jeton-de-mot-inconnu-unknown-au-vocabulaire">4.5 Ajout d&#x27;un jeton de mot inconnu (unknown) au vocabulaire<a href="#45-ajout-dun-jeton-de-mot-inconnu-unknown-au-vocabulaire" class="hash-link" aria-label="Direct link to 4.5 Ajout d&#x27;un jeton de mot inconnu (unknown) au vocabulaire" title="Direct link to 4.5 Ajout d&#x27;un jeton de mot inconnu (unknown) au vocabulaire">​</a></h3>
<p>Lorsqu&#x27;on considère que notre vocabulaire est ouvert (c.-à-d. qu&#x27;on peut avoir de nouveaux mots
lorsqu&#x27;on utilise un modèle), il est important de tenir compte de ce mot. L&#x27;approche de base consiste
à ajouter un mot inconnu () dans notre vocabulaire et d&#x27;assigner tous les nouveaux mots à ce jeton.</p>
<p>Cela peut être fait simplement en ajouter le jeton au vocabulaire et en modifiant légèrement la conversion des mots en identifiants.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">unk_id = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">unk_token = &#x27;&lt;UNK&gt;&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">padding_token = &#x27;&lt;PAD&gt;&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">vocab = [padding_token, unk_token, &#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word2id = {token:id for id, token in enumerate(vocab)}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word2id</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">{&#x27;&lt;PAD&gt;&#x27;: 0, &#x27;&lt;UNK&gt;&#x27;: 1, &#x27;one&#x27;: 2, &#x27;two&#x27;: 3, &#x27;three&#x27;: 4}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">tokens = [&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;, &#x27;tchatchatcha&#x27;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># get(token, 1) retourne l&#x27;identifiant 1 par défaut</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">sequence = [word2id.get(token, unk_id) for token in tokens]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">sequence</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[2, 3, 4, 1]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-padding-des-exemples-dune-minibatch">5. Padding des exemples d&#x27;une minibatch<a href="#5-padding-des-exemples-dune-minibatch" class="hash-link" aria-label="Direct link to 5. Padding des exemples d&#x27;une minibatch" title="Direct link to 5. Padding des exemples d&#x27;une minibatch">​</a></h2>
<p>Comme mentionné précédemment, tous les exemples d&#x27;une minibatch soumise à un réseau récurrent devrait avoir le même
nombre de jetons. Comme les textes ont habituellement différentes longueurs, on fait un rembourrage en ajoutant des
jetons de padding aux textes plus courts.</p>
<p>Voici un exemple comment procéder avec la fonction pad_sequence de PyTorch.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_texts = [&quot;not a question&quot;, &quot;To be a test question&quot;, &quot;This is not&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_sequences = [convert_to_id(x) for x in input_texts]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">input_sequences</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># [[2, 1, 10], [6, 9, 1, 4, 10], [12, 7, 2]]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.nn.utils.rnn import pad_sequence</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># on convertit les listes de Ids en tenseur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">minibatch_seqs = [torch.LongTensor(seq) for seq in input_sequences]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_padded = pad_sequence(minibatch_seqs, batch_first=True, padding_value=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_padded</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[ 2,  1, 10,  0,  0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 6,  9,  1,  4, 10],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [12,  7,  2,  0,  0]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On peut par la suite passer cette minibatch d&#x27;identifiants dans une couche d&#x27;embeddings pour obtenir les séquences
sous forme de plongements. On reprend ici la couche embedding_layer de la section précédente pour faire cette conversion.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">embeddings = embedding_layer(x_padded)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embeddings.size()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># torch.Size([3, 5, 300])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embeddings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[[ 0.3235,  0.3555,  0.0294,  ...,  0.3456,  0.2777, -0.0781],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.6221,  0.2501, -0.0375,  ..., -0.0087, -0.5015,  0.1330],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.0850,  0.5020,  0.0024,  ..., -0.2151, -0.2630, -0.0060],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [[ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.3192,  0.0632, -0.2786,  ...,  0.0827,  0.0978,  0.2504],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.6221,  0.2501, -0.0375,  ..., -0.0087, -0.5015,  0.1330],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0438,  0.0248, -0.2094,  ..., -0.3010, -0.1458,  0.2819],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [-0.0850,  0.5020,  0.0024,  ..., -0.2151, -0.2630, -0.0060]],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [[-0.0592,  0.1065, -0.2161,  ..., -0.4275,  0.0250,  0.0247],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0611,  0.2672,  0.2177,  ...,  0.1498,  0.4010, -0.0943],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.3235,  0.3555,  0.0294,  ...,  0.3456,  0.2777, -0.0781],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-packing-des-exemples-dune-minibatch">6. Packing des exemples d&#x27;une <em>minibatch</em><a href="#6-packing-des-exemples-dune-minibatch" class="hash-link" aria-label="Direct link to 6-packing-des-exemples-dune-minibatch" title="Direct link to 6-packing-des-exemples-dune-minibatch">​</a></h2>
<p>L&#x27;utilisation du padding pour obtenir des séquences de même longueur peut mener à un traitement inefficace. Par exemple,
supposons qu&#x27;une minibatch contient 3 séquences de longueurs 3, 5 et 10. Après le rembourrage, on se retrouve
avec 3 séquences de longueurs 10.</p>
<p>Pour mieux le visualiser:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">seqs = [[1, 2, 3], [4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">seq_tensors = [torch.LongTensor(seq) for seq in seqs]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_padded = pad_sequence(seq_tensors, batch_first=True, padding_value=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_padded</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># tensor([[ 1,  2,  3,  0,  0,  0,  0,  0,  0,  0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 4,  5,  6,  7,  8,  0,  0,  0,  0,  0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#         [ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Un RNN qui traitent ces 3 séquences devra faire 30 récurrences, alors que seulement 18 sont requises.
Le problème se complique encore plus si on utilise des réseaux bidirectionnels.</p>
<p>Une manière de contourner ce problème avec PyTorch est de faire un <em>packing</em> (un emballage) qui consiste à
réorganiser les séquences par position (tous les éléments des séquences en position 1, suivi des éléments en
position 2, suivi...) afin d&#x27;éliminer les 0 et d&#x27;éviter les calculs inutiles.</p>
<p>On peut obtenir une représentation emballée (packed) d&#x27;une minibatch avec la fonction <code>pack_padded_sequences</code>
qui utilise les séquences rembourrées ainsi que leurs longeurs originales avant emballage.</p>
<p>Pour notre exemple, on obtient le packing suivant:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.nn.utils.rnn import pack_padded_sequence</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">original_lengths = [len(seq) for seq in seqs]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Les longueurs des séquences originales:&quot;, original_lengths)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_packed = pack_padded_sequence(x_padded, torch.LongTensor(original_lengths), batch_first=True, enforce_sorted=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_packed</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Les longueurs des séquences originales: [3, 5, 10]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># PackedSequence(data=tensor([ 9,  4,  1, 10,  5,  2, 11,  6,  3, 12,  7, 13,  8, 14, 15, 16, 17, 18]),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># batch_sizes=tensor([3, 3, 3, 2, 2, 1, 1, 1, 1, 1]), sorted_indices=tensor([2, 1, 0]),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># unsorted_indices=tensor([2, 1, 0]))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Les séquences emballées:&quot;, x_packed.data.tolist())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Les séquences emballées: [9, 4, 1, 10, 5, 2, 11, 6, 3, 12, 7, 13, 8, 14, 15, 16, 17, 18]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On note ici que les séquences ont été réordonnancées de la plus longue à la plus courte avant d&#x27;être emballées.
Ce tri en ordre décroissant est avantageux dans certaines conditions (par ex. si vous roulez votre code sur un GPU).</p>
<p>On peut facilement retrouver les séquences rembourrées à partir des séquences emballées comme suit:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.nn.utils.rnn import pad_packed_sequence</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_padded_reconstructed = pad_packed_sequence(x_packed, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">x_padded_reconstructed</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># (tensor([[ 1,  2,  3,  0,  0,  0,  0,  0,  0,  0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 4,  5,  6,  7,  8,  0,  0,  0,  0,  0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#          [ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]]),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([ 3,  5, 10]))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Cette fonction pour récupérer les séquences rembourrées est également utilisée pour récupérer l&#x27;output d&#x27;un réseau récurrent qui traite en entrée un input <em>packed</em>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-exemple-de-réseau-récurrent-simple-pour-un-problème-de-classification">7. Exemple de réseau récurrent simple pour un problème de classification<a href="#7-exemple-de-réseau-récurrent-simple-pour-un-problème-de-classification" class="hash-link" aria-label="Direct link to 7. Exemple de réseau récurrent simple pour un problème de classification" title="Direct link to 7. Exemple de réseau récurrent simple pour un problème de classification">​</a></h2>
<p>Un exemple simple pour illustrer 3 parties : les données, le réseau et l&#x27;entraînement.</p>
<p>Données: des questions de 3 catégories - LOCATION, DEFINITION et TEMPORAL</p>
<p>Réseau: Il contient une couche GRU ainsi qu&#x27;une <em>embedding layer</em> pour convertir les textes en plongements de mots.
Pour faire la classification des textes, on utilise une couche linéaire dont la sortie contient une neurone par classe.</p>
<p>Entraînement: Avec Poutyne comme dans les exemples précédents du cours.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="71-la-création-du-jeu-de-données-et-des-fonctions-utilitaires">7.1 La création du jeu de données et des fonctions utilitaires<a href="#71-la-création-du-jeu-de-données-et-des-fonctions-utilitaires" class="hash-link" aria-label="Direct link to 7.1 La création du jeu de données et des fonctions utilitaires" title="Direct link to 7.1 La création du jeu de données et des fonctions utilitaires">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def load_dataset(filename):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    with open(filename, &#x27;r&#x27;) as infile:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        content = json.load(infile)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return content[&quot;questions&quot;], content[&quot;labels&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_dataset_path = &quot;./data/questions_small.json&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">questions, labels = load_dataset(train_dataset_path)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;{} exemples de catégories {}.&quot;.format(len(labels), set(labels)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 1616 exemples de catégories {&#x27;LOCATION&#x27;, &#x27;DEFINITION&#x27;, &#x27;TEMPORAL&#x27;}.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On convertit les classes en identifiants.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">label_list = list(set(labels))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">id2label = {label_id: value for label_id, value in enumerate(label_list)}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">label2id = {value: label_id for label_id, value in enumerate(label_list)}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">nb_classes = len(label_list)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(label2id)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># {&#x27;LOCATION&#x27;: 0, &#x27;DEFINITION&#x27;: 1, &#x27;TEMPORAL&#x27;: 2}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">y = [label2id[label] for label in labels]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from sklearn.model_selection import train_test_split</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">X_train, X_valid, y_train, y_valid = train_test_split(questions, y, test_size=0.1, shuffle=True,random_state=42)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Nb exemples d&#x27;entraînement: {}, Nb d&#x27;exemples de validation: {}.&quot;.format(len(y_train), len(y_valid)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Nb exemples d&#x27;entraînement: 1454, Nb d&#x27;exemples de validation: 162.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On construit le vocabulaire et les fonctions utilitaires pour faire la conversion des mots en identifiant.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import spacy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">nlp = spacy.load(&#x27;en_core_web_md&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_size = nlp.meta[&#x27;vectors&#x27;][&#x27;width&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On débute par ajouter les jetons de <em>padding</em> et de mot inconnu au vocabulaire pour travailler à vocabulaire ouvert.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">padding_token = &quot;&lt;PAD&gt;&quot;   # mot 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">unk_token = &quot;&lt;UNK&gt;&quot;    # mot 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">zero_vec_embedding = np.zeros(embedding_size, dtype=np.float64)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">id2word = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">id2word[0] = padding_token</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">id2word[1] = unk_token</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word2id = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word2id[padding_token] = 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word2id[unk_token] = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">id2embedding = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">id2embedding[0] = zero_vec_embedding</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">id2embedding[1] = zero_vec_embedding</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">word_index = 2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">vocab = word2id.keys()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for question in X_train:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for word in nlp(question):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        if word.text not in vocab:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            word2id[word.text] = word_index</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            id2word[word_index] = word.text</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            id2embedding[word_index] = word.vector</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            word_index += 1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>On termine avec les classes de Dataset qui gèrent nos données d&#x27;entraînement et de validation.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch import LongTensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.nn.utils.rnn import pad_sequence</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.utils.data import DataLoader, Dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class QuestionDataset(Dataset):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, data , targets, word_to_id, spacy_model):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.data = data</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.sequences = [None for _ in range(len(data))]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.targets = targets</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.word2id = word_to_id</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.tokenizer = spacy_model</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __len__(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return len(self.data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __getitem__(self, index):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        if self.sequences[index] is None:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            self.sequences[index] = self.tokenize(self.data[index])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return LongTensor(self.sequences[index]), LongTensor([self.targets[index]]).squeeze(0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def tokenize(self, sentence):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        tokens = [word.text for word in self.tokenizer(sentence)]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return [self.word2id.get(token, 1) for token in tokens]  # get(token, 1) retourne 1 par défaut si mot inconnu</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_dataset = QuestionDataset(X_train, y_train, word2id, nlp)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">valid_dataset = QuestionDataset(X_valid, y_valid, word2id, nlp)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">valid_dataset[20]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># (tensor([  59,    3,    4,    1,    1, 1318,    7]), tensor(2))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="72-le-réseau-gru">7.2 Le réseau GRU<a href="#72-le-réseau-gru" class="hash-link" aria-label="Direct link to 7.2 Le réseau GRU" title="Direct link to 7.2 Le réseau GRU">​</a></h3>
<p>Un structure standard avec une couche d&#x27;embeddings, un couche GRU et une couche linéaire qui sert de tête de prédiction
sur le dernier état caché du réseau récurrent. La couche d&#x27;embeddings est créée à partir d&#x27;une matrice de poids
construite obtenues avant la création du réseau. À noter qu&#x27;on fait de l&#x27;emballage (<em>packing</em>) qui permet d&#x27;éviter les
récurrences superflues. Le padding des batchs d&#x27;entraînement est effectué par les <em>dataloaders</em>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class GRUClassifier(nn.Module):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, embeddings, hidden_state_size, nb_classes) :</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super(GRUClassifier, self).__init__()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.embedding_layer = nn.Embedding.from_pretrained(embeddings)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.embedding_size = embeddings.size()[1]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.rnn = nn.GRU(self.embedding_size, hidden_state_size, 1, batch_first=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.classification_layer = nn.Linear(hidden_state_size, nb_classes)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def forward(self, x, x_lengths):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.embedding_layer(x)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        packed_batch = pack_padded_sequence(x, x_lengths, batch_first=True, enforce_sorted=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        _, last_hidden_state = self.rnn(packed_batch)  # On utilise le hidden state de la dernière cellule</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = last_hidden_state.squeeze()  # Le GRU a une seule couche, on retire cette dimension</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.classification_layer(x)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return x</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Comme nous avons une tâche de classification de texte, nous n&#x27;avons besoin que de l&#x27;état caché du dernier mot.
Cet état est disponible en sortie du réseau récurrent (2e valeur de sortie). L&#x27;approche serait légèrement différente
pour une tâche d&#x27;étiquetage de mots où on doit récupérer les états cachés de tous les mots après avoir désemballé
la sortie du réseau (avec la fonction <code>pad_packed_sequence</code>). Pour un exemple de token classification (étiquetage de mots),
voir le tutoriel suivant sur l&#x27;analyse d&#x27;adresses postales <a href="https://www.dotlayer.org/en/categories/address-parsing/" target="_blank" rel="noopener noreferrer">lien</a>.</p>
<p>On crée maintenant les classes de Dataloaders. Cette classe a la responsabilité de faire le padding des exemples de la
batch. On utilise une fonction utilitaire <code>pad_batch</code> qui est passé en argument à la création du dataloader.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def pad_batch(batch):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    x = [x for x,y in batch]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    x_true_length = [len(x) for x,y in batch]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    y = torch.stack([y for x,y in batch], dim=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return ((pad_sequence(x, batch_first=True), x_true_length), y)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=pad_batch)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=True, collate_fn=pad_batch)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">next(iter(train_dataloader))  # Un exemple de batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ((tensor([[ 224,   91,  105,    4,   86, 2143,  567,   26, 2144,   44, 2145, 2146,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#               7,    0,    0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#           [   2,    8,    4, 1926, 1927, 1033, 1550,    7,    0,    0,    0,    0,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#               0,    0,    0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#           [   2,   33,  101,  101, 2059,  104,  100,    7,    0,    0,    0,    0,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#               0,    0,    0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#           [   2,    8,  101,  101,  147,  148,  149,  104,    7,    0,    0,    0,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ...</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#             403,  404,    7],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#           [   2,    8, 2200,    7,    0,    0,    0,    0,    0,    0,    0,    0,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#               0,    0,    0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#           [   2,    8,   26, 2043, 2044,    7,    0,    0,    0,    0,    0,    0,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#               0,    0,    0],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#           [  59,    3,  320,  321,    7,    0,    0,    0,    0,    0,    0,    0,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#               0,    0,    0]]),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#   [13, 8, 8, 9, 5, 8, 4, 7, 6, 6, 9, 4, 15, 4, 6, 5]),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#  tensor([0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 0, 1, 1, 2]))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Maintenant on construit la table d&#x27;<em>embeddings</em> qui sera passée en argument au modèle lors de sa création.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">vocab_size = len(id2embedding)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer = np.zeros((vocab_size, embedding_size), dtype=np.float32)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for token_id, embedding in id2embedding.items():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    embedding_layer[token_id,:] = embedding</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">embedding_layer = torch.from_numpy(embedding_layer)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Taille de la couche d&#x27;embeddings:&quot;, embedding_layer.shape)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Taille de la couche d&#x27;embeddings: torch.Size([3022, 300])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Finalement on construit notre modèle de classification de questions.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from poutyne import set_seeds</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">set_seeds(42)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">hidden_size = 100  # choisi arbitrairement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model = GRUClassifier(embedding_layer, hidden_size, nb_classes)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="73-lentraîne-avec-poutyne">7.3 L&#x27;entraîne avec Poutyne<a href="#73-lentraîne-avec-poutyne" class="hash-link" aria-label="Direct link to 7.3 L&#x27;entraîne avec Poutyne" title="Direct link to 7.3 L&#x27;entraîne avec Poutyne">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from poutyne.framework import Experiment</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">experiment = Experiment(&#x27;model/gru_classification&#x27;, model, optimizer = &quot;SGD&quot;, task=&quot;classification&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">logging = experiment.train(train_dataloader, valid_dataloader, epochs=25, disable_tensorboard=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch:  1/25 Train steps: 91 Val steps: 11 10.94s loss: 1.004985 acc: 50.687758 fscore_macro: 0.249522 val_loss: 0.952887 val_acc: 56.172840 val_fscore_macro: 0.239789</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch 1: val_acc improved from -inf to 56.17284, saving file to model/gru_classification/checkpoint_epoch_1.ckpt</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch:  2/25 Train steps: 91 Val steps: 11 0.97s loss: 0.956208 acc: 52.613480 fscore_macro: 0.229833 val_loss: 0.937381 val_acc: 56.172840 val_fscore_macro: 0.239789</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch:  3/25 Train steps: 91 Val steps: 11 1.02s loss: 0.935598 acc: 52.819807 fscore_macro: 0.234294 val_loss: 0.918388 val_acc: 56.172840 val_fscore_macro: 0.239789</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch:  4/25 Train steps: 91 Val steps: 11 1.14s loss: 0.912273 acc: 54.470426 fscore_macro: 0.269421 val_loss: 0.900670 val_acc: 59.876543 val_fscore_macro: 0.320687</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ...</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch: 24/25 Train steps: 91 Val steps: 11 0.72s loss: 0.275926 acc: 90.646492 fscore_macro: 0.858318 val_loss: 0.272842 val_acc: 90.740741 val_fscore_macro: 0.868657</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch 24: val_acc improved from 90.12346 to 90.74074, saving file to model/gru_classification/checkpoint_epoch_24.ckpt</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Epoch: 25/25 Train steps: 91 Val steps: 11 0.84s loss: 0.257278 acc: 91.471802 fscore_macro: 0.872796 val_loss: 0.269933 val_acc: 89.506173 val_fscore_macro: 0.862955</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Restoring data from model/gru_classification/checkpoint_epoch_24.ckpt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="74-quelques-prédictions-pour-tester-le-tout">7.4 Quelques prédictions pour tester le tout<a href="#74-quelques-prédictions-pour-tester-le-tout" class="hash-link" aria-label="Direct link to 7.4 Quelques prédictions pour tester le tout" title="Direct link to 7.4 Quelques prédictions pour tester le tout">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from numpy import argmax</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def obtain_prediction(sentence, label=None):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    tokens = [word.text for word in nlp(sentence)]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    sequence = [word2id.get(token, 1) for token in tokens]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    sentence_length = len(sequence)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    class_scores = model(LongTensor(sequence).unsqueeze(0), LongTensor([sentence_length])).detach().numpy()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    best_score_id = argmax(class_scores)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return id2label[best_score_id]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">questions = [&quot;Where is Milan ?&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">             &quot;What is fibromyalgia ?&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">             &quot;When did Elvis Presley die ?&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for question in questions:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    prediction = obtain_prediction(question)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Question: {} \tPrediction: {}&quot;.format(question, prediction))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Question: Where is Milan ?  Prediction: LOCATION</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Question: What is fibromyalgia ?  Prediction: DEFINITION</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Question: When did Elvis Presley die ?   Prediction: TEMPORAL</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/courses/ift-7022/week-08-partie-2.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/courses/ift-7022/week-08-partie-1"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">8 Deep NLP - Réseaux récurrents pour le traitement de séquences (RNN, GRU, LSTM)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/courses/ift-7022/week-09"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">9 Deep NLP - Introduction aux modèles Transformers</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-création-dune-couche-rnn-ou-gru" class="table-of-contents__link toc-highlight">1. Création d&#39;une couche RNN ou GRU</a><ul><li><a href="#11-couche-récurrente-rnn" class="table-of-contents__link toc-highlight">1.1. Couche récurrente RNN</a></li><li><a href="#12-couche-récurrente-gru" class="table-of-contents__link toc-highlight">1.2 Couche récurrente GRU</a></li><li><a href="#13-stacked-rnn" class="table-of-contents__link toc-highlight">1.3 Stacked RNN</a></li><li><a href="#14-rnn-bidirectionnel" class="table-of-contents__link toc-highlight">1.4 RNN bidirectionnel</a></li><li><a href="#15-ajouter-une-couche-de-prédiction-à-la-sortie-dun-rnn" class="table-of-contents__link toc-highlight">1.5 Ajouter une couche de prédiction à la sortie d&#39;un RNN</a></li></ul></li><li><a href="#2-création-dun-lstm" class="table-of-contents__link toc-highlight">2. Création d&#39;un LSTM</a></li><li><a href="#3-passer-des-embeddings-préentraînés-directement-comme-input-dun-réseau-récurrent" class="table-of-contents__link toc-highlight">3. Passer des <em>embeddings</em> préentraînés directement comme input d&#39;un réseau récurrent</a></li><li><a href="#4-couche-dembeddings-pour-convertir-les-mots-en-plongements" class="table-of-contents__link toc-highlight">4. Couche d&#39;<em>embeddings</em> pour convertir les mots en plongements</a><ul><li><a href="#41-pour-aller-rapidement-à-lessentiel" class="table-of-contents__link toc-highlight">4.1 Pour aller rapidement à l&#39;essentiel</a></li><li><a href="#42-ajout-dun-jeton-de-padding-rembourrage-dans-la-couche-dembeddings" class="table-of-contents__link toc-highlight">4.2 Ajout d&#39;un jeton de <em>padding</em> (rembourrage) dans la couche d&#39;<em>embeddings</em></a></li><li><a href="#43-créer-une-embedding-layer-à-partir-de-plongements-existants" class="table-of-contents__link toc-highlight">4.3 Créer une <em>embedding</em> layer à partir de plongements existants</a></li><li><a href="#44-exemple-avec-spacy" class="table-of-contents__link toc-highlight">4.4 Exemple avec Spacy</a></li><li><a href="#45-ajout-dun-jeton-de-mot-inconnu-unknown-au-vocabulaire" class="table-of-contents__link toc-highlight">4.5 Ajout d&#39;un jeton de mot inconnu (unknown) au vocabulaire</a></li></ul></li><li><a href="#5-padding-des-exemples-dune-minibatch" class="table-of-contents__link toc-highlight">5. Padding des exemples d&#39;une minibatch</a></li><li><a href="#6-packing-des-exemples-dune-minibatch" class="table-of-contents__link toc-highlight">6. Packing des exemples d&#39;une <em>minibatch</em></a></li><li><a href="#7-exemple-de-réseau-récurrent-simple-pour-un-problème-de-classification" class="table-of-contents__link toc-highlight">7. Exemple de réseau récurrent simple pour un problème de classification</a><ul><li><a href="#71-la-création-du-jeu-de-données-et-des-fonctions-utilitaires" class="table-of-contents__link toc-highlight">7.1 La création du jeu de données et des fonctions utilitaires</a></li><li><a href="#72-le-réseau-gru" class="table-of-contents__link toc-highlight">7.2 Le réseau GRU</a></li><li><a href="#73-lentraîne-avec-poutyne" class="table-of-contents__link toc-highlight">7.3 L&#39;entraîne avec Poutyne</a></li><li><a href="#74-quelques-prédictions-pour-tester-le-tout" class="table-of-contents__link toc-highlight">7.4 Quelques prédictions pour tester le tout</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Alain Boisvert. Construit avec Docusaurus.</div></div></div></footer></div>
</body>
</html>
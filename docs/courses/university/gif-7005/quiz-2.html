<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-courses/university/gif-7005/quiz-2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.1">
<title data-rh="true">Quiz 2 du 11 octobre 2023 | Alain Boisvert</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://boisalai.github.io/docs/courses/university/gif-7005/quiz-2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Quiz 2 du 11 octobre 2023 | Alain Boisvert"><meta data-rh="true" name="description" content="Question 1"><meta data-rh="true" property="og:description" content="Question 1"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://boisalai.github.io/docs/courses/university/gif-7005/quiz-2"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/university/gif-7005/quiz-2" hreflang="en"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/university/gif-7005/quiz-2" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Alain Boisvert RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Alain Boisvert Atom Feed">



<link rel="stylesheet" href="/fonts/font-awesome/fontawesome.css">
<link rel="stylesheet" href="/fonts/font-awesome/solid.css">
<link rel="stylesheet" href="/fonts/font-awesome/regular.css">
<link rel="stylesheet" href="/fonts/font-awesome/brands.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.6520ee1d.css">
<script src="/assets/js/runtime~main.089b18cf.js" defer="defer"></script>
<script src="/assets/js/main.61e0bf1e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Alain Boisvert</b></a><a class="navbar__item navbar__link" target="" href="/docs/courses/university/ift-7022">IFT-7022</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" target="" href="/docs/courses/university/gif-7005">GIF-7005</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/boisalai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-github"> </a><a href="https://www.linkedin.com/in/alain-boisvert-98b058156/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-linkedin-in"> </a><a href="mailto:ay.boisvert@gmail.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-solid fa-envelope"> </a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Alain Boisvert</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/cv">Curriculum vitæ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/learning">Learning path</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/certificates">Certificates</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/courses/university/gif-7005">Courses</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/courses/university/gif-7005">Université Laval</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/courses/university/gif-7005">GIF-7005 Introduction à l&#x27;apprentissage automatique</a><button aria-label="Collapse sidebar category &#x27;GIF-7005 Introduction à l&#x27;apprentissage automatique&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-01">Semaine 1 Introduction à l&#x27;apprentissage</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-02">Semaine 2 Méthodes paramétriques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-03">Semaine 3 Méthodes multivariées</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-04">Semaine 4 Méthodes non paramétriques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-05">Semaine 5 Discriminants linéaires</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-06">Semaine 6 Méthodes à noyau</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-07">Semaine 7 Perceptron multicouche</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-08">Semaine 8 Apprentissage profond</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-10">Semaine 10 Réseau de neurones à convolution</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-11">Semaine 11 Méthodes par ensembles</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-12">Semaine 12 Prétraitements et analyse de données</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/week-13">Semaine 13 Clustering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/devoir-1">Devoir 1 du 4 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/devoir-2">Devoir 2 du 18 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/devoir-3">Devoir 3 du 8 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/devoir-4">Devoir 4 du 22 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/devoir-5">Devoir 5 du 8 décembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/quiz-1">Quiz 1 du 27 septembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/courses/university/gif-7005/quiz-2">Quiz 2 du 11 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/quiz-3">Quiz 3 du 25 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/quiz-4">Quiz 4 du 15 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/examen-2022">Examen final 2022</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/examen-2019">Examen final 2019</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/examen-2018">Examen final 2018</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/examen-2017">Examen final 2017</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/examen-2016">Examen final 2016</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7005/projet">Projet</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/courses/university/ift-7022">IFT-7022 Traitement automatique de la langue naturelle</a><button aria-label="Expand sidebar category &#x27;IFT-7022 Traitement automatique de la langue naturelle&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/university/gif-7105">GIF-7105 Photographie algorithmique</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/courses/deeplearning-ai/p01-chatgpt-building-systems">DeepLearning.AI</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/courses/activeloop/rag-for-production">Activeloop</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/fine-tuning-llms">Training and fine-tuning LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/python-gpu">Best practices CPU and GPU</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/models/test">Interactive models</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/references/links">References</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Courses</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Université Laval</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/courses/university/gif-7005"><span itemprop="name">GIF-7005 Introduction à l&#x27;apprentissage automatique</span></a><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Quiz 2 du 11 octobre 2023</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Quiz 2 du 11 octobre 2023</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="question-1">Question 1<a href="#question-1" class="hash-link" aria-label="Direct link to Question 1" title="Direct link to Question 1">​</a></h2>
<p>Peux-tu répondre aux questions suivantes?</p>
<p>Parmi les éléments ci-dessous, sélectionnez ceux qui sont vrais en ce qui a trait aux discriminants linéaires.</p>
<p><strong>A.</strong> Le critère d&#x27;erreur du perceptron est obtenu à partir de la somme des valeurs des données mal classées dans l&#x27;ensemble de données. | The perceptron error criterion is derived from the sum of misclassified data points in the dataset.</p>
<ul>
<li><strong>Vrai</strong> Le critère d&#x27;erreur du perceptron est basé sur la somme des vecteurs des données mal classées.</li>
</ul>
<p><strong>B.</strong> Le perceptron assigne une classe sur la base de la valeur absolue de la fonction discriminante. | The perceptron assigns a class based on the absolute value of the discriminant function.</p>
<ul>
<li><strong>Faux</strong> Le perceptron assigne une classe sur la base du signe de la fonction discriminante et non de sa valeur absolue.</li>
</ul>
<p><strong>C.</strong> Un discriminant avec une fonction de base implique une transformation non linéaire traitée sous une forme linéaire. | A discriminant with a basis function involves a non-linear transformation processed in a linear form.</p>
<ul>
<li><strong>Vrai</strong> L&#x27;utilisation d&#x27;une fonction de base permet de transformer des données non linéaires en une forme qui peut être traitée linéairement.</li>
</ul>
<p><strong>D.</strong> La régression logistique exige toujours que les variables indépendantes soient normalement distribuées. | Logistic regression always requires the independent variables to be normally distributed.</p>
<ul>
<li><strong>Faux</strong> La régression logistique ne nécessite pas que les variables indépendantes soient normalement distribuées.</li>
</ul>
<p><strong>E.</strong> L&#x27;objectif principal de la régression logistique est de déterminer la matrice de covariance entre différentes caractéristiques. | The main goal of logistic regression is to determine the covariance matrix between different features.</p>
<ul>
<li><strong>Faux</strong> L&#x27;objectif principal de la régression logistique n&#x27;est pas de déterminer la matrice de covariance, mais de prédire la probabilité qu&#x27;une observation appartienne à une catégorie particulière.</li>
</ul>
<p><strong>F.</strong> Les modèles discriminants visent à résoudre uniquement le problème de la discrimination, considérant l&#x27;estimation des densités comme une étape inutile. | Discriminative models aim to solve only the problem of discrimination, considering the estimation of densities as an unnecessary step.</p>
<ul>
<li><strong>Vrai</strong> Les modèles discriminants, contrairement aux modèles génératifs, se concentrent directement sur la discrimination sans estimer les densités de probabilité des classes.</li>
</ul>
<p><strong>G.</strong> La régression logistique est un modèle linéaire incapable de traiter des données de classement non linéairement séparables. | Logistic regression is a linear model unable to handle non-linearly separable classification data.</p>
<ul>
<li><strong>Faux</strong> Bien que la régression logistique soit un modèle linéaire, elle peut être étendue pour traiter des données non linéaires en utilisant des fonctions de base ou d&#x27;autres transformations.</li>
</ul>
<p><strong>H.</strong> Un discriminant linéaire est décrit par une combinaison de poids associés aux caractéristiques et d&#x27;un terme de biais. | A linear discriminant is described by a combination of weights associated with features and a bias term.</p>
<ul>
<li><strong>Vrai</strong> Un discriminant linéaire est décrit par une combinaison linéaire des caractéristiques (avec des poids associés) et d&#x27;un terme de biais.</li>
</ul>
<p><strong>I.</strong> En classement paramétrique, le concept de matrice de covariance partagée implique que les classes ne peuvent pas être séparées linéairement. | In parametric classification, the concept of a shared covariance matrix implies that the classes cannot be linearly separated.</p>
<ul>
<li><strong>Faux</strong> Une matrice de covariance partagée ne signifie pas nécessairement que les classes ne peuvent pas être séparées linéairement. Elle signifie simplement que toutes les classes sont supposées avoir la même matrice de covariance.</li>
</ul>
<p><strong>J.</strong> La stratégie « un contre tous » pour les modèles multiclasse utilise une fonction discriminante par classe. | The &quot;one versus all&quot; (OvA) strategy for multi-class models uses one discriminating function per class.</p>
<ul>
<li><strong>Vrai</strong> La stratégie &quot;un contre tous&quot; (ou &quot;one versus all&quot;) pour les modèles multiclasse entraîne un classificateur par classe, où cette classe est traitée comme positive et toutes les autres classes sont traitées comme négatives.</li>
</ul>
<p>Donc, les énoncés A, C, F, H, et J sont vrais.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="question-2">Question 2<a href="#question-2" class="hash-link" aria-label="Direct link to Question 2" title="Direct link to Question 2">​</a></h2>
<p>Nous avons 5 choix de mesures de distance :</p>
<ul>
<li>Distance de Manhattan</li>
<li>Distance euclidienne</li>
<li>Distance D-infini</li>
<li>Distance de Minkowsky</li>
<li>Distance de Mahalanobis</li>
</ul>
<p>Pour chaque proposition suivante, choisissez la mesure de distance correspondante parmi les 5 choix précédents.</p>
<p><strong>Q1.</strong> Une métrique généralisée qui peut englober une gamme de mesures de distance. | A generalized metric that can capture a range of distance measures.</p>
<ul>
<li>Distance de Minkowsky</li>
</ul>
<p><strong>Q2.</strong> Inclut un paramètre afin de faire varier l&#x27;importance des variables dans la métrique en fonction de leur magnitude.| Includes a parameter to vary the importance of the variables in the metric according to their magnitude.</p>
<ul>
<li>Distance de Minkowsky</li>
</ul>
<p><strong>Q3.</strong> Sa particularité réside dans sa capacité à prendre en compte la variance et la structure de covariance des données. | Its particularity lies in its ability to account for the variance and covariance structure of the data.</p>
<ul>
<li>Distance de Mahalanobis</li>
</ul>
<p><strong>Q4.</strong> Également appelée « norme L2 ». | Also referred to as the &quot;L2 norm.&quot;</p>
<ul>
<li>Distance euclidienne</li>
</ul>
<p><strong>Q5.</strong> Calculée comme la somme des différences absolues entre les coordonnées de deux points. | Calculated as the sum of the absolute differences between the coordinates of two points.</p>
<ul>
<li>Distance de Manhattan</li>
</ul>
<p><strong>Q6.</strong> Ne prend en compte que la variable pour laquelle la différence est la plus grande. | Takes into account only the variable for which the difference is the largest.</p>
<ul>
<li>Distance D-infini</li>
</ul>
<p><strong>Q7.</strong> Dans un parcours en grille, cette distance représente le chemin le plus court qu&#x27;une voiture emprunterait en naviguant uniquement dans des rues orthogonales. | In a grid-based path, this distance represents the shortest path a car would take navigating only orthogonal streets.</p>
<ul>
<li>Distance de Manhattan</li>
</ul>
<p><strong>Q8.</strong> Type de distance mesurée à l&#x27;aide d&#x27;une règle entre deux points d&#x27;un plan en 2D. | The type of distance you&#x27;d measure with a ruler between two points in a 2D plane.</p>
<ul>
<li>Distance euclidienne</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="question-3">Question 3<a href="#question-3" class="hash-link" aria-label="Direct link to Question 3" title="Direct link to Question 3">​</a></h2>
<p>Nous avons 7 choix possibles de méthodes sur le classement avec discriminants linéaires:</p>
<ul>
<li>Règle du perceptron</li>
<li>Méthode des moindres carrés</li>
<li>Régression logistique</li>
<li>Régression d&#x27;arête (Ridge regression)</li>
<li>LASSO</li>
<li>Modèles de lois normales avec covariance partagées</li>
<li>Descente du gradient stochastique</li>
</ul>
<p>Pour chacune des propositions suivantes, sélectionnez la méthode correspondante sur le classement avec discriminants linéaires.</p>
<p><strong>Q1.</strong> Utilise la fonction sigmoïde pour resserrer la sortie entre 0 et 1. | Uses the sigmoid function to squeeze the output between 0 and 1.</p>
<ul>
<li>Régression logistique</li>
</ul>
<p><strong>Q2.</strong> Implémente la régularisation L2 pour éviter le sur-apprentissage en pénalisant les grands coefficients. | Implements L2 regularization to prevent overfitting by penalizing large coefficients.</p>
<ul>
<li>Régression d&#x27;arête (Ridge regression)</li>
</ul>
<p><strong>Q3.</strong> Minimise la somme des carrés des différences entre les valeurs observées et estimées. | Minimizes the sum of the squared differences between observed and estimated values.</p>
<ul>
<li>Méthode des moindres carrés</li>
</ul>
<p><strong>Q4.</strong> Permet de prédire la probabilité d&#x27;appartenance à une classe sans estimer directement les paramètres de sa distribution. | Allows predicting the probability of belonging to a class without directly estimating its distribution parameters.</p>
<ul>
<li>Régression logistique</li>
</ul>
<p><strong>Q5.</strong> Sensible aux valeurs aberrantes qui peuvent affecter le résultat de l&#x27;ajustement de manière disproportionnée. | Sensitive to outliers as they can disproportionately affect the fit.</p>
<ul>
<li>Méthode des moindres carrés</li>
</ul>
<p><strong>Q6.</strong> Souvent utilisé dans la sélection des caractéristiques car il permet de ramener certains coefficients à zéro. | Often used in feature selection because it can shrink some coefficients to zero.</p>
<ul>
<li>LASSO</li>
</ul>
<p><strong>Q7.</strong> Ne converge que si les données sont linéairement séparables et que le taux d&#x27;apprentissage est suffisamment faible. | Converges only if the data is linearly separable and the learning rate is sufficiently small.</p>
<ul>
<li>Règle du perceptron</li>
</ul>
<p><strong>Q8.</strong> Permet le traitement de très grands ensembles de données, en une seule passe sur celles-ci. | Can process very large datasets, in only one pass over them.</p>
<ul>
<li>Descente du gradient stochastique</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="question-4">Question 4<a href="#question-4" class="hash-link" aria-label="Direct link to Question 4" title="Direct link to Question 4">​</a></h2>
<p>Parmi les éléments ici-bas, sélectionnez ceux qui sont vrais à propos de l&#x27;estimation non paramétrique de densité.</p>
<p><strong>A.</strong> L&#x27;application de la méthode des k-PPV dans un contexte donné est définie principalement par le nombre de voisins, la mesure de la distance et l&#x27;ensemble de données de référence. | The application of the k-NN method in a given context is defined mainly by the number of neighbors, the distance measurement, and the reference dataset.</p>
<ul>
<li><strong>Vrai</strong> Le k-NN dépend du nombre de voisins, de la mesure de la distance et de l&#x27;ensemble de données de référence.</li>
</ul>
<p><strong>B.</strong> La distance de Minkowsky accorde toujours la même importance à toutes les dimensions. | The Minkowsky distance always gives equal weight to all dimensions.</p>
<ul>
<li><strong>Faux</strong> La distance de Minkowsky ne donne pas nécessairement un poids égal à toutes les dimensions. Elle dépend de la valeur de l&#x27;ordre p. Par exemple, lorsque p=1, c&#x27;est la distance de Manhattan, et lorsque p=2, c&#x27;est la distance euclidienne.</li>
</ul>
<p><strong>C.</strong> L&#x27;un des inconvénients des histogrammes en tant que méthode d&#x27;estimation de la densité est qu&#x27;ils peuvent être sensibles à l&#x27;emplacement de départ des compartiments. | One of the drawbacks of histograms as a density estimation method is that they can be sensitive to the starting location of the bins.</p>
<ul>
<li><strong>Vrai</strong> L&#x27;emplacement de départ des compartiments dans les histogrammes peut influencer l&#x27;apparence de l&#x27;histogramme.</li>
</ul>
<p><strong>D.</strong> L&#x27;estimation de densité par noyau peut être étendue au classement, où la fonction discriminante est déterminée sur la base des densités estimées pour chaque classe. | Kernel density estimation can be extended to classification, where the discriminant function is determined based on the estimated densities for each class.</p>
<ul>
<li><strong>Vrai</strong> L&#x27;estimation de densité par noyau peut être utilisée pour le classement.</li>
</ul>
<p><strong>E.</strong> Le taux d&#x27;erreur bayésien optimal représente le taux d&#x27;erreur lorsque les vraies densités de probabilité de classe sont connues ; il est alors impossible d&#x27;obtenir une meilleure généralisation. | The optimal Bayesian error rate represents the error rate when the true class probability densities are known; it is then impossible to achieve better generalization.</p>
<ul>
<li><strong>Vrai</strong> Si les vraies densités de probabilité sont connues, le taux d&#x27;erreur bayésien optimal est le meilleur possible.</li>
</ul>
<p><strong>F.</strong> Des méthodes telles que l&#x27;édition de Wilson et la condensation de Hart peuvent être utilisées pour sélectionner un sous-ensemble représentatif de données dans les k-PPV. | Methods like Wilson&#x27;s editing and Hart&#x27;s condensing can be used to select a representative subset of data in k-NN.</p>
<ul>
<li><strong>Vrai</strong> Les méthodes d&#x27;édition de Wilson et de condensation de Hart aident à sélectionner un sous-ensemble de données pour les k-NN.</li>
</ul>
<p><strong>G.</strong> Le noyau d&#x27;Epanechnikov a un support infini. | The Epanechnikov kernel has an infinite support range.</p>
<ul>
<li><strong>Faux</strong> Le noyau d&#x27;Epanechnikov a un support fini.</li>
</ul>
<p><strong>H.</strong> Dans l&#x27;estimation de densité par noyau, le choix de la largeur de fenêtre affecte le compromis biais-variance : une petite largeur de fenêtre peut conduire à une variance élevée (sur-apprentissage) tandis qu&#x27;une grande largeur de fenêtre peut entraîner un biais élevé (sous-apprentissage). | In kernel density estimation, the choice of bandwidth affects the bias-variance trade-off: a small bandwidth can lead to high variance (overfitting) while a large bandwidth can cause high bias (underfitting).</p>
<ul>
<li><strong>Vrai</strong> La largeur de la fenêtre (ou la bande passante) dans l&#x27;estimation de densité par noyau affecte le compromis entre biais et variance.</li>
</ul>
<p><strong>I.</strong> L&#x27;estimation de densité par noyau fournit une estimation plus souple que l&#x27;estimateur naïf d&#x27;histogramme. | Kernel density estimation provides a softer estimate compared to the naive histogram estimator.</p>
<ul>
<li><strong>Vrai</strong> L&#x27;estimation de densité par noyau est généralement plus souple et continue que l&#x27;estimation basée sur des histogrammes.</li>
</ul>
<p><strong>J.</strong> Les méthodes non paramétriques ne posent pas d&#x27;hypothèses fortes sur la nature de la distribution sous-jacente des données. | Nonparametric methods make no strong assumptions about the form of the underlying distribution of the data.</p>
<ul>
<li><strong>Vrai</strong> Les méthodes non paramétriques n&#x27;assument pas de forme spécifique pour la distribution sous-jacente.</li>
</ul>
<p>Donc, les énoncés A, C, D, E, F, H, I, et J sont vrais.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/courses/university/gif-7005/quiz-2.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/courses/university/gif-7005/quiz-1"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Quiz 1 du 27 septembre 2023</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/courses/university/gif-7005/quiz-3"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Quiz 3 du 25 octobre 2023</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#question-1" class="table-of-contents__link toc-highlight">Question 1</a></li><li><a href="#question-2" class="table-of-contents__link toc-highlight">Question 2</a></li><li><a href="#question-3" class="table-of-contents__link toc-highlight">Question 3</a></li><li><a href="#question-4" class="table-of-contents__link toc-highlight">Question 4</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Alain Boisvert. Construit avec Docusaurus.</div></div></div></footer></div>
</body>
</html>
<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-courses/gif-7005/week-10" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">Semaine 10 : Réseaux de neurones à convolution | Alain Boisvert</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://boisalai.github.io/docs/courses/gif-7005/week-10"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Semaine 10 : Réseaux de neurones à convolution | Alain Boisvert"><meta data-rh="true" name="description" content="Séance du 8 nov. 2023."><meta data-rh="true" property="og:description" content="Séance du 8 nov. 2023."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://boisalai.github.io/docs/courses/gif-7005/week-10"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/gif-7005/week-10" hreflang="en"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/gif-7005/week-10" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Alain Boisvert RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Alain Boisvert Atom Feed">



<link rel="stylesheet" href="/fonts/font-awesome/fontawesome.css">
<link rel="stylesheet" href="/fonts/font-awesome/solid.css">
<link rel="stylesheet" href="/fonts/font-awesome/regular.css">
<link rel="stylesheet" href="/fonts/font-awesome/brands.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.b5c999da.css">
<script src="/assets/js/runtime~main.e6737288.js" defer="defer"></script>
<script src="/assets/js/main.a09b2bce.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Alain Boisvert</b></a><a class="navbar__item navbar__link" target="" href="/docs/courses/ift-7022">IFT-7022</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" target="" href="/docs/courses/gif-7005">GIF-7005</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/boisalai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-github"> </a><a href="https://www.linkedin.com/in/alain-boisvert-98b058156/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-linkedin-in"> </a><a href="mailto:ay.boisvert@gmail.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-solid fa-envelope"> </a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Alain Boisvert</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/cv">Curriculum vitæ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/learning">Learning path</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/certificates">Certificates</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/courses">Courses</a><button aria-label="Collapse sidebar category &#x27;Courses&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/courses/gif-7005">GIF-7005 Introduction à l&#x27;apprentissage automatique</a><button aria-label="Collapse sidebar category &#x27;GIF-7005 Introduction à l&#x27;apprentissage automatique&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-01">Semaine 1 Introduction à l&#x27;apprentissage</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-02">Semaine 2 Méthodes paramétriques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-03">Semaine 3 Méthodes multivariées</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-04">Semaine 4 Méthodes non paramétriques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-05">Semaine 5 Discriminants linéaires</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-06">Semaine 6 Méthodes à noyau</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-07">Semaine 7 Perceptron multicouche</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-08">Semaine 8 Apprentissage profond</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/courses/gif-7005/week-10">Semaine 10 Réseau de neurones à convolution</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-11">Semaine 11 Méthodes par ensembles</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-12">Semaine 12 Prétraitements et analyse de données</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-1">Devoir 1 du 4 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-2">Devoir 2 du 18 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-3">Devoir 3 du 8 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-4">Devoir 4 du 22 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-1">Quiz 1 du 27 septembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-2">Quiz 2 du 11 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-3">Quiz 3 du 25 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-4">Quiz 4 du 15 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/examen">Examen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/projet">Projet</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/courses/ift-7022">IFT-7022 Traitement automatique de la langue naturelle</a><button aria-label="Expand sidebar category &#x27;IFT-7022 Traitement automatique de la langue naturelle&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chatgpt-building-systems">Building Systems with the ChatGPT API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chatgpt-prompt-engineering">ChatGPT Prompt Engineering for Developers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/fine-tuning-llms">Training and fine-tuning LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/langchain-1">LangChain for LLM Application Development</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/pair-prog-with-llm">Pair Programming with a Large Language Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chat-with-your-data">LangChain Chat with Your Data</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/references">References</a><button aria-label="Expand sidebar category &#x27;References&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/code-snippets">Code Snippets</a><button aria-label="Expand sidebar category &#x27;Code Snippets&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/courses"><span itemprop="name">Courses</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/courses/gif-7005"><span itemprop="name">GIF-7005 Introduction à l&#x27;apprentissage automatique</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Semaine 10 Réseau de neurones à convolution</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Semaine 10 : Réseaux de neurones à convolution</h1>
<p>Séance du 8 nov. 2023.</p>
<p>Références :</p>
<ul>
<li>Y. LeCun, Y. Bengio et G. Hinton. <a href="https://doi.org/10.1038/nature14539" target="_blank" rel="noopener noreferrer">Deep learning</a>. Nature, vol. 521, pages 436–444, 2015.</li>
<li>I. Goodfellow, Y. Bengio et A. Courville. “<a href="http://www.deeplearningbook.org/" target="_blank" rel="noopener noreferrer">Deep Learning</a>”, MIT Press, 2016.</li>
<li>G. Hinton, Y. Bengio et Y. LeCun, <a href="https://nips.cc/Conferences/2015/Schedule?showEvent=4891" target="_blank" rel="noopener noreferrer">Deep Learning NIPS’15 Tutorial</a>, 2015.</li>
<li>📗<!-- -->  <a href="https://www.statlearning.com/" target="_blank" rel="noopener noreferrer">James et coll. (2023)</a> : chap. 10</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="101-convolution-et-traitement-des-images">10.1 Convolution et traitement des images<a href="#101-convolution-et-traitement-des-images" class="hash-link" aria-label="Direct link to 10.1 Convolution et traitement des images" title="Direct link to 10.1 Convolution et traitement des images">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="convolution">Convolution<a href="#convolution" class="hash-link" aria-label="Direct link to Convolution" title="Direct link to Convolution">​</a></h3>
<ul>
<li>Convolution : produit de deux fonctions sur un même domaine</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>≡</mo><msubsup><mo>∫</mo><mrow><mi>t</mi><mo>=</mo><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi mathvariant="normal">∞</mi></msubsup><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>t</mi><mo stretchy="false">)</mo><mtext> </mtext><mi>g</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mtext> </mtext><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">f(x) \ast g(x) \equiv \int_{t=-\infty}^\infty f(x-t)\,g(t)\,dt</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≡</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.3846em;vertical-align:-0.9703em"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4143em"><span style="top:-1.7881em;margin-left:-0.4445em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9703em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span></span></span>
<ul>
<li>Formulation discrète</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>g</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>≡</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi mathvariant="normal">∞</mi></munderover><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>t</mi><mo stretchy="false">)</mo><mtext> </mtext><mi>g</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) \ast g(x) \equiv \sum_{t=-\infty}^\infty f(x-t)\,g(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≡</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.9597em;vertical-align:-1.3083em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em"><span style="top:-1.9em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3083em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></span>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="convolution-et-estimation-de-densité">Convolution et estimation de densité<a href="#convolution-et-estimation-de-densité" class="hash-link" aria-label="Direct link to Convolution et estimation de densité" title="Direct link to Convolution et estimation de densité">​</a></h3>
<ul>
<li>Distribution de DIrac décentrée</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">∞</mi><mtext> si </mtext><mi>x</mi><mo>=</mo><mi>t</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mtext> autrement </mtext></mrow></mstyle></mtd></mtr></mtable></mrow><mo separator="true">,</mo><mspace width="1em"></mspace><msubsup><mo>∫</mo><mrow><mi>t</mi><mo>=</mo><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi mathvariant="normal">∞</mi></msubsup><mi>δ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>t</mi><mo stretchy="false">)</mo><mtext> </mtext><mi>d</mi><mi>t</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\delta(x-t) =
\begin{cases}
\infty \text{ si } x = t \\
0 \text{ autrement }
\end{cases},
\hspace{10pt}
\int_{t=-\infty}^\infty \delta(x-t)\,dt = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">∞</span><span class="mord text"><span class="mord"> si </span></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">t</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">0</span><span class="mord text"><span class="mord"> autrement </span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4143em"><span style="top:-1.7881em;margin-left:-0.4445em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-3.8129em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9703em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>
<ul>
<li>Convolution sur Dirac décentrés</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>δ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>u</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) \ast \delta(x-u) = f(x-u)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">u</span><span class="mclose">)</span></span></span></span></span>
<ul>
<li>Estimation de densité à noyau : convolution du noyau avec plusieurs Diracs centrés sur les données</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mi>h</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>K</mi><mrow><mo fence="true">(</mo><mfrac><mrow><mi>x</mi><mo>−</mo><msup><mi>x</mi><mi>t</mi></msup></mrow><mi>h</mi></mfrac><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mi>h</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>K</mi><mrow><mo fence="true">(</mo><mfrac><mi>x</mi><mi>h</mi></mfrac><mo fence="true">)</mo></mrow><mo>∗</mo><mi>δ</mi><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msup><mi>x</mi><mi>t</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{p}(x) = \frac{1}{Nh} \sum_{t=1}^N K\left(\frac{x-x^t}{h}\right) = \frac{1}{Nh} \sum_{t=1}^N K \left(\frac{x}{h}\right) \ast \delta(x-x^t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">p</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4706em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7936em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0936em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8436em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="traitement-dimages">Traitement d&#x27;images<a href="#traitement-dimages" class="hash-link" aria-label="Direct link to Traitement d&#x27;images" title="Direct link to Traitement d&#x27;images">​</a></h3>
<ul>
<li>Convolution 2D est un élément de base du traitement d&#x27;images</li>
</ul>
<p><img loading="lazy" alt="s95" src="/assets/images/s95-7ccccea8dbd79138ec65c8a11012adcd.png" width="1338" height="690" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="exemples-de-filtres">Exemples de filtres<a href="#exemples-de-filtres" class="hash-link" aria-label="Direct link to Exemples de filtres" title="Direct link to Exemples de filtres">​</a></h3>
<p><img loading="lazy" alt="s96" src="/assets/images/s96-a4ce981f524c1a46ff3b7cb82dcc8a2f.png" width="1610" height="860" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="opérateur-de-sobel">Opérateur de Sobel<a href="#opérateur-de-sobel" class="hash-link" aria-label="Direct link to Opérateur de Sobel" title="Direct link to Opérateur de Sobel">​</a></h3>
<ul>
<li>Filtre classique pour la détection d’arêtes</li>
<li>Calcul les gradients locaux de l’intensit´e de l’image</li>
<li>S’appuie sur deux convolutions pour obtenir le gradient vertical <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">G</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{G}_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathbf">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> et le gradient horizontal <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">G</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{G}_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9722em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathbf">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>
d&#x27;une image <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf">A</span></span></span></span>, le résultat est une image <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">G</mi><mo>=</mo><msqrt><mrow><msubsup><mi mathvariant="bold">G</mi><mi>x</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mi mathvariant="bold">G</mi><mi>y</mi><mn>2</mn></msubsup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\mathbf{G} = \sqrt{\mathbf{G}_x^2 + \mathbf{G}_y^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf">G</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6765em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1635em"><span class="svg-align" style="top:-3.8em"><span class="pstrut" style="height:3.8em"></span><span class="mord" style="padding-left:1em"><span class="mord"><span class="mord mathbf">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7401em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathbf">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7401em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span></span></span><span style="top:-3.1235em"><span class="pstrut" style="height:3.8em"></span><span class="hide-tail" style="min-width:1.02em;height:1.88em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.88em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6765em"><span></span></span></span></span></span></span></span></span>.</li>
</ul>
<p><img loading="lazy" alt="s97" src="/assets/images/s97-99df4839296b4d31b6256267a5de8272.png" width="1456" height="592" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="102-réseau-de-neurones-à-convolution">10.2 Réseau de neurones à convolution<a href="#102-réseau-de-neurones-à-convolution" class="hash-link" aria-label="Direct link to 10.2 Réseau de neurones à convolution" title="Direct link to 10.2 Réseau de neurones à convolution">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="réseaux-de-neurones-à-convolution">Réseaux de neurones à convolution<a href="#réseaux-de-neurones-à-convolution" class="hash-link" aria-label="Direct link to Réseaux de neurones à convolution" title="Direct link to Réseaux de neurones à convolution">​</a></h3>
<ul>
<li>Idée : définir des réseaux de neurones comportant des opérations de convolution<!-- -->
<ul>
<li>Apprendre les valeurs numériques des filtres convolués</li>
<li>Définir un réseau exploitant des éléments de la structure des données<!-- -->
<ul>
<li>Son ou parole : données temporelles (convolutions 1D)</li>
<li>Image : données spatiales (convolutions 2D)</li>
<li>Vidéo : données spatio-temporelles (convolutions 3D)</li>
</ul>
</li>
<li>Enchaînement d’étages de convolutions, filtrant sortie de couche précédente</li>
<li>Permet une modèlisation plus compacte que réseaux pleinement connectés et invariante en translation</li>
</ul>
</li>
<li>Quelques composants d’un réseaux à convolution<!-- -->
<ul>
<li>Couche de filtres convolués sur les différents canaux</li>
<li>Pooling : valeur maximale (max pool) ou moyenne (avg pool) dans une certaine fenêtre convoluée</li>
<li>Fonctions de transfert : ReLU, etc.</li>
<li>Près de la sortie, couches pleinement connectées (comme avec perceptron multicouche)</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="réseau-à-convolution">Réseau à convolution<a href="#réseau-à-convolution" class="hash-link" aria-label="Direct link to Réseau à convolution" title="Direct link to Réseau à convolution">​</a></h3>
<ul>
<li>Image</li>
<li>Convolutions et ReLU</li>
<li>Convolutions et ReLU</li>
<li>Max pooling</li>
<li>Convolutions et ReLU</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="103-exemples-de-réseau-à-convolution">10.3 Exemples de réseau à convolution<a href="#103-exemples-de-réseau-à-convolution" class="hash-link" aria-label="Direct link to 10.3 Exemples de réseau à convolution" title="Direct link to 10.3 Exemples de réseau à convolution">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lenet5">LeNet5<a href="#lenet5" class="hash-link" aria-label="Direct link to LeNet5" title="Direct link to LeNet5">​</a></h3>
<ul>
<li>LeNet5 : réseau à convolution classique, proposé dans les années 1990<!-- -->
<ul>
<li>3 couches de convolutions, 2 couches de average pooling, 2 couches pleinement connectées</li>
<li>60k paramàtres (de 10M à 100M avec réseaux modernes)</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="s98" src="/assets/images/s98-5c9318464d85a76a775616a775da647f.png" width="1622" height="534" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="alexnet">AlexNet<a href="#alexnet" class="hash-link" aria-label="Direct link to AlexNet" title="Direct link to AlexNet">​</a></h3>
<ul>
<li>AlexNet : réseau pour la reconnaissance d’objets<!-- -->
<ul>
<li>Gagnant du concours ImageNet 2012</li>
<li>Implémenté pour calculs sur GPU</li>
<li>Souvent utilisé comme modèle de base pour transfert de représentations</li>
<li>8 couches de convolution, quelques couches de max pooling, 3 couches pleinement connectées</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vgg">VGG<a href="#vgg" class="hash-link" aria-label="Direct link to VGG" title="Direct link to VGG">​</a></h3>
<ul>
<li>VGGNet : plus grande profondeur avec topologie simplifiée<!-- -->
<ul>
<li>Gagnant du concours ImageNet 2013</li>
<li>Profondeur est un élément critique pour de bonnes performances</li>
<li>Similaire à AlexNet, mais avec seulement convolutions 3 × 3, max pooling 2 × 2, 3 couches pleinement connectées et 16 couches au total (VGG-16)</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="VGG" src="/assets/images/vgg-2864307890d9cafc239d18d4f4bee355.png" width="888" height="502" class="img_ev3q"></p>
<p>Cette figure présente le réseau VGG-16. Vous trouverez abondamment de documentation sur ce réseau sur le Web, par exemple :
<a href="https://datagen.tech/guides/computer-vision/vgg16/" target="_blank" rel="noopener noreferrer">ici</a> ou <a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener noreferrer">ici</a>.</p>
<p>Pour répondre aux questions :</p>
<ul>
<li>Les deux premières couches sont (convolution + ReLu).</li>
<li>On applique ReLU sur chacune des valeurs des matrices résultant des convolutions.</li>
<li>La troisième dimension est le nombre de filtres de convolution utilisés pour la couche en question.</li>
</ul>
<p>Pour une explication plus précise sur les différentes composantes formant les réseaux à convolutions, voir
<a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks" target="_blank" rel="noopener noreferrer">ici</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="resnet">ResNet<a href="#resnet" class="hash-link" aria-label="Direct link to ResNet" title="Direct link to ResNet">​</a></h3>
<ul>
<li>Réseaux résiduels : permettre des connexions directes entre couches non adjacentes (skip links)</li>
<li>Permet des réseaux beaucoup plus profonds et performants<!-- -->
<ul>
<li>Gagnant de compétition ImageNet 2015 (3,57 % d’erreur top 5)</li>
<li>Facilite l’optimisation et la propagation du signal à travers le réseau</li>
<li>Bloc résiduel doit faire mieux qu’un traitement directement sur le bloc précédent</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="s99" src="/assets/images/s99-15ba11603c3d2a299acf78aad159986d.png" width="1532" height="416" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="densenet">DenseNet<a href="#densenet" class="hash-link" aria-label="Direct link to DenseNet" title="Direct link to DenseNet">​</a></h3>
<ul>
<li>Observation : réseaux à convolution peuvent être plus profonds et obtenir de meilleures performances avec connections proches dans tout le réseau à son entrée</li>
<li>DenseNet : connecter chaque couche à toutes les couches qui précèdent<!-- -->
<ul>
<li>Réseau à <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span> couches aura <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>L</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">L(L+1)/2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mord">/2</span></span></span></span> connections directes entre les couches</li>
</ul>
</li>
<li>En pratique, on crée des blocs denses séparés par des couches de convolutions et de pooling</li>
<li>Chaque couche dans un bloc dense peut être relativement &quot;étroite&quot;, c&#x27;est-à-dire peut comprendre peu de neurones</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="efficientnet">EfficientNet<a href="#efficientnet" class="hash-link" aria-label="Direct link to EfficientNet" title="Direct link to EfficientNet">​</a></h3>
<ul>
<li>EfficientNet : ajustement optimal de la taille de réseaux à convolution<!-- -->
<ul>
<li>Comment faire l’ajustement de l’architecture de réseaux selon les ressources disponibles ?</li>
</ul>
</li>
<li>Idée : si la résolution de l’image est plus élevée, les performances seront meilleures, mais les ressources requises (profondeur et largeur) sont plus
importants pour bien capturer les détails des images</li>
<li>Ajustement proportionnel de la profondeur, largeur et résolution selon facteur <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span></span></span></span>.<!-- -->
<ul>
<li>Profondeur : nombre de couches du réseau, selon <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>α</mi><mi>ϕ</mi></msup></mrow><annotation encoding="application/x-tex">\alpha^\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span></span></span></span></span></span></span></li>
<li>Largeur : nombre de canaux dans chaque couche, selon <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>β</mi><mi>ϕ</mi></msup></mrow><annotation encoding="application/x-tex">\beta^\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0435em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span></span></span></span></span></span></span></li>
<li>Résolution : ajustement de la résolution de l’image d’entrée, selon <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>γ</mi><mi>ϕ</mi></msup></mrow><annotation encoding="application/x-tex">\gamma^\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0435em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span></span></span></span></span></span></span></span></li>
<li>Valeurs de <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span></span></span></span> déterminée expérimentalement (recherche en grille) pour un réseau ayant ses ressources doublées (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>⋅</mo><msup><mi>β</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>γ</mi><mn>2</mn></msup><mo>∼</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">\alpha \cdot \beta^2 \cdot \gamma^2 \sim 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4445em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span>)</li>
</ul>
</li>
<li>Architecture basée sur MobileNet V2, avec goulot d&#x27;étranglement inversé des connexions résiduelles</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ajustement-de-la-taille-dans-efficientnet">Ajustement de la taille dans EfficientNet<a href="#ajustement-de-la-taille-dans-efficientnet" class="hash-link" aria-label="Direct link to Ajustement de la taille dans EfficientNet" title="Direct link to Ajustement de la taille dans EfficientNet">​</a></h3>
<p><img loading="lazy" alt="s100" src="/assets/images/s100-1b4c917c4a238af521d547f3ff69eeec.png" width="2186" height="1056" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performances-avec-efficientnet">Performances avec EfficientNet<a href="#performances-avec-efficientnet" class="hash-link" aria-label="Direct link to Performances avec EfficientNet" title="Direct link to Performances avec EfficientNet">​</a></h3>
<ul>
<li>À ressources égales, EfficientNet offre des performances supérieures</li>
<li>Huit versions (EfficientNet-B0 à B7) ont été proposées pour différents compromis ressources requises / performance</li>
<li>Modèles idéaux pour utilisation dans dispositifs mobiles et l’informatique en périphérie (<em>edge computing</em>)</li>
</ul>
<p><img loading="lazy" alt="s100" src="/assets/images/s100-1b4c917c4a238af521d547f3ff69eeec.png" width="2186" height="1056" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="u-net">U-Net<a href="#u-net" class="hash-link" aria-label="Direct link to U-Net" title="Direct link to U-Net">​</a></h3>
<ul>
<li>Réseaux présentés jusqu’à présent d’abord proposés et testés pour reconnaissance d’objets (classement)<!-- -->
<ul>
<li>D’autres tâches possibles en vision : détection, suivi, etc.</li>
</ul>
</li>
<li>Segmentation : identifier régions cohérentes de l’image<!-- -->
<ul>
<li>Séparer les différentes régions</li>
<li>Donner une étiquette à chaque région</li>
</ul>
</li>
<li>U-Net : réseau proposé en imagerie biomédicale<!-- -->
<ul>
<li>Réseau pleinement convolutionnel, donne une image en sortie</li>
<li>Compression de l’information en milieu de réseau, similaire à un auto-encodeur</li>
<li>Skip links permettent de conserver structure spatiale</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="s102" src="/assets/images/s102-a83a07524eff7aac9851b213cd5536bc.png" width="2194" height="1098" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="104-génération-dimages">10.4 Génération d&#x27;images<a href="#104-génération-dimages" class="hash-link" aria-label="Direct link to 10.4 Génération d&#x27;images" title="Direct link to 10.4 Génération d&#x27;images">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="génération-dexemples">Génération d&#x27;exemples<a href="#génération-dexemples" class="hash-link" aria-label="Direct link to Génération d&#x27;exemples" title="Direct link to Génération d&#x27;exemples">​</a></h3>
<ul>
<li>Idée : générer des données d’entrées à partir d’une sortie désirée<!-- -->
<ul>
<li>Générer donc un modèle de la donnée pouvant produire la sortie selon le réseau de neurones</li>
</ul>
</li>
<li>Approche : descendre le gradient sur la donnée d’entrée<!-- -->
<ul>
<li>On va générer une nouvelle donnée à partir de la valeur initiale de <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em"></span><span class="mord mathbf">x</span></span></span></span> et la sortie désirée <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">r</mi></mrow><annotation encoding="application/x-tex">\mathbf{r}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em"></span><span class="mord mathbf">r</span></span></span></span></li>
<li>Poids du réseau ne changent pas</li>
</ul>
</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi mathvariant="bold">x</mi><mo>=</mo><mo>−</mo><mi>η</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold">x</mi><mi mathvariant="normal">∣</mi><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold">x</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\Delta \mathbf{x} = - \eta \frac{\partial E(\mathbf{x}|\theta)}{\partial \mathbf{x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathbf">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.113em;vertical-align:-0.686em"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.03588em">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathbf">x</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mopen">(</span><span class="mord mathbf">x</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transfert-de-style">Transfert de style<a href="#transfert-de-style" class="hash-link" aria-label="Direct link to Transfert de style" title="Direct link to Transfert de style">​</a></h3>
<ul>
<li>Idée : transférer le style d’une image dans une nouvelle image<!-- -->
<ul>
<li>Comparer le contenu dans les couches de convolution (ex. VGG19) et le style (matrice de Gram)</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="s103" src="/assets/images/s103-8b9a21caf51680cce3ab0fd35e65fd39.png" width="2174" height="752" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="generative-adversarial-networks-gan">Generative Adversarial Networks (GAN)<a href="#generative-adversarial-networks-gan" class="hash-link" aria-label="Direct link to Generative Adversarial Networks (GAN)" title="Direct link to Generative Adversarial Networks (GAN)">​</a></h3>
<ul>
<li>Modèle GAN : mettre en compétition deux réseaux de neurones<!-- -->
<ul>
<li>Réseau discriminatif : distinguer données véritables du problème des données générées</li>
<li>Réseau génératif : produire des données ayant l’air authentiques</li>
<li>Permet des traitements variés basés sur un apprentissage non supervisé</li>
</ul>
</li>
<li>Exemple : traduction image `a image avec GANs conditionnels</li>
</ul>
<p><img loading="lazy" alt="s104" src="/assets/images/s104-5678b3a3fa366cbc417b678db8e5c440.png" width="1980" height="686" class="img_ev3q"></p>
<p><img loading="lazy" alt="s105" src="/assets/images/s105-acc228afb29cf52d71e3370e5a44f81c.png" width="1732" height="1114" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="caractéristiques-des-gan">Caractéristiques des GAN<a href="#caractéristiques-des-gan" class="hash-link" aria-label="Direct link to Caractéristiques des GAN" title="Direct link to Caractéristiques des GAN">​</a></h3>
<ul>
<li>Méthode clé dans le développement de modèles génératifs<!-- -->
<ul>
<li>La plupart des modèles génératifs historiques capables de résultats réalistes sont basés sur des GANs</li>
<li>Ex. <em>This person does not exist</em> basé sur StyleGAN</li>
</ul>
</li>
<li>Entraînement autosupervisé, sans requérir de données étiquetées ou de mesure de qualité explicite<!-- -->
<ul>
<li>Déclencheur d’avancées dans l’utilisation d’approches autosupervisées pour entraîner des réseaux profonds</li>
<li>Pas de garantie du réalisme et de la qualité des données produites</li>
</ul>
</li>
<li>Modèle complexe à entraîner<!-- -->
<ul>
<li>Equilibre dans l’entraînement des modèles génératifs et discriminatifs difficile à maintenir, tâche discriminative plus facile que la tâche générative</li>
<li>Perte de couverture dans la génération par effondrement sur un mode (<em>mode collapse</em>)</li>
<li>Entraînement peut être assez lourd en calculs</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="105-traitement-de-séquences">10.5 Traitement de séquences<a href="#105-traitement-de-séquences" class="hash-link" aria-label="Direct link to 10.5 Traitement de séquences" title="Direct link to 10.5 Traitement de séquences">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="réseau-récurrent">Réseau récurrent<a href="#réseau-récurrent" class="hash-link" aria-label="Direct link to Réseau récurrent" title="Direct link to Réseau récurrent">​</a></h3>
<ul>
<li>Réseaux usuels (<em>feedforward</em>) : données propagées dans le réseau, indépendant des données suivantes / précédentes<!-- -->
<ul>
<li>Traitement de donnés séquentielles important dans nombreux contextes</li>
</ul>
</li>
<li>Réseaux récurrents : connexions avec valeurs précédentes<!-- -->
<ul>
<li>Traitement avec algorithmes habituels en déroulant le réseau</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="s106" src="/assets/images/s106-814cde3bb6463f554a7c989115f63e45.png" width="1836" height="612" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="long-short-term-memory-lstm">Long Short-Term Memory (LSTM)<a href="#long-short-term-memory-lstm" class="hash-link" aria-label="Direct link to Long Short-Term Memory (LSTM)" title="Direct link to Long Short-Term Memory (LSTM)">​</a></h3>
<ul>
<li>Modèle LSTM : ajouter de la mémoire au réseau</li>
<li>Cellule de mémoire (état), avec quatre neurones<!-- -->
<ul>
<li>Entrée</li>
<li>Activation de l’entrée</li>
<li>Activation de l’oubli</li>
<li>Activation de la sortie</li>
</ul>
</li>
<li>Cellules utilisées comme neurones avec une mémoire dans des réseaux multicouches</li>
</ul>
<p><img loading="lazy" alt="s107" src="/assets/images/s107-f55dcd021e01d1c8f5e9e138923d0757.png" width="1228" height="780" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="variants-des-lstm">Variants des LSTM<a href="#variants-des-lstm" class="hash-link" aria-label="Direct link to Variants des LSTM" title="Direct link to Variants des LSTM">​</a></h3>
<ul>
<li>LSTM bidirectionnel (BiLSTM) : traiter la séquence dans les deux directions<!-- -->
<ul>
<li>Cellules additionelles pour traiter données en sens inverse</li>
<li>Permet de mieux exploiter le contenu de la séquence</li>
<li>Particulièrement utile pour traitement de la langue naturelle</li>
</ul>
</li>
<li>GRU (Gated Recurrent Unit) : simplification du modèle LSTM<!-- -->
<ul>
<li>Simplification du modèle de cellule LSTM en combinant activation de l’entrée et de l’oubli</li>
<li>Fait un compromis entre complexité et performance</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="forces-et-faiblesses-des-lstm">Forces et faiblesses des LSTM<a href="#forces-et-faiblesses-des-lstm" class="hash-link" aria-label="Direct link to Forces et faiblesses des LSTM" title="Direct link to Forces et faiblesses des LSTM">​</a></h3>
<ul>
<li>Forces des LSTM<!-- -->
<ul>
<li>Apte à capturer des relations éloignées dans les séquences</li>
<li>A démontré une grande versatilité dans son application au traitement de séquences (ex. traduction automatisée, reconnaissance de la parole)</li>
<li>Offre un meilleur contrôle sur la dillution du gradient, qui est un enjeu avec les réseaux récurrents classiques</li>
</ul>
</li>
<li>Faiblesses des LSTM<!-- -->
<ul>
<li>Modèles complexes, avec nombre élevé de paramètres, requérant de longs temps d’entraînement et de gros jeux de données</li>
<li>A tendance à faire sur surapprentissage, en particulier sur de petits jeux de données</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="106-réseaux-autoattentifs-transformers">10.6 Réseaux autoattentifs (<em>transformers</em>)<a href="#106-réseaux-autoattentifs-transformers" class="hash-link" aria-label="Direct link to 106-réseaux-autoattentifs-transformers" title="Direct link to 106-réseaux-autoattentifs-transformers">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="réseaux-autoattentifs-transformers">Réseaux autoattentifs (<em>transformers</em>)<a href="#réseaux-autoattentifs-transformers" class="hash-link" aria-label="Direct link to réseaux-autoattentifs-transformers" title="Direct link to réseaux-autoattentifs-transformers">​</a></h3>
<ul>
<li>Réseaux autoattentifs (en anglais : <em>transformer networks</em> ou bien <em>self-attentive network</em>)<!-- -->
<ul>
<li>Utilise un mécanisme d’attention pour établir les relations les éléments d’une séquence (ex. mots d’une phrase)</li>
<li>Conçus pour permettre un traitement parallèle avec têtes multiples, permet utilisation efficace de GPU</li>
<li>Comportent une composante encodeur et une composante décodeur</li>
<li>N’utilise pas de récurrence, le mécanisme d’attention donne une capacité d’utiliser l’ensemble du contexte (mémoire à long terme)</li>
</ul>
</li>
<li>Modèles centraux dans les grands modèles de langue (GPT, BERT)<!-- -->
<ul>
<li>Aussi utilisé avec les images (vision transformers (ViT)), reconnaissance de la parole, etc.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fonctionnement-des-réseaux-autoattentifs">Fonctionnement des réseaux autoattentifs<a href="#fonctionnement-des-réseaux-autoattentifs" class="hash-link" aria-label="Direct link to Fonctionnement des réseaux autoattentifs" title="Direct link to Fonctionnement des réseaux autoattentifs">​</a></h3>
<ul>
<li>Entrée : transformation de la séquence d’entrée en vecteur<!-- -->
<ul>
<li>Pour texte, plongement lexical + encodage positionnel de chaque mot</li>
</ul>
</li>
<li>Encodeur : attention sur plusieurs têtes + renormalisation<!-- -->
<ul>
<li>Attention calculée entre tous les éléments</li>
<li>Normalisation par couche pleinement connectées</li>
</ul>
</li>
<li>Sortie : transformation de la séquence de sortie en vecteur</li>
<li>Décodeur : mécanisme d’attention sur sortie et entrée<!-- -->
<ul>
<li>Premières étapes seulement sur sortie masquée</li>
<li>Étapes suivantes en combinant représentation de la sortie et de l’entrée</li>
<li>Normalisation par couche pleinement connectées</li>
<li>Probabilités du prochain mot en sortie</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="s108" src="/assets/images/s108-145afe23e63f0cc39f21c73a6ad42576.png" width="946" height="1068" class="img_ev3q"></p>
<p><img loading="lazy" alt="F-f7fG4boAANtUZ.png" src="/assets/images/F-f7fG4boAANtUZ-1bae61332b2c3406a5bb2d15d0587e56.png" width="1200" height="1691" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mécanisme-dattention">Mécanisme d’attention<a href="#mécanisme-dattention" class="hash-link" aria-label="Direct link to Mécanisme d’attention" title="Direct link to Mécanisme d’attention">​</a></h3>
<ul>
<li>Calcul de l&#x27;attention entre la requête <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8805em;vertical-align:-0.1944em"></span><span class="mord mathbf">Q</span></span></span></span>, la clé <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">K</mi></mrow><annotation encoding="application/x-tex">\mathbf{K}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf">K</span></span></span></span> et la valeur <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">V</mi></mrow><annotation encoding="application/x-tex">\mathbf{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf" style="margin-right:0.01597em">V</span></span></span></span> selon :</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi mathvariant="bold">Q</mi><mo separator="true">,</mo><mi mathvariant="bold">K</mi><mo separator="true">,</mo><mi mathvariant="bold">V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="bold">Q</mi><msup><mi mathvariant="bold">K</mi><mi mathvariant="normal">⊤</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi mathvariant="bold">V</mi></mrow><annotation encoding="application/x-tex">\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left( \frac{\mathbf{Q}\mathbf{K}^\top}{\sqrt{d_k}} \right) \mathbf{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord mathbf">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathbf">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathbf" style="margin-right:0.01597em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.4761em;vertical-align:-0.95em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5261em"><span style="top:-2.2528em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathbf">Q</span><span class="mord"><span class="mord mathbf">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathbf" style="margin-right:0.01597em">V</span></span></span></span></span>
<ul>
<li>Les valeurs de <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8805em;vertical-align:-0.1944em"></span><span class="mord mathbf">Q</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">K</mi></mrow><annotation encoding="application/x-tex">\mathbf{K}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf">K</span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">V</mi></mrow><annotation encoding="application/x-tex">\mathbf{V}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf" style="margin-right:0.01597em">V</span></span></span></span> découlent de l&#x27;application de poids <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{W}_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9722em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{W}_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{W}_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> sur les données <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf">X</span></span></span></span>.</li>
<li>Division par <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.1828em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span></span> pour stabiliser le gradient (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> : taille des clés <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">K</mi></mrow><annotation encoding="application/x-tex">\mathbf{K}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em"></span><span class="mord mathbf">K</span></span></span></span>)</li>
<li>Chaque tête travaille en parallèle avec ses propres poids <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mi>q</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{W}_q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9722em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{W}_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">W</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{W}_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.016em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>.</li>
</ul>
<p><img loading="lazy" alt="s109" src="/assets/images/s109-467805f92b7647b5d339607b614d0f6b.png" width="1852" height="1030" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="exemple-dapplication-en-traduction">Exemple d’application en traduction<a href="#exemple-dapplication-en-traduction" class="hash-link" aria-label="Direct link to Exemple d’application en traduction" title="Direct link to Exemple d’application en traduction">​</a></h3>
<p><img loading="lazy" alt="s110" src="/assets/images/s110-b1d9515d6099fb0472e31207d92a5375.png" width="1786" height="1158" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="grands-modèles-de-langue">Grands modèles de langue<a href="#grands-modèles-de-langue" class="hash-link" aria-label="Direct link to Grands modèles de langue" title="Direct link to Grands modèles de langue">​</a></h3>
<ul>
<li>BERT (<em>Bidirectional Encoder Representations from Transformers</em>)<!-- -->
<ul>
<li>Proposé en 2018 par une équipe de chercheurs de Google</li>
<li>Formé d’un module de plongement lexical, plusieurs couches d’encodeurs autoattentifs, et d’une conversion vers sortie probabiliste</li>
<li>Rapidement devenu un modèle central en traitement de la langue naturelle</li>
<li>Depuis 2020, pratiquement toutes les requêtes de recherche en anglais sur Google sont traitées avec BERT</li>
</ul>
</li>
<li>GPT (<em>Generative Pre-trained Transformer</em>)<!-- -->
<ul>
<li>Famille de modèles d’OpenAI basés sur des transformeurs, proposée en 2018 (GPT-1)</li>
<li>GPT-3 : GPT-1 + normalisation modifiée (GPT-2) + mise à l’échelle, proposé en 2020, 175G de paramètres entraîné sur 500G tokens</li>
<li>GPT-4 : architecture non dévoilée mais estimé à 1,7T (1700G) paramètres</li>
<li>ChatGPT : intégration de GPT-3.5 / GPT-4 et apprentissage par renforcement avec rétroaction humaine (RLHF)</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vision-transformers-vit">Vision transformers (ViT)<a href="#vision-transformers-vit" class="hash-link" aria-label="Direct link to Vision transformers (ViT)" title="Direct link to Vision transformers (ViT)">​</a></h3>
<ul>
<li>Vision transformers (ViT) : adaptation de l’architecture de réseaux autoattentifs à la vision numérique<!-- -->
<ul>
<li>Au lieu de traiter des séquences de mots, traite des tuiles de taille fixe, sans recoupement, de l’image</li>
<li>Chaque tuile est représentée par un vecteur 1D, avec information positionnelle ajoutée à la représentation</li>
<li>Représentation des tuiles fournie comme une séquence au réseau autoattentif</li>
</ul>
</li>
<li>Caractéristiques des ViT<!-- -->
<ul>
<li>En mesure de capturer des relations complexes et distantes dans les images, sans requérir des couches de convolution</li>
<li>Peut obtenir des performances au niveau de l’état de l’art, avec suffisamment de données et de ressources</li>
<li>Requiert de très gros jeux de données et entraînement intensif pour bien performer</li>
</ul>
</li>
</ul>
<p><img loading="lazy" alt="s111" src="/assets/images/s111-9e26a22f432edc54d7bf27a4ecfbf986.png" width="2042" height="1112" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="107-modèles-de-diffusion">10.7 Modèles de diffusion<a href="#107-modèles-de-diffusion" class="hash-link" aria-label="Direct link to 10.7 Modèles de diffusion" title="Direct link to 10.7 Modèles de diffusion">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="modèles-de-diffusion">Modèles de diffusion<a href="#modèles-de-diffusion" class="hash-link" aria-label="Direct link to Modèles de diffusion" title="Direct link to Modèles de diffusion">​</a></h3>
<ul>
<li>Modèles de diffusion : classe de modèles génératifs simulant un processus de diffusion aléatoire transformant une instance de données en instance de bruit<!-- -->
<ul>
<li>Inspirés par la physique, avec diffusion de particules d’un milieu de hautes concentrations vers de basses concentrations</li>
<li>Utilisés pour la génération, débruitage ou reconstruction d’images</li>
</ul>
</li>
<li>Processus de diffusion<!-- -->
<ul>
<li>Diffusion avant : démarrer par une image nette sur laquelle on ajout successivement un bruit léger jusqu’à ce que l’image ne soit que du bruit</li>
<li>Diffusion arrière : démarrer le processus d’une image de pur bruit sur laquelle ont applique successivement des opérations de débruitage pour obtenir une image nette</li>
<li>Chaque étape de diffusion avant ou arrière guidé par une fonction de transition, typiquement gaussienne, conditionnée sur l’état actuel</li>
<li>Une fois la mécanique de diffusion arrière (débruitage) bien apprise, elle peut être utilisée pour générer des nouvelles images</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="processus-de-diffusion-avant">Processus de diffusion avant<a href="#processus-de-diffusion-avant" class="hash-link" aria-label="Direct link to Processus de diffusion avant" title="Direct link to Processus de diffusion avant">​</a></h3>
<p><img loading="lazy" alt="s112" src="/assets/images/s112-d4d8afb124803f6192213d6c90d71f6d.png" width="2172" height="828" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="processus-de-diffusion-arrière">Processus de diffusion arrière<a href="#processus-de-diffusion-arrière" class="hash-link" aria-label="Direct link to Processus de diffusion arrière" title="Direct link to Processus de diffusion arrière">  ​</a></h3>
<p><img loading="lazy" alt="s113" src="/assets/images/s113-6e5f1888a1b36dc406272db5c396ecb8.png" width="2152" height="958" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="entraînement-de-modèles-de-diffusion">Entraînement de modèles de diffusion<a href="#entraînement-de-modèles-de-diffusion" class="hash-link" aria-label="Direct link to Entraînement de modèles de diffusion" title="Direct link to Entraînement de modèles de diffusion">​</a></h3>
<ul>
<li>Diffusion avant : typiquement consiste en l’application d’un bruit gaussien sur les pixels<!-- -->
<ul>
<li>Application répétée d’un faible bruit gaussien transforme l’ensemble des pixels en valeurs aléatoires de distribution normale</li>
<li>Niveau de bruit appliqué peut varier dans la séquence selon une cédule</li>
</ul>
</li>
<li>Diffusion arrière : réseau de neurones pour retirer le bruit<!-- -->
<ul>
<li>Utiliser données de la diffusion avant pour entraîner le réseau de débruitage</li>
<li>Réseau de débruitage reçoit niveau de bruit actuel</li>
<li>U-Net couramment utilisés comme réseaux de débruitage</li>
</ul>
</li>
<li>Le processus de diffusion arrière peut être conditionné<!-- -->
<ul>
<li>Classe spécifique visée</li>
<li>Requête texte, en utilisant représentation vectorielle de celle-ci (plongement lexical ou réseau autoattentif)</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="forces-et-faiblesse-des-modèles-de-diffusion">Forces et faiblesse des modèles de diffusion<a href="#forces-et-faiblesse-des-modèles-de-diffusion" class="hash-link" aria-label="Direct link to Forces et faiblesse des modèles de diffusion" title="Direct link to Forces et faiblesse des modèles de diffusion">​</a></h3>
<ul>
<li>Forces des modèles de diffusion<!-- -->
<ul>
<li>Capables de générer des données de haute qualité</li>
<li>Flexibles et peut être adapté à différents types de données, fonctionne avec des distributions de données complexes</li>
</ul>
</li>
<li>Faiblesses des modèles de diffusion<!-- -->
<ul>
<li>Processus de génération peut être lourd en termes computationnels, avec les nombreuses itérations requises dans la diffusion arrière</li>
<li>Entraînement est très lourd en calculs</li>
</ul>
</li>
<li>Ces modèles sont à la base des modèles génératifs d’images comme DALL-E (OpenAI), Midjourney ou Stable Diffusion</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="108-notions-de-base-sur-pytorch">10.8 Notions de base sur PyTorch<a href="#108-notions-de-base-sur-pytorch" class="hash-link" aria-label="Direct link to 10.8 Notions de base sur PyTorch" title="Direct link to 10.8 Notions de base sur PyTorch">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pytorch">PyTorch<a href="#pytorch" class="hash-link" aria-label="Direct link to PyTorch" title="Direct link to PyTorch">​</a></h3>
<ul>
<li>Librairie de différentiation automatique pour l’apprentissage profond</li>
<li>Début octobre 2016 par une équipe de Facebook</li>
<li>Construit par dessus le moteur C de Torch</li>
<li>Plus <em>pythonesque</em> que TensorFlow</li>
<li>Très proche de la syntaxe de numpy</li>
<li>Supporte les calculs par GPU (extrêmement rapide, facteur 10!)</li>
<li>Supporte les graphes dynamiques</li>
<li>Stable et utilisable pour déploiement à grande échelle</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="concept-de-tenseur">Concept de tenseur<a href="#concept-de-tenseur" class="hash-link" aria-label="Direct link to Concept de tenseur" title="Direct link to Concept de tenseur">​</a></h3>
<ul>
<li>Pytorch est organisé autour d’opérations de manipulation de tenseurs, incluant dérivation automatique</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Créer un tenseur à partir d’une liste avec torch.&lt;type&gt;Tensor()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a = torch.FloatTensor([[1,2,3], [2,3,4]])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Créer un tenseur aléatoire</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a = torch.randn(2, 3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(a)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Créer un tenseur à partir d’un array Numpy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a = torch.from_numpy(numpy_array)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># On peut effectuer toute sorte d’opérations sur les tenseurs</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a = torch.FloatTensor([[1,2,3], [2,3,4]])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">b = torch.FloatTensor([[4,3,3], [5,3,4]])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">c = a + b</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(c)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Liste complète ici : <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer">TORCH</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dérivation-automatique">Dérivation automatique<a href="#dérivation-automatique" class="hash-link" aria-label="Direct link to Dérivation automatique" title="Direct link to Dérivation automatique">​</a></h3>
<ul>
<li>Durant l’application des opérations, PyTorch se construit un graphe de calcul<!-- -->
<ul>
<li>Ce graphe permet de suivre toutes les opérations nécessaires au calcul du résultat</li>
</ul>
</li>
<li>Ensuite facile de calculer automatiquement la dérivée à chaque étape du graphe</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Pour indiquer le calcul de la dérivée par rapport à un certain tenseur, </span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># utiliser paramètre requires_grad</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a = torch.FloatTensor([[1,2,3], [2,3,4]], requires_grad=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Ou bien une fois le tenseur existant</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a.requires_grad = True</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="exemple-dune-régression-linéaire">Exemple d’une régression linéaire<a href="#exemple-dune-régression-linéaire" class="hash-link" aria-label="Direct link to Exemple d’une régression linéaire" title="Direct link to Exemple d’une régression linéaire">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Déclarer vecteur de poids et un biais aléatoire</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 10 dimensions</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">W = torch.randn(10, requires_grad=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">b = torch.randn(1, requires_grad=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Executer la chaîne d’opération (très proche de numpy)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># y_hat est la sortie prédite, x l&#x27;entrée</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">y_hat = W.dot(x) + b</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Calculer l’erreur quadratique</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># y est la sortie désirée</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">err = 0.5 * (y_hat - y) ** 2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Dériver l’équation à l’aide de la méthode backward()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">err.backward()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># On peut alors récupérer dérivées dans les tenseurs W et b</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">W_grad = W.grad</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">b_grad = b.grad</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Faire un pas dans la bonne direction pour descendre le gradient</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">W = W - eta * W.grad</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">b = b - eta * b.grad</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="exécution-sur-gpu">Exécution sur GPU<a href="#exécution-sur-gpu" class="hash-link" aria-label="Direct link to Exécution sur GPU" title="Direct link to Exécution sur GPU">​</a></h3>
<ul>
<li>Possible de faire facilement toutes les opérations sur les tenseurs sur un GPU<!-- -->
<ul>
<li>PyTorch définit tenseurs <code>torch.cuda.&lt;type&gt;Tensor</code> de la même manière que ceux vus préalablement.</li>
<li>Pour traduire un tenseur d’un type non-GPU (non-cuda) à un type GPU (cuda) et inversement, il suffit d’utiliser la méthode <code>to</code> :</li>
</ul>
</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">a = a.to(&#x27;cuda&#x27;) # vers le GPU</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">a = a.to(&#x27;cpu&#x27;) # de retour sur le CPU</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Quelle est la différence entre <code>torch.nn</code> et <code>torch.nn.fonctionnel</code>?</div><div class="admonitionContent_BuS1"><p><strong>Réponse :</strong> Alors que le premier définit des classes <code>nn.Module</code>, le second utilise une approche fonctionnelle (sans état).
Pour approfondir un peu : les <code>nn.Modules</code> sont définis comme des classes Python et possèdent des attributs, par exemple,
un module <code>nn.Conv2d</code> aura des attributs internes comme <code>self.weight</code>. <code>F.conv2d</code>, quant à lui, définit juste l&#x27;opération
et nécessite que tous les arguments soient passés (y compris les poids et le biais). En interne, les modules appellent
généralement leur équivalent fonctionnel dans la méthode <code>forward</code> quelque part.</p><p>Cela dit, cela dépend aussi de votre style de codage sur la manière dont vous souhaitez travailler avec vos modules/paramètres,
etc. Bien que les modules puissent être suffisants dans la plupart des cas d&#x27;utilisation, l&#x27;API fonctionnelle pourrait vous
offrir une flexibilité supplémentaire qui est parfois nécessaire.</p><p>Nous avons eu une discussion similaire récemment dans
ce <a href="https://discuss.pytorch.org/t/beginner-should-relu-sigmoid-be-called-in-the-init-method/18689/6?u=ptrblck" target="_blank" rel="noopener noreferrer">fil de discussion</a>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="109-définir-un-réseau">10.9 Définir un réseau<a href="#109-définir-un-réseau" class="hash-link" aria-label="Direct link to 10.9 Définir un réseau" title="Direct link to 10.9 Définir un réseau">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="définir-un-réseau">Définir un réseau<a href="#définir-un-réseau" class="hash-link" aria-label="Direct link to Définir un réseau" title="Direct link to Définir un réseau">​</a></h3>
<ul>
<li>PyTorch offre une manière de déclarer facilement des réseaux<!-- -->
<ul>
<li>Définir réseau avec tenseurs directement serait une tâche ardue</li>
<li>Typiquement on utilise le package <code>torch.nn</code> et on hérite de <code>nn.Module</code></li>
</ul>
</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class MonReseau(nn.Module):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # on d´efinit la structure du r´eseau ici</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # - les couches</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # - les op´erations non-lin´eaires</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # - les m´ethodes de r´egularisation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # on effectue l&#x27;inf´erence ici</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>Plusieurs types de couches sont offertes<!-- -->
<ul>
<li>Composition de modules simples pour créer des modules plus complexes</li>
</ul>
</li>
<li>Exemples de modules de base (voir <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer">TORCH.NN</a>)</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Linéaire</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.nn.Linear(in_features, out_features, bias=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Convolution 2D</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                padding=0, dilation=1, groups=1, bias=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Dropout</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.nn.Dropout(p=0.5, inplace=False)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>Plupart des couches sont également disponibles en fonctions à partir de <code>torch.nn.functional</code>
<ul>
<li>Attention : le module n’enregistre pas ces couches lorsqu’elles sont déclarées directement en fonction</li>
<li>Paramètres de ces couches ne sont pas pris en compte dans la liste des paramètres</li>
<li>Certaines couches comme <code>dropout</code> ou <code>batchnorm</code> ont des comportements différents en entraînement et en test, changer mode du réseau change le comportement d’une
couche classe, mais pas d’une couche fonction</li>
<li>Vaut mieux donc utiliser couches fonctions seulement lorsque la couche n’a pas de paramètres à optimiser et/ou même comportement entre entraînement et test (ex.
fonction d’activation)</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="lenet-5">Lenet-5<a href="#lenet-5" class="hash-link" aria-label="Direct link to Lenet-5" title="Direct link to Lenet-5">​</a></h3>
<p><img loading="lazy" alt="s114" src="/assets/images/s114-302f79bce179db8ff0a6d38da9cc56fa.png" width="2194" height="926" class="img_ev3q"></p>
<ul>
<li>Implémentation PyTorch du réseau Lenet-5 pour un jeu de données avec image sur un channel (tenseur 2D)</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn.functional as F</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class Lenet5(nn.Module):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.C1 = nn.Conv2d(1, 6, kernel_size=5)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.S2 = nn.MaxPool2d(2)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.C3 = nn.Conv2d(6, 16, kernel_size=5)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.S4 = nn.MaxPool2d(2)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.C5 = nn.Linear(16*5*5, 120)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.F6 = nn.Linear(120, 64)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.output = nn.Linear(64, 10)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        y = self.S2(F.relu(self.C1(x)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        y = self.S4(F.relu(self.C3(y)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        y = y.view(-1, 16*5*5) # redimensionne</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        y = F.relu(self.C5(y))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        y = F.relu(self.F6(y))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return self.output(y)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model = Lenet5()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.to(&#x27;cuda&#x27;) # vers le GPU</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.to(&#x27;cpu&#x27;) # de retour sur le CPU</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>Il est également possible de changer le mode du réseau, ce qui changera le
comportement de certaines couches, comme ceci :</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">model = Lenet5()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.train() # en mode entra^ınement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.eval() # en mode test</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Voir <a href="https://github.com/TylerYep/torchinfo" target="_blank" rel="noopener noreferrer">Torchinfo</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1010-manipuler-les-données">10.10 Manipuler les données<a href="#1010-manipuler-les-données" class="hash-link" aria-label="Direct link to 10.10 Manipuler les données" title="Direct link to 10.10 Manipuler les données">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="charger-et-manipuler-des-données">Charger et manipuler des données<a href="#charger-et-manipuler-des-données" class="hash-link" aria-label="Direct link to Charger et manipuler des données" title="Direct link to Charger et manipuler des données">​</a></h3>
<ul>
<li>Classe pour gérer les jeux de données : <code>torch.utils.data.Dataset</code>
<ul>
<li>Doit définir une méthode <code>__getitem__(self, index)</code> pour accéder à une instance</li>
<li>Doit définir une méthode <code>__len__(self)</code> pour retourner la taille du jeu de données</li>
</ul>
</li>
<li>Classe pour charger des lots de données : <code>torch.utils.data.DataLoader</code>
<ul>
<li>Doit recevoir un objet <code>Dataset</code> et une <code>batch_size</code>, d’autres arguments permettent des options avancées</li>
<li><code>DataLoader</code> est un itérateur python</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="charger-et-manipuler-des-images">Charger et manipuler des images<a href="#charger-et-manipuler-des-images" class="hash-link" aria-label="Direct link to Charger et manipuler des images" title="Direct link to Charger et manipuler des images">​</a></h3>
<ul>
<li>Sous-package <code>torchvision</code> implémente plusieurs fonctions utiles pour vision numérique et traitement d’images<!-- -->
<ul>
<li><code>torchvision.datasets</code> permet de télécharger plusieurs jeux de données populaires tels que MNIST, CIFAR ou encore SVHN</li>
<li><code>ImageFolder</code> et <code>DatasetFolder</code> permettent de charger facilement un jeu de données organisées en répertoires</li>
<li><code>torchvision.transforms</code> implémente des transformations sur les images</li>
<li><code>ToTensor</code> permet de convertir en un tenseur PyTorch</li>
<li><code>Normalize</code> permet de normaliser un tenseur PyTorch</li>
</ul>
</li>
<li>Plusieurs autres fonctions disponibles, voir <a href="https://pytorch.org/vision/stable/datasets.html" target="_blank" rel="noopener noreferrer">DATASETS</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="exemple-avec-mnist">Exemple avec MNIST<a href="#exemple-avec-mnist" class="hash-link" aria-label="Direct link to Exemple avec MNIST" title="Direct link to Exemple avec MNIST">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.utils.data import DataLoader</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.datasets import MNIST</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.transforms import ToTensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">batch_size = 64</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># télécharge dans &#x27;path/to/data&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_set = MNIST(&#x27;path/to/data&#x27;, train=True, transform=ToTensor(), download=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1011-entraîner-un-réseau">10.11 Entraîner un réseau<a href="#1011-entraîner-un-réseau" class="hash-link" aria-label="Direct link to 10.11 Entraîner un réseau" title="Direct link to 10.11 Entraîner un réseau">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="entraîner-un-réseau">Entraîner un réseau<a href="#entraîner-un-réseau" class="hash-link" aria-label="Direct link to Entraîner un réseau" title="Direct link to Entraîner un réseau">​</a></h3>
<ul>
<li>Une fois les données chargées, il faut un optimiseur et fonction d’erreur pour faire un entraînement<!-- -->
<ul>
<li>Optimiseurs dans <code>torch.optim</code></li>
<li>Fonctions d’erreurs dans <code>torch.nn</code>, comme les couches</li>
</ul>
</li>
<li>Par exemple, pour effectuer du classement à plusieurs classes, nous pourrions utiliser :<!-- -->
<ul>
<li>Optimiseur par descente du gradient stochastique <code>torch.optim.SGD</code></li>
<li>Entropie croisée <code>torch.nn.CrossEntropyLoss</code></li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="entraînement-de-lenet-5-en-classification">Entraînement de LeNet-5 en classification<a href="#entraînement-de-lenet-5-en-classification" class="hash-link" aria-label="Direct link to Entraînement de LeNet-5 en classification" title="Direct link to Entraînement de LeNet-5 en classification">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">nb_epoch = 10</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">batch_size = 64</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">learning_rate = 0.01</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">momentum = 0.9</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># télécharge dans &#x27;path/to/data&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_set = MNIST(&#x27;path/to/data&#x27;, train=True, transform=ToTensor(), download=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model = Lenet5()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.train() # mettre en mode entraînement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">criterion = torch.nn.CrossEntropyLoss()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for i_epoch in range(nb_epoch):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for i_batch, batch in enumerate(train_loader):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        X, y = batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        optimizer.zero_grad()      # important! remet les gradients à 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        y_hat = model(X)           # calcule la prédiction</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        loss = criterion(y_hat, y) # calcule l&#x27;erreur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        loss.backward()            # dérive le graphe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        optimizer.step()           # effectue une étape d&#x27;optimisation</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="utiliser-un-réseau-pré-entraîné">Utiliser un réseau pré-entraîné<a href="#utiliser-un-réseau-pré-entraîné" class="hash-link" aria-label="Direct link to Utiliser un réseau pré-entraîné" title="Direct link to Utiliser un réseau pré-entraîné">​</a></h3>
<ul>
<li>Possible de sauvegarder un réseau via son dictionnaire d’état (<code>state_dict</code>) et fonction <code>torch.save</code></li>
<li>De la même manière, il est possible de charger un modèle pré-entraîné avec la fonction <code>torch.load</code> et la méthode <code>load_state_dict</code></li>
<li>Il est prudent de charger un réseau avec une indication sur la destination pour être sûr qu’il se retrouve premièrement sur le CPU</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">state = model.state_dict()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.save(state, &#x27;path/to/model&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">state = torch.load(&#x27;path/to/model&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.load_state_dict(state)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">state = torch.load(&#x27;path/to/model&#x27;, map_location=lambda storage, loc: storage)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Voir <a href="https://discuss.pytorch.org/t/on-a-cpu-device-how-to-load-checkpoint-saved-on-gpu-device/349" target="_blank" rel="noopener noreferrer">On a cpu device, how to load checkpoint saved on gpu device</a>.</p>
<ul>
<li>Sous-package <code>torchvision.models</code> implémente plusieurs modèles utiles aux tâches de vision.</li>
<li>Peuvent être chargés avec des poids pré-entraînés sur l’énorme jeu de données d’images naturelles ImageNet</li>
<li>Par exemple, il est possible de charger un ResNet-18 avec les poids pré-entraîné comme suit :</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.models import resnet18</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model = resnet18(pretrained=True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>Accès aux paramètres du réseau avec leur nom de couche avec la méthode <code>named_parameters()</code></li>
<li>Ainsi, il est possible d’analyser le réseau, de le modifier et de geler des couches.</li>
<li>Si vous geler des couches, il est alors important de seulement donner les paramètres devant être optimisés à l’optimiseur</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Analyser le réseau</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for name, param in model.named_parameters():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    print(name)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    print(param.grad)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Modifier une couche</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.nom_de_couche = NouvelleCouche()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Geler des couches</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for name, param in model.named_parameters():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if name == nom_de_couche_a_geler:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        param.requires_grad = False</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Donner les paramètres devant être optimisés à l’optimiseur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">params = filter(lambda x: x.requires_grad, model.parameters())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=momentum)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/courses/gif-7005/week-10.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/courses/gif-7005/week-08"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Semaine 8 Apprentissage profond</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/courses/gif-7005/week-11"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Semaine 11 Méthodes par ensembles</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#101-convolution-et-traitement-des-images" class="table-of-contents__link toc-highlight">10.1 Convolution et traitement des images</a><ul><li><a href="#convolution" class="table-of-contents__link toc-highlight">Convolution</a></li><li><a href="#convolution-et-estimation-de-densité" class="table-of-contents__link toc-highlight">Convolution et estimation de densité</a></li><li><a href="#traitement-dimages" class="table-of-contents__link toc-highlight">Traitement d&#39;images</a></li><li><a href="#exemples-de-filtres" class="table-of-contents__link toc-highlight">Exemples de filtres</a></li><li><a href="#opérateur-de-sobel" class="table-of-contents__link toc-highlight">Opérateur de Sobel</a></li></ul></li><li><a href="#102-réseau-de-neurones-à-convolution" class="table-of-contents__link toc-highlight">10.2 Réseau de neurones à convolution</a><ul><li><a href="#réseaux-de-neurones-à-convolution" class="table-of-contents__link toc-highlight">Réseaux de neurones à convolution</a></li><li><a href="#réseau-à-convolution" class="table-of-contents__link toc-highlight">Réseau à convolution</a></li></ul></li><li><a href="#103-exemples-de-réseau-à-convolution" class="table-of-contents__link toc-highlight">10.3 Exemples de réseau à convolution</a><ul><li><a href="#lenet5" class="table-of-contents__link toc-highlight">LeNet5</a></li><li><a href="#alexnet" class="table-of-contents__link toc-highlight">AlexNet</a></li><li><a href="#vgg" class="table-of-contents__link toc-highlight">VGG</a></li><li><a href="#resnet" class="table-of-contents__link toc-highlight">ResNet</a></li><li><a href="#densenet" class="table-of-contents__link toc-highlight">DenseNet</a></li><li><a href="#efficientnet" class="table-of-contents__link toc-highlight">EfficientNet</a></li><li><a href="#ajustement-de-la-taille-dans-efficientnet" class="table-of-contents__link toc-highlight">Ajustement de la taille dans EfficientNet</a></li><li><a href="#performances-avec-efficientnet" class="table-of-contents__link toc-highlight">Performances avec EfficientNet</a></li><li><a href="#u-net" class="table-of-contents__link toc-highlight">U-Net</a></li></ul></li><li><a href="#104-génération-dimages" class="table-of-contents__link toc-highlight">10.4 Génération d&#39;images</a><ul><li><a href="#génération-dexemples" class="table-of-contents__link toc-highlight">Génération d&#39;exemples</a></li><li><a href="#transfert-de-style" class="table-of-contents__link toc-highlight">Transfert de style</a></li><li><a href="#generative-adversarial-networks-gan" class="table-of-contents__link toc-highlight">Generative Adversarial Networks (GAN)</a></li><li><a href="#caractéristiques-des-gan" class="table-of-contents__link toc-highlight">Caractéristiques des GAN</a></li></ul></li><li><a href="#105-traitement-de-séquences" class="table-of-contents__link toc-highlight">10.5 Traitement de séquences</a><ul><li><a href="#réseau-récurrent" class="table-of-contents__link toc-highlight">Réseau récurrent</a></li><li><a href="#long-short-term-memory-lstm" class="table-of-contents__link toc-highlight">Long Short-Term Memory (LSTM)</a></li><li><a href="#variants-des-lstm" class="table-of-contents__link toc-highlight">Variants des LSTM</a></li><li><a href="#forces-et-faiblesses-des-lstm" class="table-of-contents__link toc-highlight">Forces et faiblesses des LSTM</a></li></ul></li><li><a href="#106-réseaux-autoattentifs-transformers" class="table-of-contents__link toc-highlight">10.6 Réseaux autoattentifs (<em>transformers</em>)</a><ul><li><a href="#réseaux-autoattentifs-transformers" class="table-of-contents__link toc-highlight">Réseaux autoattentifs (<em>transformers</em>)</a></li><li><a href="#fonctionnement-des-réseaux-autoattentifs" class="table-of-contents__link toc-highlight">Fonctionnement des réseaux autoattentifs</a></li><li><a href="#mécanisme-dattention" class="table-of-contents__link toc-highlight">Mécanisme d’attention</a></li><li><a href="#exemple-dapplication-en-traduction" class="table-of-contents__link toc-highlight">Exemple d’application en traduction</a></li><li><a href="#grands-modèles-de-langue" class="table-of-contents__link toc-highlight">Grands modèles de langue</a></li><li><a href="#vision-transformers-vit" class="table-of-contents__link toc-highlight">Vision transformers (ViT)</a></li></ul></li><li><a href="#107-modèles-de-diffusion" class="table-of-contents__link toc-highlight">10.7 Modèles de diffusion</a><ul><li><a href="#modèles-de-diffusion" class="table-of-contents__link toc-highlight">Modèles de diffusion</a></li><li><a href="#processus-de-diffusion-avant" class="table-of-contents__link toc-highlight">Processus de diffusion avant</a></li><li><a href="#processus-de-diffusion-arrière" class="table-of-contents__link toc-highlight">Processus de diffusion arrière</a></li><li><a href="#entraînement-de-modèles-de-diffusion" class="table-of-contents__link toc-highlight">Entraînement de modèles de diffusion</a></li><li><a href="#forces-et-faiblesse-des-modèles-de-diffusion" class="table-of-contents__link toc-highlight">Forces et faiblesse des modèles de diffusion</a></li></ul></li><li><a href="#108-notions-de-base-sur-pytorch" class="table-of-contents__link toc-highlight">10.8 Notions de base sur PyTorch</a><ul><li><a href="#pytorch" class="table-of-contents__link toc-highlight">PyTorch</a></li><li><a href="#concept-de-tenseur" class="table-of-contents__link toc-highlight">Concept de tenseur</a></li><li><a href="#dérivation-automatique" class="table-of-contents__link toc-highlight">Dérivation automatique</a></li><li><a href="#exemple-dune-régression-linéaire" class="table-of-contents__link toc-highlight">Exemple d’une régression linéaire</a></li><li><a href="#exécution-sur-gpu" class="table-of-contents__link toc-highlight">Exécution sur GPU</a></li></ul></li><li><a href="#109-définir-un-réseau" class="table-of-contents__link toc-highlight">10.9 Définir un réseau</a><ul><li><a href="#définir-un-réseau" class="table-of-contents__link toc-highlight">Définir un réseau</a></li><li><a href="#lenet-5" class="table-of-contents__link toc-highlight">Lenet-5</a></li></ul></li><li><a href="#1010-manipuler-les-données" class="table-of-contents__link toc-highlight">10.10 Manipuler les données</a><ul><li><a href="#charger-et-manipuler-des-données" class="table-of-contents__link toc-highlight">Charger et manipuler des données</a></li><li><a href="#charger-et-manipuler-des-images" class="table-of-contents__link toc-highlight">Charger et manipuler des images</a></li><li><a href="#exemple-avec-mnist" class="table-of-contents__link toc-highlight">Exemple avec MNIST</a></li></ul></li><li><a href="#1011-entraîner-un-réseau" class="table-of-contents__link toc-highlight">10.11 Entraîner un réseau</a><ul><li><a href="#entraîner-un-réseau" class="table-of-contents__link toc-highlight">Entraîner un réseau</a></li><li><a href="#entraînement-de-lenet-5-en-classification" class="table-of-contents__link toc-highlight">Entraînement de LeNet-5 en classification</a></li><li><a href="#utiliser-un-réseau-pré-entraîné" class="table-of-contents__link toc-highlight">Utiliser un réseau pré-entraîné</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Alain Boisvert. Construit avec Docusaurus.</div></div></div></footer></div>
</body>
</html>
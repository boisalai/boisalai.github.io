<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-courses/gif-7005/devoir-4" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">Devoir 4 | Alain Boisvert</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://boisalai.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://boisalai.github.io/docs/courses/gif-7005/devoir-4"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Devoir 4 | Alain Boisvert"><meta data-rh="true" name="description" content="D4Q1 - Réseau de neurones à convolution"><meta data-rh="true" property="og:description" content="D4Q1 - Réseau de neurones à convolution"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://boisalai.github.io/docs/courses/gif-7005/devoir-4"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/gif-7005/devoir-4" hreflang="en"><link data-rh="true" rel="alternate" href="https://boisalai.github.io/docs/courses/gif-7005/devoir-4" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Alain Boisvert RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Alain Boisvert Atom Feed">



<link rel="stylesheet" href="/fonts/font-awesome/fontawesome.css">
<link rel="stylesheet" href="/fonts/font-awesome/solid.css">
<link rel="stylesheet" href="/fonts/font-awesome/regular.css">
<link rel="stylesheet" href="/fonts/font-awesome/brands.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.2dcfce69.css">
<script src="/assets/js/runtime~main.7e1e92b9.js" defer="defer"></script>
<script src="/assets/js/main.e46baa82.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Alain Boisvert</b></a><a class="navbar__item navbar__link" target="" href="/docs/courses/ift-7022">IFT-7022</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" target="" href="/docs/courses/gif-7005">GIF-7005</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/boisalai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-github"> </a><a href="https://www.linkedin.com/in/alain-boisvert-98b058156/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-brands fa-linkedin-in"> </a><a href="mailto:ay.boisvert@gmail.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link fa-solid fa-envelope"> </a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Alain Boisvert</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/cv">Curriculum vitæ</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/learning">Learning path</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/certificates">Certificates</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/courses">Courses</a><button aria-label="Collapse sidebar category &#x27;Courses&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/courses/gif-7005">GIF-7005 Introduction à l&#x27;apprentissage automatique</a><button aria-label="Collapse sidebar category &#x27;GIF-7005 Introduction à l&#x27;apprentissage automatique&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-01">Semaine 1 Introduction à l&#x27;apprentissage</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-02">Semaine 2 Méthodes paramétriques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-03">Semaine 3 Méthodes multivariées</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-04">Semaine 4 Méthodes non paramétriques</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-05">Semaine 5 Discriminants linéaires</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-06">Semaine 6 Méthodes à noyau</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-07">Semaine 7 Perceptron multicouche</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-08">Semaine 8 Apprentissage profond</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-10">Semaine 10 Réseau de neurones à convolution</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-11">Semaine 11 Méthodes par ensembles</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-12">Semaine 12 Prétraitements et analyse de données</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/week-13">Semaine 13 Clustering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-1">Devoir 1 du 4 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-2">Devoir 2 du 18 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-3">Devoir 3 du 8 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/courses/gif-7005/devoir-4">Devoir 4 du 22 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/devoir-5">Devoir 5 du 8 décembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-1">Quiz 1 du 27 septembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-2">Quiz 2 du 11 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-3">Quiz 3 du 25 octobre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/quiz-4">Quiz 4 du 15 novembre 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/examen-2022">Examen final 2022</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/examen-2019">Examen final 2019</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/examen-2018">Examen final 2018</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/examen-2017">Examen final 2017</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/examen-2016">Examen final 2016</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/gif-7005/projet">Projet</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/courses/ift-7022">IFT-7022 Traitement automatique de la langue naturelle</a><button aria-label="Expand sidebar category &#x27;IFT-7022 Traitement automatique de la langue naturelle&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chatgpt-building-systems">Building Systems with the ChatGPT API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chatgpt-prompt-engineering">ChatGPT Prompt Engineering for Developers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/docs/courses/fine-tuning-llms">Training and fine-tuning LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/langchain-1">LangChain for LLM Application Development</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/pair-prog-with-llm">Pair Programming with a Large Language Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/courses/chat-with-your-data">LangChain Chat with Your Data</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/references">References</a><button aria-label="Expand sidebar category &#x27;References&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/code-snippets">Code Snippets</a><button aria-label="Expand sidebar category &#x27;Code Snippets&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/courses"><span itemprop="name">Courses</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/courses/gif-7005"><span itemprop="name">GIF-7005 Introduction à l&#x27;apprentissage automatique</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Devoir 4 du 22 novembre 2023</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Devoir 4</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="d4q1---réseau-de-neurones-à-convolution">D4Q1 - Réseau de neurones à convolution<a href="#d4q1---réseau-de-neurones-à-convolution" class="hash-link" aria-label="Direct link to D4Q1 - Réseau de neurones à convolution" title="Direct link to D4Q1 - Réseau de neurones à convolution">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-préambule">Code préambule<a href="#code-préambule" class="hash-link" aria-label="Direct link to Code préambule" title="Direct link to Code préambule">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">!pip install torchvision</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">os.environ[&quot;OMP_NUM_THREADS&quot;] = &quot;1&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import gzip</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import time</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import numpy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from IPython import display</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn.functional as F</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.optim import SGD</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.utils.data import Dataset, DataLoader</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.datasets import ImageFolder</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.models import resnet18</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torchvision.transforms as T</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import matplotlib</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">matplotlib.rcParams[&#x27;figure.figsize&#x27;] = (9.0, 7.0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from matplotlib import pyplot</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">DEVICE = torch.device(&#x27;cuda&#x27;) if torch.cuda.is_available() else torch.device(&#x27;cpu&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Retirer ce code avant de soumettre.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">if torch.backends.mps.is_available():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;mps&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">elif torch.cuda.is_available():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;cuda&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">else:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;cpu&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def create_balanced_sampler(dataset):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def make_weights_for_balanced_classes(images, n_classes):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        count = [0] * n_classes</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        for item in images:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            count[item[1]] += 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        weight_per_class = [0.] * n_classes</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        N = float(sum(count))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        for i in range(n_classes):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            weight_per_class[i] = N/float(count[i])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        weight = [0] * len(images)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        for idx, val in enumerate(images):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            weight[idx] = weight_per_class[val[1]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return weight</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    n_classes = numpy.unique(dataset.targets)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    weights = make_weights_for_balanced_classes(dataset.data, len(n_classes))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    weights = torch.DoubleTensor(weights)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return sampler</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def compute_accuracy(model, dataloader, device=&#x27;cpu&#x27;):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    training_before = model.training</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    model.eval()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    all_predictions = []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    all_targets = []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for i_batch, batch in enumerate(dataloader):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images, targets = batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images = images.to(device)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets = targets.to(device)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        with torch.no_grad():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            predictions = model(images)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        all_predictions.append(predictions.cpu().numpy())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        all_targets.append(targets.cpu().numpy())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if all_predictions[0].shape[-1] &gt; 1:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy = numpy.concatenate(all_predictions, axis=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy = predictions_numpy.argmax(axis=1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets_numpy = numpy.concatenate(all_targets, axis=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy = numpy.concatenate(all_predictions).squeeze(-1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets_numpy = numpy.concatenate(all_targets)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy[predictions_numpy &gt;= 0.5] = 1.0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy[predictions_numpy &lt; 0.5] = 0.0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if training_before:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        model.train()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return (predictions_numpy == targets_numpy).mean()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Pour cette question, vous devez faire l&#x27;entraînement d&#x27;un réseau de neurones sur le jeu de données
<a href="https://www.kaggle.com/fmena14/volcanoesvenus/" target="_blank" rel="noopener noreferrer">Volcanoes on Venus</a>. Il s&#x27;agit d&#x27;un problème de classification pour
lequel nous vous fournissons une version abrégée du jeu de données
d&#x27;<a href="https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/volcanoes_train.pt.gz" target="_blank" rel="noopener noreferrer">entraînement</a>
et de <a href="https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/volcanoes_test.pt.gz" target="_blank" rel="noopener noreferrer">test</a> (attention: 120 Mo).</p>
<p>Pour vous mettre en contexte, voici une synthèse des trois étapes requises pour l&#x27;entraînement de votre modèle
dans un contexte de classification:</p>
<ul>
<li><strong>Gérer les données</strong>: La première étape est la gestion des données. Elle se fait en deux temps. En premier, il faut
définir une classe (dans le sens programmation orientée objet du terme) qui s&#x27;occupe des données. Elle permet de
contrôler le chargement et l&#x27;application des transformations. Chaque fois qu&#x27;une donnée (ici une image) est demandée
par le système, cette classe est appelée. Cette classe permet de faire une copie des images du disque dur vers la
mémoire vive de votre machine. Ce transfert est un moment propice pour appliquer les transformations, tout en réduisant
le temps de déplacement des données vers le GPU. Dans PyTorch, ceci est effectué par une classe dénommée <code>Dataset</code>.
Ensuite, il faut définir une classe, nommée <code>DataLoader</code> dans PyTorch, qui contrôle la façon dont les données sont
sélectionnées dans le jeu de données, car on doit pouvoir décider si on veut les piger aléatoirement ou dans un ordre
particulier. Elle permet alors de définir la méthode d&#x27;échantillonnage et la taille des lots (batch) que l&#x27;on souhaite
obtenir. Notez également que PyTorch fonctionne principalement avec des
<a href="https://fr.wikipedia.org/wiki/Tenseur" target="_blank" rel="noopener noreferrer">tenseurs</a> -- généralisation à plusieurs dimensions des matrices.</li>
<li><strong>Développer le modèle</strong>: La seconde étape est de définir le modèle de réseau de neurones que l&#x27;on souhaite utiliser.
Ce réseau peut être construit et personnalisé dans une classe PyTorch, que l&#x27;on nomme <code>VolcanoesNet</code> pour la question
courante. Elle permet de définir et d&#x27;initialiser les couches du réseau dans la fonction <code>init</code>. La fonction <code>forward</code>
permet de contrôler dans quel ordre se fera l&#x27;inférence sur les couches définies dans <code>init</code>. Elle permet aussi de
varier la forme du tenseur entre les couches, au besoin.</li>
<li><strong>Entraîner le modèle</strong>: La dernière étape est d&#x27;entraîner le modèle. Pour ce faire, vous devez développer les boucles
d&#x27;entraînement. On entraîne un modèle itératif, où une époque représente une boucle complète sur toutes les données
d&#x27;entraînement et une batch représente un lot de données utilisées pour une inférence, échantillonnées par le
<code>DataLoader</code>. Pour chaque batch, les opérations d&#x27;entraînement d&#x27;un réseau (remise à zéro des gradients, inférence,
calcul de la perte, rétropropagation) doivent être appliquées. La séparation du jeu de données en batch permet de ne
pas dépasser la capacité mémoire des GPUs, comme on traite chacune d&#x27;entre elles indépendamment. Pour chaque batch,
les données sont transférées de la mémoire vive du CPU vers le GPU (et inversement à la fin de la batch) pour appliquer
les opérations d&#x27;entraînement.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q1a">Q1A<a href="#q1a" class="hash-link" aria-label="Direct link to Q1A" title="Direct link to Q1A">​</a></h3>
<p>Pour commencer, vous vous familiarisez avec les données Volcanoes afin de pouvoir les manipuler dans l&#x27;entraînement. Pour
ce faire, définissez la classe <code>VolcanoesDataset</code>, qui hérite de la classe abstraite <code>torch.utils.data.Dataset</code>, et
surchargez les méthodes <code>__getitem__</code> et <code>__len__</code>, comme mentionné dans la documentation. Ceci doit résulter en un jeu
de données utilisable par PyTorch.</p>
<p>De plus, vous devez tester votre classe <code>VolcanoesDataset</code> en affichant quatre images choisies aléatoirement, dans une
figure unique. Indiquez la classe correspondante dans le titre de chacune des sous-figures. Également, vous devez
représenter la distribution des données par classe du jeu d&#x27;entraînement dans un histogramme.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">class VolcanoesDataset(Dataset):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Cette classe sert à définir le dataset Volcanoes pour PyTorch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    proposé de Francisco Mena sur kaggle : https://bit.ly/2DasPF1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        path (str): le chemin du fichier .pt du dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    This class is used to define the Volcanoes dataset for PyTorch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    proposed by Francisco Mena on kaggle : https://bit.ly/2DasPF1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        path (str): path to dataset .pt file</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, path):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # garde les paramètres en mémoire / store parameters in memory</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.path = path</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # charger les données / load data</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        with gzip.open(path, &#x27;rb&#x27;) as f:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            self.data = torch.load(f)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Pour faciliter la lecture des valeurs cibles / ease reading the targets</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.targets = numpy.array(list(zip(*self.data))[1])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __getitem__(self, index):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Fourni l&#x27;instance à un certain indice du jeu de données</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Provide an instance of the dataset according to the index</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        image, label = self.data[index]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return image, label</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __len__(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Fournis la taille du jeu de données</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Provide the lenght of the dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return len(self.data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creation du dataset / Creating the dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># train_set = VolcanoesDataset(&#x27;/pax/shared/GIF-4101-7005/volcanoes_train.pt.gz&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Retirer ce code avant soumission!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">DATA_FOLDER = &quot;/Users/alain/workspace/Volcanoes-on-venus&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">file_path = os.path.join(DATA_FOLDER, &#x27;volcanoes_train.pt.gz&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_set = VolcanoesDataset(file_path)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">fig, subfigs = pyplot.subplots(2, 2, tight_layout=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for subfig in subfigs.reshape(-1):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Affichage de quatre images aléatoires</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Displaying four random images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    index = numpy.random.randint(0, len(train_set))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    image, label = train_set[index]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    subfig.imshow(image.squeeze(), cmap=&#x27;gray&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    subfig.set_title(&#x27;Classe: {}&#x27;.format(label))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    subfig.axis(&#x27;off&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">fig, subfig = pyplot.subplots()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Tracer histogramme de la distribution des données par classe de train_set</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Plot class distribution histogram for train_set</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Calcul des fréquences pour chaque classe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">frequencies = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for _, label in train_set:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label = label.item()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if label not in frequencies:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        frequencies[label] = 0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    frequencies[label] += 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Tracer l&#x27;histogramme pour les classes 0 et 1.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">subfig.bar(frequencies.keys(), frequencies.values(), color=[&#x27;red&#x27;, &#x27;blue&#x27;], edgecolor=&#x27;black&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">subfig.set_title(&#x27;Distribution des classes dans le jeu d’entraînement&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">subfig.set_xticks([0, 1])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">subfig.set_xlabel(&#x27;Classe&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">subfig.set_ylabel(&#x27;Nombre d’images&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pyplot.show()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="output_7_0" src="/assets/images/output_7_0-8d6b5a5466e3e252c9454ea53a5638a1.png" width="731" height="690" class="img_ev3q"></p>
<p><img loading="lazy" alt="output_7_1" src="/assets/images/output_7_1-1ed9a432b7f8191e9a605e5b3b4396e3.png" width="781" height="625" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q1b">Q1B<a href="#q1b" class="hash-link" aria-label="Direct link to Q1B" title="Direct link to Q1B">​</a></h3>
<p>Vous devez maintenant créer le réseau de neurones et définir les méthodes ainsi que les attributs nécessaires pour
qu&#x27;il puisse être entraîné.</p>
<ul>
<li>Commencez par initialiser les couches de votre réseau dans la méthode <code>__init__</code> de <code>VolcanoesNet</code>, en utilisant</li>
<li>les couches de convolution (<code>Conv2D</code>), de normalisation (<code>BatchNorm2D</code>) et linéaire (<code>Linear</code>), selon l&#x27;architecture suivante.</li>
</ul>
<p><img loading="lazy" alt="Architecture" src="/assets/images/d4q1_volcanoes_net-eac7e16aa0204cea1cf1ef9f5915174a.png" width="885" height="171" class="img_ev3q"></p>
<p>L&#x27;architecture présentée dans l&#x27;image semble être un réseau de neurones convolutif (CNN) typique pour la classification
d&#x27;images. Voici une description de ses composants, de gauche à droite :</p>
<ol>
<li><strong>Inputs</strong>: Les données d&#x27;entrée qui seraient des images.</li>
<li><strong>Conv2d (kernel 5)</strong>: Une couche de convolution avec des filtres de taille 5x5. Le nombre de filtres n&#x27;est pas
précisé mais le nombre 32 à côté peut indiquer le nombre de canaux de sortie ou de filtres.</li>
<li><strong>BatchNorm</strong>: Normalisation par lots, utilisée pour normaliser les activations de la couche précédente, pour chaque lot.</li>
<li><strong>ReLU</strong>: La fonction d&#x27;activation ReLU (Rectified Linear Unit), qui ajoute de la non-linéarité au modèle.</li>
<li><strong>Conv2d (kernel 5)</strong>: Une autre couche de convolution avec des filtres de taille 5x5. Ici, 64 peut indiquer le nombre de canaux de sortie.</li>
<li><strong>BatchNorm</strong>: Une autre couche de normalisation par lots.</li>
<li><strong>ReLU</strong>: Une autre application de la fonction d&#x27;activation ReLU.</li>
<li><strong>Conv2d (kernel 3)</strong>: Une couche de convolution avec des filtres de taille 3x3, indiquant possiblement une extraction de caractéristiques plus fines.</li>
<li><strong>BatchNorm</strong>: Une troisième couche de normalisation par lots.</li>
<li><strong>ReLU</strong>: Une troisième application de la fonction d&#x27;activation ReLU.</li>
<li><strong>Conv2d (kernel 3)</strong>: Encore une couche de convolution avec des filtres de taille 3x3.</li>
<li><strong>BatchNorm</strong>: Normalisation par lots.</li>
<li><strong>ReLU</strong>: Fonction d&#x27;activation ReLU.</li>
<li><strong>Average Pooling</strong>: Une couche de pooling moyen qui réduit la dimension spatiale des caractéristiques en calculant la moyenne des valeurs dans chaque fenêtre de pooling.</li>
<li><strong>Linear</strong>: Une couche linéaire ou complètement connectée qui est généralement utilisée pour la classification.</li>
<li><strong>Sigmoid</strong>: La fonction d&#x27;activation sigmoïde qui est souvent utilisée pour la classification binaire.</li>
</ol>
<p>Chaque couche de convolution est suivie d&#x27;une normalisation par lots et d&#x27;une fonction d&#x27;activation ReLU, ce qui est
une pratique courante pour améliorer la convergence pendant l&#x27;entraînement et ajouter de la non-linéarité. L&#x27;architecture
se termine par une couche de pooling moyen pour réduire la dimensionnalité suivie d&#x27;une couche linéaire pour la
classification, et une fonction d&#x27;activation sigmoïde qui est typique pour les problèmes de classification binaire où
l&#x27;output est la probabilité d&#x27;appartenir à la classe 1.</p>
<ul>
<li>Pour les convolutions, vous devez respecter le nombre de filtres (<em>filters</em>) et la taille des noyaux (<em>kernels</em>) de
convolution. Vous devez aussi, et ce pour toutes les convolutions, spécifier un pas (<em>stride</em>) de 2. Aussi, vous devez
retirer le biais de la convolution si cette dernière est suivie d&#x27;une couche de normalisation, car elle contient déjà
un paramètre pour le biais.</li>
<li>Écrivez les lignes de code manquantes pour définir l&#x27;ordre d&#x27;inférence des couches dans le réseau dans la
méthode <code>forward</code> de <code>VolcanoesNet</code>. Les modules <code>average_pooling</code>, <code>linear</code> et <code>sigmoid</code> sont déjà implémentées
dans la librairie PyTorch.</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">class VolcanoesNet(nn.Module):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Cette classe définit un réseau pleinement convolutionnel simple</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    permettant de classifier des images satellite de Venus.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    This class defines a simple fully convolutional network</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    to classify satellite images from Venus.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Initialiser ici les modules contenant des paramètres à optimiser.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Ces modules seront utilisés dans la méthode &#x27;forward&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=2, padding=2, bias=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.bn1 = nn.BatchNorm2d(32)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.relu = nn.ReLU()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=2, bias=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.bn2 = nn.BatchNorm2d(64)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.bn3 = nn.BatchNorm2d(64)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, bias=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.bn4 = nn.BatchNorm2d(64)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.fc = nn.Linear(64, 1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.sigmoid = nn.Sigmoid()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Effectuer l&#x27;inférence du réseau. L&#x27;ordre d&#x27;exécution est importante.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Perform network inference. The order of execution is important.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.relu(self.bn1(self.conv1(x)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.relu(self.bn2(self.conv2(x)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.relu(self.bn3(self.conv3(x)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.relu(self.bn4(self.conv4(x)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.avgpool(x)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = x.view(x.size(0), -1)  # Le tenseur est aplati pour le connecter à la couche linéaire.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.fc(x)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = self.sigmoid(x)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return x</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q1c">Q1C<a href="#q1c" class="hash-link" aria-label="Direct link to Q1C" title="Direct link to Q1C">​</a></h3>
<p>Il faut maintenant développer les outils nécessaires pour effectuer l&#x27;entraînement du réseau de neurones, selon le code
que vous avez développé aux sous-questions précédentes. L&#x27;entraînement est défini par une boucle qui itère sur l&#x27;ensemble
des données d&#x27;entraînement, chaque itération correspondant à une époque. Pour chaque époque, il faut itérer sur tous
les lots (batch) qu&#x27;elle contient.</p>
<p>Pour cette question, vous devez:</p>
<ul>
<li>Écrire le code manquant pour la préparation de l&#x27;entraînement.</li>
<li>Écrire le code manquant à l&#x27;intérieur de la boucle d&#x27;entraînement.</li>
<li>Écrire le code manquant à l&#x27;intérieur de la fonction de calcul de l&#x27;erreur et des matrices de confusion.</li>
</ul>
<p>La matrice de confusion est particulièrement utile pour visualiser les performances de votre réseau. On assigne la
donnée à la première classe 0 lorsque la probabilité en sortie est plus petite que 0,5, sinon la données est assignée à la deuxième classe.</p>
<p>Également, discutez brièvement les performances du réseau selon la matrice de confusion obtenue.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Initialisation des paramètres d&#x27;entraînement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Paramètres recommandés:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Nombre d&#x27;epochs (nb_epoch = 10)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Taux d&#x27;apprentissage (learning_rate = 0.01)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Momentum (momentum = 0.9)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Taille du lot (batch_size = 32)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Initialization of training parameters</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Recommended parameters:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Number of epochs (nb_epoch = 10)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Learning rate (learning_rate = 0.01)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Momentum (momentum = 0.9)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># - Batch size (batch_size = 32)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">nb_epoch = 10</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">learning_rate = 0.01</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">momentum = 0.9</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">batch_size = 32</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Chargement des données d&#x27;entraînement et de test</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Loading training and testing set</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># train_set = VolcanoesDataset(&#x27;/pax/shared/GIF-4101-7005/volcanoes_train.pt.gz&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># test_set = VolcanoesDataset(&#x27;/pax/shared/GIF-4101-7005/volcanoes_test.pt.gz&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Retirer ce code avant soumission!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">DATA_FOLDER = &quot;/Users/alain/workspace/Volcanoes-on-venus&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_path = os.path.join(DATA_FOLDER, &#x27;volcanoes_train.pt.gz&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">test_path = os.path.join(DATA_FOLDER, &#x27;volcanoes_test.pt.gz&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_set = VolcanoesDataset(train_path)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">test_set = VolcanoesDataset(test_path)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Création du sampler avec les classes balancées</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Create the sampler with balanced classes</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">balanced_train_sampler = create_balanced_sampler(train_set)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">balanced_test_sampler = create_balanced_sampler(test_set)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Création du dataloader d&#x27;entraînement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Create training dataloader</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train_loader = DataLoader(train_set, batch_size=batch_size, sampler=balanced_train_sampler)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">test_loader = DataLoader(test_set, batch_size=batch_size, sampler=balanced_test_sampler)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def compute_confusion_matrix(model, dataloader, device):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Mettre le model en mode évaluation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    model.eval()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Calculer toutes les prédictions sur le dataloader</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Put the model in evaluation mode</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Compute all predictions on the dataloader</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    all_predictions = []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    all_targets = []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for i_batch, batch in enumerate(dataloader):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images, targets = batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images = images.to(device)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets = targets.to(device)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        with torch.no_grad():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            predictions = model(images)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        all_predictions.append(predictions.cpu().numpy())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        all_targets.append(targets.cpu().numpy())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    predictions_numpy = numpy.concatenate(all_predictions).squeeze()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    targets_numpy = numpy.concatenate(all_targets).squeeze()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Assigner la classe 0 ou 1 aux prédictions</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Calculer la matrice de confusion. Attention de bien avoir</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # une matrice 2 par 2 en sortie</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    #</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Assign class 0 or 1 to the predictions</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Compute the confusion matrix. Be careful to have</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # a 2 by 2 matrix as output.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    predictions_numpy = (predictions_numpy &gt;= 0.5).astype(int)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    matrix = numpy.zeros((2, 2), dtype=int)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for true_label, predicted_label in zip(targets_numpy, predictions_numpy):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        matrix[int(true_label), predicted_label] += 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return matrix  # Retourner matrice de confusion / return confusion matrix</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Instancier votre réseau VolcanoesNet dans une variable nommée &quot;model&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Instantiate your VolcanoesNet network in a variable named &quot;model&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model = VolcanoesNet()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Transférer le réseau sur GPU ou CPU en fonction de la variable &quot;DEVICE&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Transfer the network to GPU or CPU depending on the &quot;DEVICE&quot; variable</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Instancier une fonction d&#x27;erreur BinaryCrossEntropy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># et la mettre dans une variable nommée criterion</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Instantiate an error function BinaryCrossEntropy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># and put it in a variable named criterion</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">criterion = nn.BCELoss()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Instancier l&#x27;algorithme d&#x27;optimisation SGD</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Ne pas oublier de lui donner les hyperparamètres</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># d&#x27;entraînement : learning rate et momentum!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Instantiate the SGD optimization algorithm</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Don&#x27;t forget to give it the training hyperparameters:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># learning rate and momentum!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Mettre le réseau en mode entraînement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Set the network in training mode</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">model.train()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Boucle d&#x27;entraînement / Training loop</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for i_epoch in range(nb_epoch):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    start_time, train_losses = time.time(), []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for i_batch, batch in enumerate(train_loader):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images, targets = batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets = targets.type(torch.FloatTensor).unsqueeze(-1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images = images.to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets = targets.to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Mettre les gradients à zéro</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Set gradients to zero</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        optimizer.zero_grad()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Calculer:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # 1. l&#x27;inférence dans une variable &quot;predictions&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # 2. l&#x27;erreur dans une variable &quot;loss&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Compute:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # 1. the inference in a &quot;predictions&quot; variable</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # 2. the error in a &quot;loss&quot; variable</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions = model(images)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        loss = criterion(predictions, targets)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Rétropropager l&#x27;erreur et effectuer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # une étape d&#x27;optimisation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Backpropagate the error and perform</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # an optimization step</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        loss.backward()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        optimizer.step()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Accumulation du loss de la batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Accumulating batch loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        train_losses.append(loss.item())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&#x27; [-] epoch {:4}/{:}, train loss {:.6f} in {:.2f}s&#x27;.format(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        i_epoch+1, nb_epoch, numpy.mean(train_losses), time.time()-start_time))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Affichage du score en test / Display test score</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">test_acc = compute_accuracy(model, test_loader, DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&#x27; [-] test acc. {:.6f}%&#x27;.format(test_acc * 100))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Affichage de la matrice de confusion / Display confusion matrix</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">matrix = compute_confusion_matrix(model, test_loader, DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(matrix)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Libère la cache sur le GPU *important sur un cluster de GPU*</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Free GPU cache *important on a GPU cluster*</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.cuda.empty_cache()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Entrez vos commentaires de la discussion ici.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Enter your discussion comments here</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">discussion = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Remarquons que les performances obtenues varient légèrement d&#x27;une exécution à l&#x27;autre.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Mes commentaires ci-dessous reposent sur les performances obtenues suivantes...</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">frame = {&quot;Comments&quot;:[discussion]}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">df = pandas.DataFrame(frame)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">display.display(df)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Entrez vos commentaires de la discussion ici.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Enter your discussion comments here</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">discussion = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">D&#x27;abord, remarquons que les performances obtenues varient légèrement d&#x27;une exécution à l&#x27;autre.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Mes commentaires ci-dessous reposent sur les performances obtenues suivantes:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Test acc. 69.265545%, VN=1266, FP=18, FN=1056, VP=394.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **VP=394** : Le modèle a correctement identifié 394 cas où un volcan est présent (classe réelle = 1,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  classe prédite = 1).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **FP=18** : Le modèle a incorrectement identifié 18 cas comme présentant un volcan alors qu&#x27;en réalité,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  il n&#x27;y en avait pas (classe réelle = 0, classe prédite = 1).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **FN=1056** : Le modèle a manqué 1056 cas où un volcan était présent, les identifiant à tort comme</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  ne contenant pas de volcan (classe réelle = 1, classe prédite = 0).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  Le modèle a tendance à sous-estimer la présence de volcans.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **VN=1266** : Le modèle a correctement identifié 1266 cas où aucun volcan n&#x27;était présent (classe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  réelle = 0, classe prédite = 0).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Le modèle est assez fiable pour identifier les cas sans volcan.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **Précision** : Le modèle semble avoir une bonne précision (=VP/(VP+FP)=394/(394+18)=0.96), car il</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  y a un faible nombre de faux positifs (18).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Cela indique que, lorsque le modèle prédit la présence de volcan, il est généralement correct.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **Rappel** : Par contre, le rappel est problématique (=VP/(VP+FN)=394/(394+1056)=0.27), considérant</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  le nombre élevé de faux négatifs (1056).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  Le modèle ne détecte pas beaucoup de volcans qui sont effectivement présents.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **Exactitude (Accuracy)** : L&#x27;exactitude globale du modèle est de 61.27%, ce qui peut sembler correct,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">mais ce chiffre est influencé par le nombre élevé de faux négatifs.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- **Conclusion** : Un grand nombre de faux négatifs peut indiquer que le modèle est biaisé en faveur de</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">la classe la plus représentée. Ce qui est effectivement le cas comme le montre l&#x27;histogramme produit précédemment.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">frame = {&quot;Comments&quot;:[discussion]}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">df = pandas.DataFrame(frame)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">display.display(df)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="d4q2---transfert-de-représentation">D4Q2 - Transfert de représentation<a href="#d4q2---transfert-de-représentation" class="hash-link" aria-label="Direct link to D4Q2 - Transfert de représentation" title="Direct link to D4Q2 - Transfert de représentation">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-préambule-d4q2">Code préambule (D4Q2)<a href="#code-préambule-d4q2" class="hash-link" aria-label="Direct link to Code préambule (D4Q2)" title="Direct link to Code préambule (D4Q2)">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">os.environ[&quot;OMP_NUM_THREADS&quot;] = &quot;1&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import gzip</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import time</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import numpy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn.functional as F</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.optim import SGD</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.utils.data import Dataset, DataLoader</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.datasets import ImageFolder</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.models import resnet18</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torchvision.transforms as T</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from tqdm import tqdm</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import matplotlib</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">matplotlib.rcParams[&#x27;figure.figsize&#x27;] = (9.0, 7.0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from matplotlib import pyplot</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">DEVICE = torch.device(&#x27;cuda&#x27;) if torch.cuda.is_available() else torch.device(&#x27;cpu&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Retirer ce code avant de soumettre.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">if torch.backends.mps.is_available():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;mps&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">elif torch.cuda.is_available():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;cuda&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">else:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;cpu&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def compute_accuracy(model, dataloader, device=&#x27;cpu&#x27;):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    training_before = model.training</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    model.eval()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    all_predictions = []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    all_targets = []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for i_batch, batch in enumerate(dataloader):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images, targets = batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        images = images.to(device)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets = targets.to(device)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        with torch.no_grad():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            predictions = model(images)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        all_predictions.append(predictions.cpu().numpy())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        all_targets.append(targets.cpu().numpy())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if all_predictions[0].shape[-1] &gt; 1:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy = numpy.concatenate(all_predictions, axis=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy = predictions_numpy.argmax(axis=1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets_numpy = numpy.concatenate(all_targets, axis=0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy = numpy.concatenate(all_predictions).squeeze(-1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        targets_numpy = numpy.concatenate(all_targets)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy[predictions_numpy &gt;= 0.5] = 1.0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        predictions_numpy[predictions_numpy &lt; 0.5] = 0.0</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if training_before:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        model.train()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return (predictions_numpy == targets_numpy).mean()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Pour cette question, vous devez programmer un cas de transfert de représentation permettant de réutiliser un réseau
existant. Un réseau <em>ResNet-18</em> préalablement entraîné sur le jeu d&#x27;images naturelles <em>ImageNet</em> est utilisé comme modèle
source. Ce réseau a été préentraîné sur un jeu de données différent, mais de même nature, soit pour de la reconnaissance
d&#x27;objets. L&#x27;adaptation du réseau original pour la nouvelle tâche s&#x27;effectue en remplaçant la tête du réseau
(couche de sortie) pour que le réseau puisse fonctionner sur le jeu de données
<a href="https://www.kaggle.com/joosthazelzet/lego-brick-images" target="_blank" rel="noopener noreferrer">Lego Brick</a>, séparé en un ensemble
d&#x27;<a href="https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-train.zip" target="_blank" rel="noopener noreferrer">entraînement</a> et
de <a href="https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-test.zip" target="_blank" rel="noopener noreferrer">test</a> (attention: 190 Mo au total, les
fichiers sont directement disponibles sur PAX). Vous devriez être en mesure d&#x27;atteindre de très bonnes performances
sur ce jeu en seulement une époque d&#x27;entraînement.</p>
<p>En bref, vous devez modifier la dernière couche pleinement connectée du réseau de neurones (couche <code>fc</code>) afin de
l&#x27;adapter au nombre de classes du jeu de données (16 classes ici). De plus, vous devez geler les autres couches du
réseau <em>ResNet-18</em> se trouvant avant la nouvelle couche pleinement connectée de sortie. Écrivez également la ligne
de code nécessaire à l&#x27;inférence du réseau dans la méthode <code>forward</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q2a">Q2A<a href="#q2a" class="hash-link" aria-label="Direct link to Q2A" title="Direct link to Q2A">​</a></h3>
<p>Changez la dernière couche pleinement connectée du réseau de neurones (couche <code>fc</code>) afin de l&#x27;adapter au nombre de
classes du jeu de données (16 classes ici). De plus, gelez les autres couches du réseau <em>ResNet-18</em> se trouvant
avant la nouvelle couche pleinement connectée de sortie. Écrivez également la ligne de code nécessaire à l&#x27;inférence
du réseau dans la méthode <code>forward</code>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">class LegoNet(nn.Module):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, pretrained=False):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        super().__init__()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Crée le réseau de neurone pré-entraîné</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Create the pretrained neural network</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.model = resnet18(pretrained=pretrained, progress=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Récupère le nombre de neurones avant la couche de classement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Get the number of features before the classification layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        dim_before_fc = self.model.fc.in_features</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Changer la dernière couche pleinement connecté pour avoir le bon</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # nombre de neurones de sortie</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Change the last fully connected layer to have the right</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # number of output neurons</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.model.fc = nn.Linear(dim_before_fc, 16)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        if pretrained:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Geler les paramètres qui ne font pas partie de la dernière couche fc</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Conseil: utiliser l&#x27;itérateur named_parameters() et la variable requires_grad</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Freeze parameters that are not part of the last fc layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Tip: use named_parameters() iterator and requires_grad variable</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            for name, parameter in self.model.named_parameters():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                if name not in [&#x27;fc.weight&#x27;, &#x27;fc.bias&#x27;]:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                    parameter.requires_grad = False</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def forward(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Appeler la fonction forward du réseau préentraîné (resnet18) de LegoNet</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Call the forward function of the pre-trained network (resnet18) of LegoNet</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return self.model(x)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q2b">Q2B<a href="#q2b" class="hash-link" aria-label="Direct link to Q2B" title="Direct link to Q2B">​</a></h3>
<p>Écrivez les lignes de code manquantes pour la préparation de l&#x27;entraînement et celles à l&#x27;intérieur de la
boucle d&#x27;entraînement selon deux modes:</p>
<ol>
<li>Entraîner le réseau en exécutant le code <strong>sans</strong> préentraînement, le réseau devrait être entraîné en moins de 30 minutes sur CPU (et quelques minutes sur GPU).</li>
<li>Entraîner le réseau en exécutant le code <strong>avec</strong> préentraînement (<em>fine tuning</em>).</li>
</ol>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">def train(pretrained: bool):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Définit les paramètres d&#x27;entraînement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Nous vous conseillons ces paramètres, mais vous pouvez les changer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Defines the training parameters</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # We recommend these settings, but you can change them</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    nb_epoch = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    learning_rate = 0.01</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    momentum = 0.9</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    batch_size = 64</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Définit les transformations nécessaires pour le chargement du jeu de données</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Defines the transformations needed to load the dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    totensor = T.ToTensor()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    normalize = T.Normalize(mean=[0.485, 0.456, 0.406],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                            std=[0.229, 0.224, 0.225])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    composition = T.Compose([totensor, normalize])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Charge le dataset d&#x27;entraînement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Load the training dataset</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # train_set = ImageFolder(&#x27;/pax/shared/GIF-4101-7005/lego-train&#x27;, transform=composition)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Selectionne 10% du jeu de test aléatoirement pour alléger le calcul</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Select 10% of the test set randomly to simplify the calculation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # test_set = ImageFolder(&#x27;/pax/shared/GIF-4101-7005/lego-test&#x27;, transform=composition)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    train_set = ImageFolder(&quot;/Users/alain/workspace/lego-brick-images/lego-train&quot;, transform=composition)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    test_set = ImageFolder(&quot;/Users/alain/workspace/lego-brick-images/lego-test&quot;, transform=composition)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    idx = numpy.random.randint(0, len(test_set), int(0.1 * len(test_set)))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    test_set.samples = [test_set.samples[i] for i in idx]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Créer les dataloader PyTorch avec la classe DataLoader</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Create PyTorch dataloaders with the DataLoader class</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Instancier un réseau LegoNet dans une variable nommée &quot;model&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Instantiate a LegoNet network in a variable named &quot;model</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    model = LegoNet(pretrained=pretrained)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Place le réseau au bon endroit, variable DEVICE définit si cuda est utilisé ou non</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Places the network in the right place, variable DEVICE defines if cuda is used or not</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    model.to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Instancier une fonction d&#x27;erreur CrossEntropyLoss et</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # la mettre dans une variable nommée criterion</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Instantiate a CrossEntropyLoss error function and</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # put it in a variable named criterion</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    criterion = nn.CrossEntropyLoss()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Instancier l&#x27;algorithme d&#x27;optimisation SGD</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Conseil: Filtrez les paramètres non-gelés!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Ne pas oublier de lui donner les hyperparamètres d&#x27;entraînement :</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # learning rate et momentum!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Instantiate the SGD optimization algorithm</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Tip: Filter out unfrozen parameters!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Don&#x27;t forget to give it the training hyperparameters :</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # learning rate and momentum!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if pretrained:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Si le modèle est préentrainé, optimiser que la dernière couche `fc`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        optimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, momentum=momentum)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Si le modèle n&#x27;est pas préentrainé, optimiser tous les paramètres.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        optimizer = SGD(model.parameters(), lr=learning_rate, momentum=momentum)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Mettre le réseau en mode entraînement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Set the network in training mode</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    model.train()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Récupère le nombre total de batch pour une époque</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Retrieves the total number of batches for an epoch.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    total_batch = len(train_loader)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for i_epoch in tqdm(range(nb_epoch)):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        progress_dataloader = tqdm(train_loader, desc=&quot;Epoch {}/{}&quot;.format(i_epoch+1, nb_epoch))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        progress_dataloader.set_description(&quot;Epoch {}/{}&quot;.format(i_epoch+1, nb_epoch))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        train_losses = []</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        for batch in progress_dataloader:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            images, targets = batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            images = images.to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            targets = targets.to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Mettre les gradients à zéro</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Set gradients to zero</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            optimizer.zero_grad()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Calculer:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # 1. l&#x27;inférence dans une variable &quot;predictions&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # 2. l&#x27;erreur dans une variable &quot;loss&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Compute:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # 1. the inference in a &quot;predictions&quot; variable</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # 2. the error in a &quot;loss&quot; variable</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            predictions = model(images)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            loss = criterion(predictions, targets)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Rétropropager l&#x27;erreur et effectuer une étape d&#x27;optimisation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Backpropagate the error and perform an optimization step</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            loss.backward()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            optimizer.step()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Ajoute le loss de la batch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            # Adds the batch loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            train_losses.append(loss.item())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Affiche le score à l&#x27;écran</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Display score</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    test_acc = compute_accuracy(model, test_loader, DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if pretrained:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        print(&#x27; [-] pretrained test acc. {:.6f}%&#x27;.format(test_acc * 100))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        print(&#x27; [-] not pretrained test acc. {:.6f}%&#x27;.format(test_acc * 100))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Libère la cache sur le GPU : *Important sur un cluster de GPU*</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Free the cache on the GPU: *Important on a GPU cluster*</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.cuda.empty_cache()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train(False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">train(True)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="d4q3---transfert-de-style">D4Q3 - Transfert de style<a href="#d4q3---transfert-de-style" class="hash-link" aria-label="Direct link to D4Q3 - Transfert de style" title="Direct link to D4Q3 - Transfert de style">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-préambule-d4q3">Code préambule (D4Q3)<a href="#code-préambule-d4q3" class="hash-link" aria-label="Direct link to Code préambule (D4Q3)" title="Direct link to Code préambule (D4Q3)">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">os.environ[&quot;OMP_NUM_THREADS&quot;] = &quot;1&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import numpy</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import requests</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import time</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pandas.set_option(&#x27;display.max_colwidth&#x27;, 0)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from IPython import display</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import matplotlib.pyplot as plt</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from io import BytesIO</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch.autograd import Variable</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn as nn</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch.nn.functional as F</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torch import optim</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torchvision</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torchvision.models as models</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision import transforms</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from tqdm import tqdm</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from PIL import Image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Constantes / Constants</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">IMG_SIZE = 256</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">IMAGENET_MEAN = [0.485, 0.456, 0.406] # Moyenne pour chaque canal de couleur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">IMAGENET_STD = [0.229, 0.224, 0.225]  # Std pour chaque canal de couleur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">STYLE_IMAGE = &#x27;style_image&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">CONTENT_IMAGE = &#x27;content_image&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">DEVICE = torch.device(&#x27;cuda&#x27;) if torch.cuda.is_available() else torch.device(&#x27;cpu&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Retirer ce code avant de soumettre.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">if torch.backends.mps.is_available():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;mps&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">elif torch.cuda.is_available():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;cuda&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">else:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    DEVICE = torch.device(&#x27;cpu&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Variables</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">results = {&#x27;Name&#x27;:[],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           &#x27;Shape&#x27;:[],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           &#x27;Mean&#x27;:[],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">           &#x27;Std&#x27;:[],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">          }</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def fetch_image(file_id):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Cette fonction télécharge une image que vous partagez de votre Google Drive.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Elle retourne l&#x27;image dans un format PIL.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    This function downloads an image you share from your Google Drive.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    It returns the image in a PIL format.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    URL = &quot;https://drive.google.com/uc?&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    session = requests.Session()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    r = session.get(URL, params = { &#x27;id&#x27; : file_id, &#x27;alt&#x27; : &#x27;media&#x27;}, stream = True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    error_msg = f&#x27;ERROR: impossible to download the image (code={r.status_code})&#x27;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    assert(r.status_code == 200), error_msg</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    params = { &#x27;id&#x27; : file_id, &#x27;confirm&#x27; : &#x27;download_warning&#x27; }</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    r = session.get(URL, params = params, stream = True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    stream = BytesIO(r.content)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    image = Image.open(stream)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Gram matrix</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def gram_matrix(tensor):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Calcul de la matrice de Gram pour un tenseur donné</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Calculation of the Gram matrix for a given tensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Gram Matrix: https://en.wikipedia.org/wiki/Gramian_matrix</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Get the (B, C, H, W) of the Tensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    _, d, h, w = tensor.size()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Reshape tensor to multiply the features for each channel</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    tensor = tensor.view(d, h * w)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Calculate the Gram matrix</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    gram = torch.mm(tensor, tensor.t())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return gram</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def extract_features(image, model_features, layers=None):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Infère l&#x27;image dans le modèle et extrait les features pour</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    les couches désirées. Les couches par défaut concordent</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    avec celles du réseau VGG19 de Gatys et al. (2016).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Infers the image into the model and extracts the features for</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    the desired layers. The default layers are consistent with</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    those of the VGG19 network of Gatys et al. (2016).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if layers is None:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        layers = {&#x27;0&#x27;: &#x27;conv1_1&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;2&#x27;: &#x27;conv1_2&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;5&#x27;: &#x27;conv2_1&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;7&#x27;: &#x27;conv2_2&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;10&#x27;: &#x27;conv3_1&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;12&#x27;: &#x27;conv3_2&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;19&#x27;: &#x27;conv4_1&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;21&#x27;: &#x27;conv4_2&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;28&#x27;: &#x27;conv5_1&#x27;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                  &#x27;30&#x27;: &#x27;conv5_2&#x27;}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    features = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    x = image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for layer_idx, layer in enumerate(model_features):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        x = layer(x)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        if str(layer_idx) in layers:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            features[layers[str(layer_idx)]] = x</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return features</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>De manière générale, l&#x27;entraînement des réseaux de neurones en classement implique un entraînement où on observe la
performance selon sa fonction de perte que l&#x27;on souhaite minimiser en validation, afin d&#x27;obtenir un modèle qui généralise
bien. Le classement n&#x27;est pas le seul contexte d&#x27;apprentissage pour les réseaux de neurones, il existe plusieurs autres
utilisations de réseaux de neurones, notamment pour permettre la génération d&#x27;images. Le contexte de génération d&#x27;images
offre ainsi un retour visuel qui permet de donner une appréciation qualitative du fonctionnement du système. Si les
images générées semblent réelles, on peut présumer que le modèle fonctionne bien! L&#x27;exercice suivant a alors été conçu
pour vous permettre de mieux visualiser les performances, avec un retour visuel qui devrait être évocateur.</p>
<p>À l&#x27;aide de PyTorch, vous allez mettre en application ce qu&#x27;on appelle le <em>transfert de style</em>, qui est un problème qui
fait appel à la notion de transfert de représentation. À l&#x27;aide d&#x27;un réseau VGG19, on vous demande de suivre
l&#x27;implémentation d&#x27;un article de recherche
<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" target="_blank" rel="noopener noreferrer">Gatys et coll., 2016</a>
afin de générer une image artistique. En utilisant un modèle fourni préentraîné sur ImageNet, nous voulons extraire le
style d&#x27;une première image (à gauche) avec le réseau et l&#x27;appliquer sur le contenu d&#x27;une seconde image (à droite):</p>
<p><img loading="lazy" alt="content_style_mona.png" src="/assets/images/content_style_mona-30648514c4b43b17df671ce39ca9be2e.png" width="1672" height="1062" class="img_ev3q"></p>
<p>L&#x27;objectif est de créer une image hybride qui contient à la fois le style ainsi que le contenu de deux images. Il s&#x27;agit
d&#x27;un exercice plus visuel qui vous permettra d&#x27;améliorer votre intuition sur le fonctionnement d&#x27;un réseau de neurones
à convolution en vous basant sur l&#x27;information d&#x27;un article scientifique. Pour vous donner une idée du résultat, voici
l&#x27;image hybride générée à partir des images présentées plus haut:</p>
<p><img loading="lazy" alt="style_transfer_mona.gif" src="/assets/images/style_transfer_mona-62486c134f08db8e6f7a970aea0c48f9.gif" width="397" height="558" class="img_ev3q"></p>
<p>Le réseau de neurones à convolution VGG19 est composé de 2 groupes: les <em>features</em> et les couches de classification.
Le style correspond au résultat du passage des filtres de la couche de <em>features</em> sur l&#x27;image d&#x27;entrée, alors que le
contenu correspond aux valeurs des pixels de la deuxième image.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q3a">Q3A<a href="#q3a" class="hash-link" aria-label="Direct link to Q3A" title="Direct link to Q3A">​</a></h3>
<p>Le transfert de style ne demande que deux images comme jeu de données pour son application:</p>
<ul>
<li>Une image qui contient un style que vous souhaitez extraire (<code>style_image</code>);</li>
<li>Une image de contenu sur laquelle vous souhaitez appliquer le style (<code>content_image</code>).</li>
</ul>
<p>L&#x27;objectif du réseau est d&#x27;optimiser les pixels de l&#x27;image hybride en pondérant le style et le contenu des images
sources. Il est à noter que le réseau utilisé, VGG19, doit préalablement être entraîné sur un très grand nombre de
données. Toutefois, puisqu&#x27;on utilise un réseau préentraîné, vous n&#x27;avez pas besoin de toutes ces images pour son entraînement.</p>
<p>La première étape du problème est de télécharger vos images de style et de contenu. Avec l&#x27;aide de la fonction
<code>fetch_image</code>, vous pouvez télécharger vos propres images à partir de votre Google Drive. Pour se faire, téléversez
une image de style ainsi qu&#x27;une image de contenu sur votre Google Drive et partagez-les publiquement en créant un
lien URL de partage. Le lien aura la forme suivante:</p>
<p><code>https://drive.google.com/file/d/&lt;FILE_ID&gt;/view?usp=sharing</code></p>
<p>Copiez-collez le <code>&lt;FILE_ID&gt;</code> et passez-le comme chaîne de caractères en entrée de la fonction <code>fetch_image(&#x27;&lt;FILE_ID&gt;&#x27;)</code>
pour télécharger votre image dans le notebook.</p>
<p>Quelques exemples d&#x27;images de contenu:</p>
<ul>
<li><a href="https://drive.google.com/file/d/11c650QrD0vP7le1EHiZ5nkjRuoUYmF6H/view?usp=sharing" target="_blank" rel="noopener noreferrer">Great Sea Turtle</a> (<code>&lt;FILE_ID&gt; : 11c650QrD0vP7le1EHiZ5nkjRuoUYmF6H</code>)</li>
<li><a href="https://drive.google.com/file/d/11ec7XKIPQXVq6jq0Swq96abJ3t4r6JQV/view?usp=sharing" target="_blank" rel="noopener noreferrer">Tuebingen</a> (<code>&lt;FILE_ID&gt; : 11ec7XKIPQXVq6jq0Swq96abJ3t4r6JQV</code>)</li>
<li><a href="https://drive.google.com/file/d/11hj6wRTK3LvfNH1H2eGZCRAFA_h-f3Ag/view?usp=sharing" target="_blank" rel="noopener noreferrer">Grace Hopper</a> (<code>&lt;FILE_ID&gt; : 11hj6wRTK3LvfNH1H2eGZCRAFA_h-f3Ag</code>)</li>
</ul>
<p>Quelques exemples d&#x27;images de style:</p>
<ul>
<li><a href="https://drive.google.com/file/d/11lRkyOtVCSZFrYT5r44y1rYXlywOmdaU/view?usp=sharing" target="_blank" rel="noopener noreferrer">The Great Wave off Kanagawa</a> (<code>&lt;FILE_ID&gt; : 11lRkyOtVCSZFrYT5r44y1rYXlywOmdaU</code>)</li>
<li><a href="https://drive.google.com/file/d/11utiecLh-3JQspwfOVHowkoWOHsD4Zx5/view?usp=sharing" target="_blank" rel="noopener noreferrer">Kadinsky</a> (<code>&lt;FILE_ID&gt; : 11utiecLh-3JQspwfOVHowkoWOHsD4Zx5</code>)</li>
<li><a href="https://drive.google.com/file/d/11vgRvxUxwh8Q5uwaD8O9aYKO7yucm57A/view?usp=sharing" target="_blank" rel="noopener noreferrer">Van Gogh</a> (<code>&lt;FILE_ID&gt; : 11vgRvxUxwh8Q5uwaD8O9aYKO7yucm57A</code>)</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Avec la fonction fetch_image, téléchargez vos propres images.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Pour se faire, ajoutez vos images sur votre Google Drive en les</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># téléversant et partagez-les avec un lien URL. Dans ce lien,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># vous retrouverez le &lt;FILE_ID&gt; qu&#x27;il faut copier-coller dans la</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># fonction fetch_image.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Exemple: https://drive.google.com/file/d/&lt;FILE_ID&gt;/view?usp=sharing</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># With the fetch_image function, upload your own images.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># To do so, add your images to your Google Drive by</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># uploading them and share them with a URL link. In this link,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># you will find the &lt;FILE_ID&gt; that you need to copy and paste into the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># function fetch_image.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Example: https://drive.google.com/file/d/&lt;FILE_ID&gt;/view?usp=sharing</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Télécharger une image contenant le style à extraire</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Download an image containing the style to extract</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">style_image_file_id = &quot;1zrY2R7tniKzX4XXgg9IxWb-9-sGtm5Sl&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">style_image = fetch_image(style_image_file_id)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO **</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Télécharger une image sur laquelle appliquer le style</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Download an image on which to apply the style</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">content_image_file_id = &quot;1PqHZ1Qu0zjHYDqqJmpBdyhFiZhiTT84m&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">content_image = fetch_image(content_image_file_id)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">images = {STYLE_IMAGE:style_image,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">          CONTENT_IMAGE:content_image}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Afficher les 2 images côte-à-côte</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Display the 2 images side by side</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">plt.figure(figsize=(15,15))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Affichage du style_image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Displaying the image_style</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">plt.subplot(1, 2, 1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">plt.imshow(images[STYLE_IMAGE])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Affichage du content_image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Displaying the content_image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">plt.subplot(1, 2, 2)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">plt.imshow(images[CONTENT_IMAGE])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="output_28_1" src="/assets/images/output_28_1-89203f1539b89dd5e73d1617cc9bbe56.png" width="1232" height="577" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q3b">Q3B<a href="#q3b" class="hash-link" aria-label="Direct link to Q3B" title="Direct link to Q3B">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="prétraitement">Prétraitement<a href="#prétraitement" class="hash-link" aria-label="Direct link to Prétraitement" title="Direct link to Prétraitement">​</a></h4>
<p>Le prétraitement des images est nécessaire pour s&#x27;assurer que celles-ci aient les mêmes caractéristiques (taille,
intensité moyenne, etc.) que celles des images utilisées pour l&#x27;entraînement. Il est également utilisé pour faire de
l&#x27;augmentation de jeu de données, en ajoutant de la diversité dans le jeu d&#x27;entraînement pour augmenter le nombre
d&#x27;images disponibles. Dans le cas du transfert de style, on l&#x27;utilise pour que les images respectent la même distribution
que pour l&#x27;entraînement du réseau VGG19 utilisé.</p>
<p>Puisqu&#x27;un réseau préentraîné est utilisé pour le transfert de style, il est important d&#x27;appliquer les mêmes paramètres
de normalisation que ceux utilisés pour l&#x27;entraînement. Le CNN ayant été entraîné sur ImageNet, on applique les mêmes
paramètres que dans la <a href="https://pytorch.org/vision/stable/models.html" target="_blank" rel="noopener noreferrer">documentation</a>. Il est à noter que ces paramètres
représentent la moyenne et la déviation standard pour chaque canal de l&#x27;image. Une image standard de type RGB dispose de
3 canaux (Red, Green, Blue).</p>
<ul>
<li>ImageNet_mean = [0.485, 0.456, 0.406]</li>
<li>ImageNet_std = [0.229, 0.224, 0.225]</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="post-traitement">Post-traitement<a href="#post-traitement" class="hash-link" aria-label="Direct link to Post-traitement" title="Direct link to Post-traitement">​</a></h4>
<p>Le post-traitement est nécessaire pour s&#x27;assurer que les images qui sont générées par le réseau de neurones respectent
les propriétés naturelles d&#x27;une image réelle pour pouvoir être affichées avec Matplotlib. Une image standard de type
RGB contient trois canaux de couleurs qui sont composés de pixels. L&#x27;intensité de la couleur de chacun des pixels se
trouve dans une plage [0,1]. Toutefois, rien ne garantit que les pixels inférés par le réseau de neurones respecteront
cette plage. En effet, comme le réseau VGG19 fait usage de la fonction d&#x27;activation sigmoïde, les pixels en sortie sont
contenus entre [-1,1] et doivent donc être ramenés entre [0,1]. Il va de même pour la normalisation. Comme le réseau
VGG19 a été préentraîné sur ImageNet avec des paramètres de normalisation spécifique à ce jeu de données, on normalise
les images de style et de contenu de la même manière en prétraitement. Toutefois, afin d&#x27;afficher l&#x27;image hybride, il
est important de renverser la normalisation pour obtenir un résultat visuellement intéressant.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="objectif">Objectif<a href="#objectif" class="hash-link" aria-label="Direct link to Objectif" title="Direct link to Objectif">​</a></h4>
<p>À partir du patron de prétraitement qui vous est donné et de la classe maison <code>AddDimension</code> qui vous permet d&#x27;ajouter
une dimension, vous devez implémenter les transformations inverses (post-traitement) afin d&#x27;annuler les transformations
qui ont été faites en amont de l&#x27;optimisation. Pour se faire, vous devez implémenter les modules de transformations
suivants:</p>
<ul>
<li><code>RemoveDimension</code>: Retirer la dimension B de la <code>batch_size</code> (taille de lot). On veut que le format passe de</li>
<li>(B,C,H,W) -&gt; (C,H,W). Utilisez la fonction PyTorch <code>squeeze</code>.</li>
<li><code>DeNormalize</code>: Retirer la normalisation en appliquant son inverse sur les valeurs des pixels de l&#x27;image. On
veut annuler l&#x27;effet de <em>ImageNet_mean</em> (égal à [0.485, 0.456, 0.406]) et de <em>ImageNet_std</em> (égal à [0.229, 0.224, 0.225]).
Vous devez faire les manipulations manuellement.</li>
<li><code>Clamp</code>: Fixer les valeurs des pixels de l&#x27;image dans les bornes [0,1]. Utilisez la fonction PyTorch <code>clamp</code>.</li>
<li><code>Permute</code>: Faire une permutation de l&#x27;ordre des dimensions pour permettre à la librairie Matplotlib de lire l&#x27;image.</li>
<li>On veut que le format passe de (C,H,W) -&gt; (H,W,C). Utilisez la fonction PyTorch <code>permute</code>.</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Classe de transformation Custom pour ajouter un channel à la position &quot;dim&quot;.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Cette classe vous est donnée comme exemple pour l&#x27;implémentation des autres transformations.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Custom transformation class to add a channel at the &quot;dim&quot; position.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># This class is given as an example for the implementation of other transformations.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class AddDimension(object):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, dim):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.dim = dim</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __call__(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            tensor (Tensor): Tensor image of size (C,H,W).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            tensor (Tensor): Tensor image with an added channel, now of size (1,C,H,W).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        new_x = x.unsqueeze(self.dim)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return new_x</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Étapes de prétraitement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 1. Redimensionner l&#x27;images à la taille désirée -&gt; (3, 256, 256)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 2. Transformer l&#x27;image PIL en tenseur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 3. Appliquer la normalisation ImageNet</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 4. Ajouter une dimension pour PyTorch (C,H,W) -&gt; (B,C,H,W)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#    où B est la taille de batch (lot).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Preprocessing steps</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Resize the image to the desired size -&gt; (3, 256, 256)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 2. Transform the PIL image into a tensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 3. Apply ImageNet normalization</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 4. Add a dimension for PyTorch (C,H,W) -&gt; (B,C,H,W)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># where B is the batch size.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">preprocessing = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                    transforms.ToTensor(),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                    transforms.Normalize(mean=IMAGENET_MEAN,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                                         std=IMAGENET_STD),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                    AddDimension(0),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                   ])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Puisque PyTorch travaille sur des lots (batch)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># d&#x27;images, une dimension supplémentaire (B) est</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ajoutée pour son fonctionnement. L&#x27;image en entrée</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># passe donc de la taille (3, 256, 256) à la taille</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># (B, 3, 256, 256) où B, ici, est de taille 1, car il</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># n&#x27;y a qu&#x27;une seule image par lot.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Since PyTorch works on batches of images,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># an extra dimension (B) is added for its operation. The input</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># image goes from the size (3, 256, 256) to the size</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># (B, 3, 256, 256) where B, here, is of size 1, because</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># there is only one image per batch.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Toutefois, afin d&#x27;afficher l&#x27;image hybride, il est important</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># de retirer cette dimension supplémentaire, car les outils</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># d&#x27;affichage s&#x27;attendent à afficher une image unique</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Cette prochaine classe doit donc vous permettre de</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># retirer cette dimension supplémentaire.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># However, in order to display the hybrid image, it is important</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># to remove this extra dimension, because the display tools</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># expect to display a single image.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># This next class should allow you to</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># remove this extra dimension.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class RemoveDimension(object):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, dim):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.dim = dim</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __call__(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            x (Tensor): Tensor image of size (1,C,H,W).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            new_x (Tensor): Tensor image with the removed channel, now of size (C,H,W).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implémentation d&#x27;une transformation Custom</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # pour retirer un channel à la position &quot;dim&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Utilisez la fonction Pytorch Squeeze()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implementation of a Custom transformation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # to remove a channel at the &quot;dim&quot; position</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Use the Pytorch Squeeze() function</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        new_x = x.squeeze(self.dim)  # On retire la dimension B</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return new_x</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Comme le réseau VGG19 a été pré-entraîné sur ImageNet</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># avec des paramètres de normalisation spécifique à ce</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># jeu de données, on assume qu&#x27;il sera plus performant sur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># une nouvelle distribution d&#x27;images si celle-ci partage</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># également cette normalisation. Ainsi, pour l&#x27;extraction</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># des features de style et de contenu, le modèle VGG19 doit</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># travailler sur des images normalisées.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># As the VGG19 network has been pre-trained on ImageNet</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># with specific normalization parameters for this dataset,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># it is assumed that it will perform better on a new</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># image distribution if it shares this normalization. Thus, for the extraction</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># of style and content features, the VGG19 model must</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># work on normalized images.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Toutefois, afin d&#x27;afficher l&#x27;image hybride, il est</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># important de retirer la normalisation si on</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># souhaite avoir un résultat visuellement intéressant,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># car la normalisation a un impact sur la distribution</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># des valeurs de pixels dans l&#x27;image. La classe suivante</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># doit vous permettre d&#x27;appliquer l&#x27;inverse de la</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># normalisation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># However, in order to display the hybrid image, it is</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># important to remove the normalization</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># to get a visually interesting result,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># because normalization has an impact on the distribution</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># of pixel values in the image. The following class</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># should allow you to apply the inverse of the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># normalization.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class DeNormalize(object):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, mean, std):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.mean = mean</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.std = std</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __call__(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            x (Tensor): Tensor image of shape (C,H,W).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            new_x (Tensor): DeNormalized tensor image (C,H,W).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implémentation d&#x27;une transformation Custom</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # pour appliquer l&#x27;inverse de la normalisation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Vous devez implémenter cette fonction manuellement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # en utilisant des opérations sur les tenseurs.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        #</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implementation of a custom transformation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # to apply the inverse normalization.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # You must create this function manually using</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # tensor operations.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        mean = torch.tensor(self.mean).view(-1, 1, 1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        std = torch.tensor(self.std).view(-1, 1, 1)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        new_x = x * std + mean  # Annule la normalisation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return new_x</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Pour que les images s&#x27;affichent, la valeur des pixels doit</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># être retournée entre [0,1]. La classe suivante doit vous permettre de borner</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># les valeurs des pixels de l&#x27;image hybride entre [0,1].</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># For the images to be displayed, the pixel value must be between [0,1].</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># The following class should allow you to bound</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># the pixel values of the hybrid image between [0,1].</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class Clamp(object):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, min, max):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.min = float(min)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.max = float(max)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __call__(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            x (Tensor): Tensor of the image.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            new_x (Tensor): Tensor with values clipped within [0,1].</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implémentation d&#x27;une transformation maison</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # pour borner les valeurs dans la plage [0, 1]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Utilisez la fonction PyTorch: Clamp()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        #</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implementation of a custom transformation</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # to clamp the values in the range [0, 1].</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Use the PyTorch: Clamp() function</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        new_x = x.clamp(self.min, self.max)  # On borne les valeurs</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return new_x</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Pour que la librairie Matplotlib puisse afficher le</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># contenu des images, les canaux doivent être</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># donnés dans le bon ordre. PyTorch utilise les images sous</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># la forme (B,C,H,W) et Matplotlib doit recevoir les images sous</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># la forme (H,W,C). Comme le Permute est appelé après le</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># RemoveDimension(), vous aurez ici, en entrée, un tenseur</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># (C,H,W) que vous devez transformer dans la forme</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># désirée pour l&#x27;affichage de Matplotlib.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># In order for the Matplotlib library to display the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># content of the images, the channels must</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># be given in the right order. PyTorch uses images in the form</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># (B,C,H,W) and Matplotlib must receive the images under</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># the form (H,W,C). As the Permute is called after the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># RemoveDimension(), you will have here, as input, a tensor</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># (C,H,W) that you must transform into the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># desired form for the display of Matplotlib.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">class Permute(object):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __init__(self, dims):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        self.dims = dims</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    def __call__(self, x):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            x (Tensor): Tensor of the image.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            new_x (Tensor): Tensor of the image with permuted dimensions.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implémentation d&#x27;une transformation Custom pour</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # faire une permutation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Utilisez la fonction PyTorch: Permute()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        #</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Implementation of a custom permute tranformation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Use the function Pytorch: Permute()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        new_x = x.permute(self.dims)  # On permute les dimensions pour Matplotlib</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        return new_x</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># transforms.Compose applique séquentiellement les</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># transformations. Étapes de post-traitement (voir les modules précédents)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 1. Retirer la 1ère dimension (B,C,H,W)-&gt;(C,H,W)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 2. Appliquer l&#x27;inverse de la normalisation ImageNet</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 3. Permuter les dimension pour Matplotlib (C,H,W)-&gt;(H,W,C)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 4. Clamp les valeurs des tenseurs entre [0,1]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Vous devez ici passer les paramètres désirés dans l&#x27;appel des classes</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># de transformation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># transforms.Compose applies sequentially the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># transforms. Postprocessing steps (see previous modules)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 1. Remove the 1st dimension (B,C,H,W)-&gt;(C,H,W)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 2. Apply the inverse of the ImageNet normalization</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 3. Swap dimensions for Matplotlib (C,H,W)-&gt;(H,W,C)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># 4. Clamp the tensor values between [0,1]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Here you have to pass the desired parameters in the call of</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># transformation classes.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">postprocessing = transforms.Compose([RemoveDimension(dim=0),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                     DeNormalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                     Permute(dims=(1, 2, 0)),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                     Clamp(min=0.0, max=1.0)])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Le code suivant est donné pour permettre d&#x27;afficher</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># certaines informations utiles qui vous permettront</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># de comprendre si vos transformations post-traitement</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># sont fonctionnelles.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># The following code is given to allow you to display</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># some useful information that will allow you to</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># understand if your postprocessing transformations</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># are functional.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Afficher les statistiques des images naturelles</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Display the statistics of natural images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for name, img in images.items():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Name&#x27;].append(f&#x27;raw_{name}&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Shape&#x27;].append(img.size)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    mean = numpy.mean(img)/255</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Mean&#x27;].append(mean)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    std = numpy.std(img)/255</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Std&#x27;].append(std)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Appliquer le prétraitement sur les images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Apply preprocessing on the images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pre_images = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for k,v in images.items():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    pre_images[k] = preprocessing(v)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    pre_images[k] = pre_images[k].to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Afficher les statistiques des images transformées</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Display the statistics of the transformed images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for name, img in pre_images.items():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Name&#x27;].append(f&#x27;pre_{name}&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Shape&#x27;].append(img.shape)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Mean&#x27;].append(img.mean().item())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Std&#x27;].append(img.std().item())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">post_images = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Appliquer le post-traitement sur les images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Apply postprocessing to images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for name,img in pre_images.items():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    image = img.cpu().detach()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    post_images[name] = postprocessing(image)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Afficher les statistiques des images transformées</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Display the statistics of the transformed images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for name, img in post_images.items():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Name&#x27;].append(f&#x27;post_{name}&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Shape&#x27;].append(img.shape)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Mean&#x27;].append(img.mean().item())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    results[&#x27;Std&#x27;].append(img.std().item())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Affichage des résultats</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># N.B. Bien que la taille de l&#x27;image ait été changée par le resize,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#      les valeurs de moyenne et de déviation standard devraient être</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#      très proches avant le prétraitement et après le post-traitement.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Displaying the results</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># N.B. Although the size of the image has been changed by the resize,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># the mean and standard deviation values should be very close</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># before preprocessing and after postprocessing.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">df = pandas.DataFrame(results)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">display.display(df)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<table><thead><tr><th></th><th>Name</th><th>Shape</th><th>Mean</th><th>Std</th></tr></thead><tbody><tr><td>0</td><td>raw_style_image</td><td>(1024, 1024)</td><td>0.537838</td><td>0.316222</td></tr><tr><td>1</td><td>raw_content_image</td><td>(1024, 679)</td><td>0.499688</td><td>0.229498</td></tr><tr><td>2</td><td>pre_style_image</td><td>(1, 3, 256, 256)</td><td>0.391451</td><td>1.303074</td></tr><tr><td>3</td><td>pre_content_image</td><td>(1, 3, 256, 256)</td><td>0.225736</td><td>0.992561</td></tr><tr><td>4</td><td>post_style_image</td><td>(256, 256, 3)</td><td>0.537964</td><td>0.301508</td></tr><tr><td>5</td><td>post_content_image</td><td>(256, 256, 3)</td><td>0.499748</td><td>0.217978</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q3c">Q3C<a href="#q3c" class="hash-link" aria-label="Direct link to Q3C" title="Direct link to Q3C">​</a></h3>
<p>Maintenant que nous avons les données pour l&#x27;entraînement et qu&#x27;elles sont formatées et normalisées, il faut télécharger le modèle préentraîné VGG19 de la librairie PyTorch. Puisque nous n&#x27;avons pas besoin des couches de classification, seules les couches de <em>features</em> sont stockées dans la variable <code>vgg</code>. Pour ce faire, affichez les noms des modules et couches du modèle et ne sélectionnez que ce qui correspond aux couches de <em>features</em>. Vous ne voulez pas conserver les couches de classification, car elles ne sont pas utiles pour la suite du problème. Ensuite, vous devez geler les paramètres du réseau, car ils ne seront pas modifiés.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">import torchvision</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(torchvision.__version__)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Télécharger la portion &quot;features&quot; du VGG19</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Nous n&#x27;avons pas besoin des couches de classification.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># !!! Veuillez passer en paramètre progress=False dans la  !!!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># !!! fonction. Autrement, l&#x27;exécution vous retournera une !!!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># !!! erreur.                                              !!!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Geler les couches pré-entraînées</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Download the features portion of the VGG19</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># We don&#x27;t need the classification layers.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># !!! Please pass in the progress=False parameter in the !!!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># !!! function. Otherwise, the execution will return an !!!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># !!! error. !!!</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Freeze pre-trained layers</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># L&#x27;utilisation du paramètre &#x27;pretrained&#x27; est dépréciée dans la version</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># de torchvision que j&#x27;utilise (version 0.16). À la place, j&#x27;utilise le</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># paramètre &#x27;weights&#x27; pour charger un modèle pré-entraîné.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from torchvision.models import vgg19, VGG19_Weights</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Télécharger la portion &quot;features&quot; du VGG19 avec les poids pré-entraînés</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">vgg = vgg19(weights=VGG19_Weights.IMAGENET1K_V1).features</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Geler les couches pré-entraînées</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for param in vgg.parameters():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    param.requires_grad = False</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Si GPU disponible, monter le modèle sur le GPU</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># If GPU available, mount the model on the GPU</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">vgg.to(DEVICE)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-txt codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-txt codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">Sequential(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (1): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (3): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (6): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (8): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (11): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (13): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (15): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (17): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (20): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (22): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (24): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (26): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (29): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (31): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (33): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (35): ReLU(inplace=True)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q3d">Q3D<a href="#q3d" class="hash-link" aria-label="Direct link to Q3D" title="Direct link to Q3D">​</a></h3>
<p>Afin de pouvoir développer les fonctions de perte (<em>loss</em>) et lancer la génération de l&#x27;image hybride, il faut tout
d&#x27;abord initialiser les pondérations et calculer quelques paramètres importants. Vous devez donc:</p>
<ol>
<li>Extraire les <em>features</em> de l&#x27;image de style avec la fonction <code>extract_features</code>;</li>
<li>Extraire les <em>features</em> de l&#x27;image de contenu avec la fonction <code>extract_features</code>;</li>
<li>Créer une copie de l&#x27;image de contenu (appelée image cible) pour permettre de l&#x27;ajuster itérativement tout en
gardant une copie du contenu original.</li>
</ol>
<p>Également, vous êtes invités à ajuster les pondérations et les paramètres <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span> pour rendre votre rendu le
plus à votre goût possible. Notez bien que vous n&#x27;êtes pas évalué sur la qualité du rendu, mais on vous encourage
fortement à tester d&#x27;autres configurations de paramètres pour bien en comprendre le fonctionnement.</p>
<p>Dans le contexte du transfert de style en utilisant des réseaux de neurones convolutionnels, comme dans votre cas avec le
modèle VGG19, les paramètres <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span> sont utilisés pour équilibrer les contributions respectives de la
perte de contenu et de la perte de style dans la fonction de perte totale lors de la génération de l&#x27;image cible.</p>
<p>Dans votre code, ces paramètres sont représentés par :</p>
<ul>
<li><code>content_weight</code> pour <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>, qui est la pondération de la perte de contenu.</li>
<li><code>style_weight</code> pour <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span>, qui est la pondération de la perte de style.</li>
</ul>
<p>La fonction de perte totale <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span> dans le transfert de style est souvent représentée comme suit :</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo>=</mo><mi>α</mi><mo>×</mo><msub><mi>L</mi><mtext>content</mtext></msub><mo>+</mo><mi>β</mi><mo>×</mo><msub><mi>L</mi><mtext>style</mtext></msub></mrow><annotation encoding="application/x-tex">L = \alpha \times L_{\text{content}} + \beta \times L_{\text{style}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">content</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">style</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>
<p>où <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mtext>content</mtext></msub></mrow><annotation encoding="application/x-tex">L_{\text{content}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">content</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> est la perte de contenu calculée entre les features de l&#x27;image de contenu et celles de l&#x27;image
cible, et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mtext>style</mtext></msub></mrow><annotation encoding="application/x-tex">L_{\text{style}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">style</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> est la perte de style calculée entre les matrices de Gram des features de l&#x27;image de style et de l&#x27;image cible.</p>
<ul>
<li>Une valeur élevée de <code>content_weight</code> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>) signifie que vous voulez que l&#x27;image cible ressemble davantage à l&#x27;image de contenu en termes de caractéristiques de contenu.</li>
<li>Une valeur élevée de <code>style_weight</code> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span>) signifie que vous voulez que l&#x27;image cible incorpore davantage les caractéristiques stylistiques de l&#x27;image de style.</li>
</ul>
<p>Ajuster ces paramètres vous permet de contrôler l&#x27;équilibre entre le maintien du contenu original de l&#x27;image et l&#x27;adoption
du style de l&#x27;image de style. C&#x27;est un processus expérimental et subjectif pour obtenir un résultat qui correspond à votre goût personnel.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Extraire les features de l&#x27;image de style avec la fonction</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># extract_features.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Extract the features of the style image with the function</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># extract_features.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">style_features = extract_features(pre_images[STYLE_IMAGE], vgg)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Extraire les features de l&#x27;image de content avec la fonction</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># extract_features.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Extract the features of the content image with the function</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># extract_features.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">content_features = extract_features(pre_images[CONTENT_IMAGE], vgg)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Pré-calculer la matrice de Gram pour chaque couche de style</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Pre-compute the Gram matrix for each style layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">style_grams = {}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for layer in style_features:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    style_grams[layer] = gram_matrix(style_features[layer])</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Création d&#x27;une image cible temporaire. Utilisez la fonction clone() de</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># la librairie PyTorch. N&#x27;oubliez pas le gradient! Considérez également le</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># device utilisé (CPU vs GPU). Il faut travailler sur une copie de</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># l&#x27;image cible pour changer son style itérativement.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Create a temporary target image. Use the clone() function of</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># the PyTorch library. Don&#x27;t forget the gradient! Also consider the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># device used (CPU vs GPU). You have to work on a copy of the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># the target image to change its style iteratively.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">target = pre_images[CONTENT_IMAGE].clone().requires_grad_(True).to(DEVICE)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Poids appliqués pour chaque couche de style</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Weights applied for each style layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Valeurs par défaut / default values:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># &#x27;conv1_1&#x27;: 1.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># &#x27;conv2_1&#x27;: 0.75</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># &#x27;conv3_1&#x27;: 0.2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># &#x27;conv4_1&#x27;: 0.2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># &#x27;conv5_1&#x27;: 0.2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">style_layers_weights = {&#x27;conv1_1&#x27;: 1.,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                        &#x27;conv2_1&#x27;: 0.75,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                        &#x27;conv3_1&#x27;: 0.2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                        &#x27;conv4_1&#x27;: 0.2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                        &#x27;conv5_1&#x27;: 0.2}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Par défaut: content_weight = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># By default: content_weight = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">content_weight = 1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Par défaut: style_weight = 1e7</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># By default: style_weight = 1e7</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">style_weight = 1e7</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q3e">Q3E<a href="#q3e" class="hash-link" aria-label="Direct link to Q3E" title="Direct link to Q3E">​</a></h3>
<p>Le transfert de style, comme vous pouvez le comprendre dans l&#x27;article de
<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" target="_blank" rel="noopener noreferrer">Gatys et coll.</a>,
ne requière pas d&#x27;entraînement à proprement parler. En effet, puisqu&#x27;on utilise un réseau préentraîné et qu&#x27;on en gèle
les poids, le réseau n&#x27;apprend rien. Toutefois, les pixels de l&#x27;image cible (hybride) doivent être optimisés pour
contenir à la fois le <em>style</em> ainsi que le <em>contenu</em> désiré. On fait donc une descente de gradient avec fonction de
perte pour minimiser la différence de contenu entre l&#x27;image originale et l&#x27;image générée, tout en intégrant le nouveau style à l&#x27;image générée.</p>
<p>Pour se faire, deux fonctions de pertes doivent être développées: une qui permet de mesurer la différence de contenu
entre l&#x27;image cible et l&#x27;image de contenu (<em>perte de contenu</em>) ainsi qu&#x27;une seconde qui permet de mesurer la différence
de style entre la matrice Gram de l&#x27;image cible et celle de l&#x27;image de style (<em>perte de style</em>). La somme pondérée de
ces deux fonctions permet de générer la <em>perte totale</em> qui sera utilisée pour l&#x27;optimisation des pixels de l&#x27;image hybride.</p>
<ol>
<li>Implémenter la fonction <code>calculate_content_loss</code> qui prend en paramètre le nom de la couche <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span></span></span></span> à évaluer et qui</li>
<li>retourne la perte de contenu entre les paramètres de l&#x27;image cible (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">F</span></span></span></span>) et les paramètres de l&#x27;image de contenu</li>
<li>(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>). La fonction de calcul de la perte est la suivante:</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>p</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mi>l</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>F</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><mo>−</mo><msubsup><mi>P</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">L_{content}(\vec{p},\vec{x},l) = \frac{1}{2}\sum_{i,j}(F_{i,j}^l - P_{i,j}^l)^2,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">p</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1522em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">x</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2077em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2849em;vertical-align:-0.4358em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.2439em;vertical-align:-0.3948em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span> où la couche qui doit être</li>
<li>utilisée pour calculer la perte de contenu est la 21e couche du modèle VGG19. Vous retrouverez le nom de cette</li>
<li>couche dans le</li>
<li>graphe du modèle.</li>
<li>Implémenter la fonction <code>calculate_style_loss</code> qui retourne la perte de style entre la matrice Gram de l&#x27;image cible</li>
<li>(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">G</span></span></span></span>) et la matrice Gram de l&#x27;image de style (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>). La fonction de calcul de cette perte est:</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mn>4</mn><msubsup><mi>N</mi><mi>l</mi><mn>2</mn></msubsup><msubsup><mi>M</mi><mi>l</mi><mn>2</mn></msubsup></mrow></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><msubsup><mi>G</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><mo>−</mo><msubsup><mi>A</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">E_i = \frac{1}{4N_l^2M_l^2}\sum_{i,j}(G_{i,j}^l - A_{i,j}^l)^2,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.4657em;vertical-align:-0.6166em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.6264em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em"><span style="top:-2.1528em;margin-left:-0.109em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span><span style="top:-2.8448em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472em"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8051em"><span style="top:-2.1528em;margin-left:-0.109em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span><span style="top:-2.8448em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6166em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.2439em;vertical-align:-0.3948em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3948em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span> où <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span>
sont des paramètres que vous devez extraire de votre compréhension de l&#x27;article, suivi de:
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>s</mi><mi>t</mi><mi>y</mi><mi>l</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>0</mn></mrow><mi>L</mi></msubsup><msub><mi>w</mi><mi>l</mi></msub><msub><mi>E</mi><mi>l</mi></msub><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">L_{style}(\vec{a},\vec{x})=\sum_{l=0}^L w_l E_l,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">a</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">x</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2077em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span> où <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">w_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> est la pondération donnée à la couche <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.01968em">l</span></span></span></span>.</li>
</ol>
<p>Implémenter la fonction <code>calculate_total_loss</code> qui retourne la perte totale pour l&#x27;itération actuelle. La fonction pour vous permettre de calculer cette perte est:
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>p</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><msub><mi>L</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>p</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">)</mo><mo>+</mo><mi>β</mi><msub><mi>L</mi><mrow><mi>s</mi><mi>t</mi><mi>y</mi><mi>l</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{total}(\vec{a},\vec{p},\vec{x})=\alpha L_{content}(\vec{p},\vec{x}) + \beta L_{style}(\vec{a},\vec{x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">a</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">p</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1522em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">x</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2077em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">p</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1522em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">x</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2077em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">a</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2355em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">x</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.2077em"><span class="overlay" style="height:0.714em;width:0.471em"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Implémenter la fonction qui calcule la perte de contenu pour</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># une couche donnée. La perte est calculée comme l&#x27;erreur quadratique</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># entre les paramètres de l&#x27;image cible et les paramètres de l&#x27;image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># de contenu pour chaque couche.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Implement the function that calculates the content loss for</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># a given layer. The loss is calculated as the squared error</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># between the parameters of the target image and the parameters</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># of the content image for each layer.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def calculate_content_loss(layer_name):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    assert(layer_name in target_features.keys())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    assert(layer_name in content_features.keys())</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Calculates the content loss between the target image features and</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    the content image features.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        layer_name (String) : Name of the layer to evaluate.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        tensor (Tensor): Tensor containing the loss of the squared mean</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                         difference between the target and content layers.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    target_feature = target_features[layer_name]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    content_feature = content_features[layer_name]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    content_loss = F.mse_loss(target_feature, content_feature) / 2</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return content_loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Implémenter la fonction qui calcule la perte de style pour une couche donnée.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Cette perte de style est calculée par l&#x27;erreur entre la matrice Gram</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># de contenu et la matrice Gram de style, pondérée par le poids donné à chaque couche.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Implement the function that calculates the style loss for a given layer.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># This style loss is calculated as the error between the content Gram</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># matrix and the style Gram matrix, weighted by the weight given to each layer.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def calculate_style_loss(weight_layer, target_gram, style_gram, target_feature):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Calculates the style loss between the Gram matrix of the image features and</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    the Gram matrix of the content image features.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        weight_layer (Float) : weighting for the current layer (w_l).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        target_gram (Tensor) : Gram matrix of the target image (G).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        style_gram (Tensor) : Gram matrix of the style image (A).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        target_feature (Tensor) : tensor containing the target feature for</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                  the current layer.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        style_loss (Tensor): Tensor with the computed style loss for the current layer.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    N_l = target_feature.shape[1]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    M_l = target_feature.shape[2] * target_feature.shape[3]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    style_loss = weight_layer * F.mse_loss(target_gram, style_gram) / (4 * N_l**2 * M_l**2)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return style_loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Implémenter la fonction qui calcule la perte totale pour l&#x27;itération.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># La perte totale est calculée par la somme pondérée de la perte de contenu</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># et la perte de style.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Implement the function that calculates the total loss for the iteration.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># The total loss is calculated by the weighted sum of the content loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># and the style loss.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def calculate_total_loss(content_weight, content_loss, style_weight, style_loss):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Calculates the total loss for the current iteration.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        content_weight (Float) : Alpha weighting for the content.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        content_loss (Float) : Content loss.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        style_weight (Float) : Beta weighting for the style.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        style_loss (Float) : Total loss.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    Returns:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        total_loss (Tensor): Tensor with the computed total loss for the current iteration.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    total_loss = content_weight * content_loss + style_weight * style_loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    return total_loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Nombre total d&#x27;itérations pour appliquer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># le transfert de style (Min: 2000 | Recommandé: 5000)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Total number of iterations to apply</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># style transfer (Min: 2000 | Recommended: 5000)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">steps = 5000</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Fréquence de mise à jour de l&#x27;image (Valeur recommandée: 500)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Image update frequency (Recommended value: 500)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">show_image_every = 500</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Initialisation de l&#x27;optimiseur Adam. Puisqu&#x27;on modifie la cible,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># on l&#x27;applique directement sur les pixels de l&#x27;image (learning_rate = 3e-3).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Initialization of the Adam optimizer. Since we modify the target,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># we apply it directly on the pixels of the image (learning_rate = 3e-3).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># [Gatys et coll, 2016] font usage de L-BFGS mais pour simplifier l&#x27;implémentation et accélérer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># la convergence vers des résultats visibles, Adam est plus approprié.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># [Gatys et al, 2016] make use of L-BFGS but to simplify implementation and accelerate</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># convergence to visible results, Adam is more appropriate.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">optimizer = optim.Adam([target], lr=3e-3)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">for s in tqdm(range(1, steps+1)):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 1. Remise à zéro des gradients</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 1. Reset the gradients to zero</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    optimizer.zero_grad()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 2. Extraire les features de l&#x27;image cible</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 2. Extract the features of the target image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    target_features = extract_features(target, vgg)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # *** TODO ***</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 3. Calculer la loss de contenu avec la fonction</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # calculate_content_loss. Vous devez retrouver le</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # nom de la couche dans le graphe du modèle.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 3. Calculate the content loss with the function</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # calculate_content_loss. You must find the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # name of the layer in the model graph.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    layer_name = &quot;conv4_2&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    content_loss = calculate_content_loss(layer_name)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # ******</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 4. Calculer la loss de style en accumulant sa valeur pour chaque couche</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 4. Calculate the style loss by accumulating its value for each layer</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    style_loss = 0 # Initialiser la loss de style à zéro / Initialise style loss to zero</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    for l_name, l_weight in style_layers_weights.items():</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Extraire le contenu de la couche / Extract layer content</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        target_feature = target_features[l_name]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Calculer la matrice de Gram du contenu / Compute content Gram matrix</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        target_gram = gram_matrix(target_feature)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Extraire la matrice Gram pré-calculée pour le style</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Extract the pre-computed Gram matrix for the style</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        style_gram = style_grams[l_name]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Calculer la loss de style avec pondération pour</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # la couche donnée avec la fonction calculate_style_loss().</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Calculate the weighted syle loss for</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # the given layer with the function calculate_style_loss().</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        layer_style_loss = calculate_style_loss(l_weight,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                                target_gram,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                                style_gram,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                                target_feature)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Accumuler la loss de style / Accumulate style loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        style_loss += layer_style_loss</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 5. Calculer la loss totale avec la fonction calculate_total_loss()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 5. Calculate the total loss with the function calculate_total_loss()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    total_loss = calculate_total_loss(content_weight,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                      content_loss,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                      style_weight,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">                                      style_loss)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 6. Mettre à jour l&#x27;image cible</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # 6. Update the target image</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    total_loss.backward()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    optimizer.step()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Afficher les images intermédiaires</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # Display intermediate images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    if  s % show_image_every == 0:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Appliquer le postprocessing sur les images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        # Apply postprocessing to the images</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        plt.figure(figsize=(10,10))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        img = target.cpu().detach()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        img_post = postprocessing(img)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        plt.imshow(img_post)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        plt.axis(&#x27;off&#x27;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        plt.show()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Libère la cache sur le GPU *important sur un cluster de GPU*</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Free the cache on the GPU *important on a GPU cluster*.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">torch.cuda.empty_cache()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>J&#x27;obtiens cette image.</p>
<p><img loading="lazy" alt="hybride" src="/assets/images/hybride-645d85f7ea2a41335487fdced8b1d4db.png" width="557" height="558" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q3f">Q3F<a href="#q3f" class="hash-link" aria-label="Direct link to Q3F" title="Direct link to Q3F">​</a></h3>
<p>Pour ce cas du transfert de style, plusieurs paramètres peuvent être modifiés pour permettre de modifier le rendu de
l&#x27;image hybride. La pondération pour chacune des couches de style peut être modifiée ainsi que les paramètres <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>
et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span>. En fonction de votre compréhension de l&#x27;article et de vos tests, observez l&#x27;effet de chacun de ces paramètres.</p>
<p>Dans la cellule de réponse prévue à cet effet, veuillez répondre aux questions suivantes:</p>
<ol>
<li>Quel est l&#x27;effet de pondérer différemment les couches sur le style?</li>
<li>Que se passe-t-il si on pondère plus fortement les premières couches?</li>
<li>Que se passe-t-il si on pondère plus fortement les dernières couches?</li>
<li>Quel est l&#x27;effet du paramètre <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span>?</li>
<li>Quel est l&#x27;effet du paramètre <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span>?</li>
<li>Qu&#x27;est-ce qui est, selon vous, une bonne configuration des paramètres de pondération des poids des couches de style,</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span>, et pourquoi?</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="q3f-réponse">Q3F Réponse<a href="#q3f-réponse" class="hash-link" aria-label="Direct link to Q3F Réponse" title="Direct link to Q3F Réponse">​</a></h3>
<ul>
<li><strong>1. Effet de la pondération des couches sur le style</strong> : Chaque couche du réseau VGG extrait différents aspects
du style de l&#x27;image. Les couches inférieures capturent des détails fins (textures, motifs) tandis que les couches
supérieures capturent des caractéristiques plus complexes et abstraites. Ainsi, pondérer différemment ces couches
permet de contrôler quel niveau de détail et d&#x27;abstraction du style dans l&#x27;image hybride.</li>
<li><strong>2. Pondération plus forte des premières couches</strong> : En pondérant plus fortement les premières couches (couches inférieures),
l&#x27;image hybride aura tendance à refléter davantage les textures et motifs de base de l&#x27;image de style, comme les coups
de pinceau ou les gradients de couleur.</li>
<li><strong>3. Pondération plus forte des dernières couches</strong> : En augmentant la pondération des dernières couches (couches supérieures),
l&#x27;image hybride tend à intégrer des aspects plus abstraits et complexes du style, comme les formes globales ou la
composition de l&#x27;image de style.</li>
<li><strong>4. Effet du paramètre <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span></strong> : Ce paramètre contrôle combien de l&#x27;image de contenu originale est conservée dans
l&#x27;image hybride. Une valeur plus élevée pour <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span> signifie que l&#x27;image hybride sera plus proche de l&#x27;image de
contenu, avec moins d&#x27;influence du style.</li>
<li><strong>5. Effet du paramètre <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></strong> : Ce paramètre détermine l&#x27;impact du style sur l&#x27;image hybride. Une valeur plus élevée pour <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span> donne plus de poids au style de l&#x27;image de style, ce qui peut conduire à une image hybride où le style est plus dominant par rapport au contenu original.</li>
<li><strong>6. Configuration optimale des paramètres</strong> : La configuration optimale des paramètres de pondération dépend de l&#x27;effet
désiré et de la nature des images de style et de contenu.<!-- -->
<ul>
<li>Si l&#x27;image de style est riche en petits détails (comme un tableau impressionniste), une pondération plus élevée des premières couches peut aider à capturer ces détails.</li>
<li>Si l&#x27;image de style a des caractéristiques stylistiques à plus grande échelle (comme des formes géométriques ou des compositions abstraites), une pondération plus élevée des couches supérieures peut être plus appropriée.</li>
<li>Pour une image hybride où le contenu doit être clairement reconnaissable mais artistiquement stylisé, un équilibre entre <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span> et <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span> sera est préférable.</li>
<li>Pour un effet de style prononcé, un <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span> élevé est nécessaire.</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/courses/gif-7005/devoir-4.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/courses/gif-7005/devoir-3"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Devoir 3 du 8 novembre 2023</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/courses/gif-7005/devoir-5"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Devoir 5 du 8 décembre 2023</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#d4q1---réseau-de-neurones-à-convolution" class="table-of-contents__link toc-highlight">D4Q1 - Réseau de neurones à convolution</a><ul><li><a href="#code-préambule" class="table-of-contents__link toc-highlight">Code préambule</a></li><li><a href="#q1a" class="table-of-contents__link toc-highlight">Q1A</a></li><li><a href="#q1b" class="table-of-contents__link toc-highlight">Q1B</a></li><li><a href="#q1c" class="table-of-contents__link toc-highlight">Q1C</a></li></ul></li><li><a href="#d4q2---transfert-de-représentation" class="table-of-contents__link toc-highlight">D4Q2 - Transfert de représentation</a><ul><li><a href="#code-préambule-d4q2" class="table-of-contents__link toc-highlight">Code préambule (D4Q2)</a></li><li><a href="#q2a" class="table-of-contents__link toc-highlight">Q2A</a></li><li><a href="#q2b" class="table-of-contents__link toc-highlight">Q2B</a></li></ul></li><li><a href="#d4q3---transfert-de-style" class="table-of-contents__link toc-highlight">D4Q3 - Transfert de style</a><ul><li><a href="#code-préambule-d4q3" class="table-of-contents__link toc-highlight">Code préambule (D4Q3)</a></li><li><a href="#q3a" class="table-of-contents__link toc-highlight">Q3A</a></li><li><a href="#q3b" class="table-of-contents__link toc-highlight">Q3B</a></li><li><a href="#q3c" class="table-of-contents__link toc-highlight">Q3C</a></li><li><a href="#q3d" class="table-of-contents__link toc-highlight">Q3D</a></li><li><a href="#q3e" class="table-of-contents__link toc-highlight">Q3E</a></li><li><a href="#q3f" class="table-of-contents__link toc-highlight">Q3F</a></li><li><a href="#q3f-réponse" class="table-of-contents__link toc-highlight">Q3F Réponse</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Alain Boisvert. Construit avec Docusaurus.</div></div></div></footer></div>
</body>
</html>